{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZd+Vj+uQiTkVleWt8Bx3o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa8dc5dbb6294beeb0a4960908a387b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4a7d25b195d04a2db15af0dc68d14575",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_412676d3cf9546d08d9c5ba192ed476e",
              "IPY_MODEL_d72729632cb14cc18e866669ed304c4a",
              "IPY_MODEL_f56992e773734ac1b9f97164416dd602"
            ]
          }
        },
        "4a7d25b195d04a2db15af0dc68d14575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "412676d3cf9546d08d9c5ba192ed476e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b09061c36f5489a88840c3615c5b53f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5055c28866c418cb219ea70501c55ef"
          }
        },
        "d72729632cb14cc18e866669ed304c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2e022780edc4955a28e86db0d646b0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffa628075321491685286a678ede4c93"
          }
        },
        "f56992e773734ac1b9f97164416dd602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3543361b867140d4990954e1be01017f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [00:00&lt;00:00, 14.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4d3252944934d7b81a9ff6b797890d7"
          }
        },
        "7b09061c36f5489a88840c3615c5b53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5055c28866c418cb219ea70501c55ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2e022780edc4955a28e86db0d646b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffa628075321491685286a678ede4c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3543361b867140d4990954e1be01017f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4d3252944934d7b81a9ff6b797890d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaygrao77/Deep-learning-assignment1/blob/Question-3/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "c56SyC-YJP2l"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from decimal import *\n",
        "# Only used to show progressbar while inside an epoch\n",
        "from tqdm.notebook import tqdm "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wandb\n",
        "# !wandb login"
      ],
      "metadata": {
        "id": "UDs0PaU3bSy1"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import wandb\n",
        "\n",
        "# wandb.init(project=\"Deep learning assignment1\", entity=\"akshaygrao\")"
      ],
      "metadata": {
        "id": "l7S9Txmvby9G"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.config = {\n",
        "#   \"learning_rate\": 0.001,\n",
        "#   \"epochs\": 100,\n",
        "#   \"batch_size\": 128\n",
        "# }"
      ],
      "metadata": {
        "id": "EX_0bvTcb401"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1 starts**"
      ],
      "metadata": {
        "id": "vhblbkxZZTB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset from fashio-mnist"
      ],
      "metadata": {
        "id": "GWft3bAmZLfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "xjCgLdUGSuwd"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_image_per_class():\n",
        "  num_class=10\n",
        "  for cls in range(num_class):\n",
        "    i=0\n",
        "    while(True):\n",
        "      i=i+1\n",
        "      if(y_train[i] == cls):\n",
        "        # image = x_train[i]\n",
        "        plt.imshow( x_train[i], cmap='gray')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "        break;"
      ],
      "metadata": {
        "id": "UGd8jLf8TvDT"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_image_per_class()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1_UsoPirT01b",
        "outputId": "8289def7-8008-4f71-e2a7-4114fb0468b6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASwklEQVR4nO3dX2xU95UH8O/hr/ljMLaJcagJDTKJIEpogshKJausUKqAlJA+EJWHipWidR9aqZX6sFHy0ORhlWi1LcvDqombRKWrbqpKEIWHCMGiRhFRQCGJN+D8gyUm4PgPBAg2BDDm7INvKjfxPWeYO3furM/3I1ke5vjOHN/x4c7cc3+/n6gqiGjym1J0AkRUHSx2oiBY7ERBsNiJgmCxEwUxrZpPJiIhT/2LiBmfMWOGGa+rqzPjFy9eTI1du3bN3LZIWX/vCxcuVDKdSUNVJ/yDy1TsIvIggG0ApgJ4QVWfzfJ4WUyZYr9JuX79eq7bW6ZPn27G29razPjKlSvN+MGDB1Nj/f395rZFam1tNeMrVqww47t37zbjebaV8/x7yUvZb+NFZCqA/wCwHsAKAJtFxH51iKgwWT6zrwFwTFWPq+pVAH8CsLEyaRFRpWUp9sUATo7796nkvr8hIh0ickhEDmV4LiLKKPcTdKraCaATiHuCjqgWZDmy9wIYf2bpO8l9RFSDshT72wDaReS7IjIDwI8A7KpMWkRUaZKlPSEiGwD8O8Zaby+p6r84P5/b23ivl+3Fs7RKnn/+eTM+c+ZMM37lyhUz3tLSYsbr6+tTY97r6/W633vvPTM+a9YsMz4yMpIa81qKQ0NDZvz48eNmvKGhITW2a5d9XNqxY4cZ9xTZmsulz66qrwF4LctjEFF18HJZoiBY7ERBsNiJgmCxEwXBYicKgsVOFESmPvsNP1mOffa8+5rPPPNMamzZsmXmtp9//rkZ93rdo6OjZnz+/PmpMW8Y6c6dO834c889Z8bfeustMz4wMJAas8bhA8CZM2fM+NSpU8249TfR2NhobnvgwAEzvnXrVjPu5ea9plmk9dl5ZCcKgsVOFASLnSgIFjtRECx2oiBY7ERBVHUq6Txlbb3deuutZvyOO+5IjX322Wfmtt4QV6/96eXe25s+Z4j33LfccosZ37Rpkxm/dOmSGT99+nRqzBvC6rWvvP1itbe8dqj1egPZW2vW9nm15XhkJwqCxU4UBIudKAgWO1EQLHaiIFjsREGw2ImCmDR99qxLE69bt86MWz3dOXPmmNtevnzZjE+blu1lmDt3bmqsr6/P3La5udmMP/TQQ2bcm2ramubam4ba66Nb01QD9rUXWZfRvu+++8z466+/bsa9588Dj+xEQbDYiYJgsRMFwWInCoLFThQEi50oCBY7URCTps+e1YoVK8y41Rf1+uxXr14t+7GBbOPdp0+fbm7rLRftTffs9aOtx/dy88Z1e9cvWFNs19XVmdt6+9wb7+712bNeF1KOTMUuIj0AhgCMArimqqsrkRQRVV4ljuz/oKr2bP5EVDh+ZicKImuxK4A9IvKOiHRM9AMi0iEih0TkUMbnIqIMsr6NX6uqvSJyE4C9IvKRqr4x/gdUtRNAJ5DvWm9EZMt0ZFfV3uT7IIBXAKypRFJEVHllF7uIzBGR+q9vA/gBgCOVSoyIKivL2/gWAK8kPeJpAP5LVXdXJKsCeMsuW31Rr1/sjdv2+sXeuG2rH+318L35z73nzrLctNdr9uLenPjW9Qfea+Ltt4ULF5rxWlR2savqcQB3VTAXIsoRW29EQbDYiYJgsRMFwWInCoLFThREmCGuXntseHjYjFtTInvtqcWLF5vxkydPmnGvNWdNmey11jxee8tjtea8qaKzsnJvbGw0t/VeE2+J71rEIztRECx2oiBY7ERBsNiJgmCxEwXBYicKgsVOFESYPntra6sZnz17thm3pha2lkwG/J7uxx9/bMatProX9/rsXq/b296bcjnL0sRebt402HfffXdqzJsi27suo6GhwYzXIh7ZiYJgsRMFwWInCoLFThQEi50oCBY7URAsdqIgwvTZrZ4r4PdVrX6xNy2x16v2pkz2crP60V6v2uuTZ2U9vpeb16P3lnS29qu1nDMA9Pf3m/EvvvjCjC9dutSM9/T0mPE88MhOFASLnSgIFjtRECx2oiBY7ERBsNiJgmCxEwURps/e0tJixr2erjV2etGiRea2Fy5cMONeH92bl97q43u/lzdW3uvDe71ua3vv9/Jy9/ab9Zp5875/8sknZtzLbdWqVWa8JvvsIvKSiAyKyJFx9zWKyF4ROZp8X5BvmkSUVSlv438P4MFv3Pc4gH2q2g5gX/JvIqphbrGr6hsAzn7j7o0Atie3twN4pMJ5EVGFlfuZvUVV+5Lb/QBSPxCLSAeAjjKfh4gqJPMJOlVVEUk9C6OqnQA6AcD6OSLKV7mttwERaQWA5Ptg5VIiojyUW+y7AGxJbm8B8Gpl0iGivLhv40XkZQD3A2gWkVMAfgXgWQB/FpHHAJwA8GieSVbCsmXLzLjXs7XWSG9qajK39Xq23rhuLzdL1j66NxY/z3nhveceHh4ue/us8+F7+/W2224z40Vwi11VN6eE1lU4FyLKES+XJQqCxU4UBIudKAgWO1EQLHaiIMIMcfWWbK6rqzPj58+fT415yz1bbTsAmDbNfhmyTPfstYg8XmvNmwY7C29J5hkzZpjxc+fOpca8dqa33+bMmWPGvb+3IvDIThQEi50oCBY7URAsdqIgWOxEQbDYiYJgsRMFEabP7g1DzTKM1Os1f/XVV2U/NuD3fK143n32LMtJe9cfeH107/oDbwisxfu95s2bZ8Zvvvnmsp87LzyyEwXBYicKgsVOFASLnSgIFjtRECx2oiBY7ERBhOmzz5o1y4x7/WRrvHtzc7O57cWLF824N61xFt50zV4f3svN65VneeysU2xfunQpNXb16lVzW29+A+8agKzXN+Sh9jIiolyw2ImCYLETBcFiJwqCxU4UBIudKAgWO1EQk6bPPnPmzEzbe33VhQsXpsa6urrMba055wGgpaXFjHvzp1v9aK+X7fWDR0ZGzLg3573FG+fvPbb3mg8MDKTGvGsfvGsnvOsyRkdHzbh1jYC3z8vlHtlF5CURGRSRI+Pue0pEekWkK/nakEt2RFQxpbyN/z2ABye4f6uqrkq+XqtsWkRUaW6xq+obAM5WIRciylGWE3Q/E5H3k7f5C9J+SEQ6ROSQiBzK8FxElFG5xf5bAMsArALQB+DXaT+oqp2qulpVV5f5XERUAWUVu6oOqOqoql4H8DsAayqbFhFVWlnFLiLj16P9IYAjaT9LRLXBbZKKyMsA7gfQLCKnAPwKwP0isgqAAugB8JMccyzJggWppw1K4vWb6+vrU2PeuOssvWjA79la86d7/WAvnpWVu7fPvTHj3vUH1hrqXp99+fLlZty7tsLL/aabbkqN9fb2mtuWy/0rVNXNE9z9Yg65EFGOeLksURAsdqIgWOxEQbDYiYJgsRMFMWmGuDY0NJhxbzik1way2jgnTpwwt/WGz3pLPmeZctlb1tj7vbNu77Ulszy395parbnu7m5z2yVLlphxbypq7zWz/p7ywiM7URAsdqIgWOxEQbDYiYJgsRMFwWInCoLFThTEpOmze0MKvel5vb6n1dPdvXu3ue1dd91lxr3csiz/6w2v9a4B8PrJ3uNb/WavB+/l5u036zU7evSoue2mTZvM+Ny5c824t99mz55txvPAIztRECx2oiBY7ERBsNiJgmCxEwXBYicKgsVOFMSk6bN7Y8I93pTK1uNn7UWfPWsvpZdlzLj33N6Uyt401t6Y8ixLaZ85c8aMe+Pd29raUmP79+83t/3yyy/NuLXkMgAMDw+b8fnz55vxPPDIThQEi50oCBY7URAsdqIgWOxEQbDYiYJgsRMFMWn67N74YG/s8+XLl8241S/2tvXG2i9atMiMe334WbNmpcaamprMbQcHB824txS2t1+HhoZSY15u3tzt58+fN+PWHAVej957TQ4fPmzGvb8J6zXLi3tkF5E2EfmLiHwgIt0i8vPk/kYR2SsiR5Pv2RZIJ6JclfI2/hqAX6rqCgB/B+CnIrICwOMA9qlqO4B9yb+JqEa5xa6qfar6bnJ7CMCHABYD2Ahge/Jj2wE8kleSRJTdDX1mF5GlAL4H4CCAFlXtS0L9AFpStukA0FF+ikRUCSWfjReRuQB2APiFql4YH9Oxsx0TnvFQ1U5VXa2qqzNlSkSZlFTsIjIdY4X+R1Xdmdw9ICKtSbwVgH1al4gK5b6Nl7Gxny8C+FBVfzMutAvAFgDPJt9fzSXDEnntLa/N4w05tIZ61tfXm9tmXXrYG75rtb+8oZgLFy4047fffrsZP3DggBm3WnteW88b2ptlv/f395vb9vX1mfGPPvrIjLe3t5tx7+81D6V8Zv8+gB8DOCwiXcl9T2CsyP8sIo8BOAHg0XxSJKJKcItdVfcDSJvZYV1l0yGivPByWaIgWOxEQbDYiYJgsRMFwWInCmLSDHH1ltD14h6rX33vvfea254+fdqMW1MeA/5U1dZQTm8qaGtJZcCfztmbMtna71mn2F65cqUZt4bAPvDAA+a23rUP3jUCV65cMeMtLRNeXZ4rHtmJgmCxEwXBYicKgsVOFASLnSgIFjtRECx2oiAmTZ/dG5d97NgxM+6NZ7fGTntjo+vq6sy415P1ph22xrt7S1F7uXl9dK+Pb12f4I3T95ZN9q6dsParN57cW8raG+fv/W7eHAd54JGdKAgWO1EQLHaiIFjsREGw2ImCYLETBcFiJwpi0vTZvb6pF/fGjFv9aK9neunSJTPujZ32lv/NoqGhwYx/+umnmR7f6vN7+8Uba+8tN229Lt71A9ZS04B/fYF37YTXh88Dj+xEQbDYiYJgsRMFwWInCoLFThQEi50oCBY7URClrM/eBuAPAFoAKIBOVd0mIk8B+CcAX0+K/oSqvpZXoh6vZztv3jwz3tPTY8at8e7eWHpv3LU3dtp7fKvn6z2212/2rgHwxtpbvNfEe2zv+gYrvmTJEnNbrw8+MjJixs+dO2fGs16/UI5SLqq5BuCXqvquiNQDeEdE9iaxrar6b/mlR0SVUsr67H0A+pLbQyLyIYDFeSdGRJV1Q5/ZRWQpgO8BOJjc9TMReV9EXhKRCdfDEZEOETkkIocyZUpEmZRc7CIyF8AOAL9Q1QsAfgtgGYBVGDvy/3qi7VS1U1VXq+rqCuRLRGUqqdhFZDrGCv2PqroTAFR1QFVHVfU6gN8BWJNfmkSUlVvsMjZs6UUAH6rqb8bd3zrux34I4Ejl0yOiSinlbPz3AfwYwGER6UruewLAZhFZhbF2XA+An+SSYYm6u7vNuNeau/POO834k08+mRrz2jRNTU1m3FsW2WtBtbe3p8Yefvhhc1uv5Xj9+nUzvnz5cjNuLbtsTTMNAHv27DHjU6bYxyqrXertc29q8XvuuceMW8tFA8Cbb75pxvNQytn4/QAmGpRcWE+diG4cr6AjCoLFThQEi50oCBY7URAsdqIgWOxEQUg1l44VkeqvU5tYv369GV+7dq0Zf/rpp1Nj3jTU9P+P12fftm2bGd+/f78Zf+GFF244p1Kp6oTzd/PIThQEi50oCBY7URAsdqIgWOxEQbDYiYJgsRMFUe0++2kAJ8bd1QzAHlhcnFrNrVbzAphbuSqZ2y2qOuHc41Ut9m89ucihWp2brlZzq9W8AOZWrmrlxrfxREGw2ImCKLrYOwt+fkut5lareQHMrVxVya3Qz+xEVD1FH9mJqEpY7ERBFFLsIvKgiHwsIsdE5PEickgjIj0iclhEuopeny5ZQ29QRI6Mu69RRPaKyNHk+4Rr7BWU21Mi0pvsuy4R2VBQbm0i8hcR+UBEukXk58n9he47I6+q7Leqf2YXkakAPgHwAIBTAN4GsFlVP6hqIilEpAfAalUt/AIMEfl7AMMA/qCqdyT3/SuAs6r6bPIf5QJV/ecaye0pAMNFL+OdrFbUOn6ZcQCPAPhHFLjvjLweRRX2WxFH9jUAjqnqcVW9CuBPADYWkEfNU9U3AHxzSZWNALYnt7dj7I+l6lJyqwmq2qeq7ya3hwB8vcx4ofvOyKsqiij2xQBOjvv3KdTWeu8KYI+IvCMiHUUnM4EWVe1LbvcDaCkymQm4y3hX0zeWGa+ZfVfO8udZ8QTdt61V1bsBrAfw0+Ttak3Ssc9gtdQ7LWkZ72qZYJnxvypy35W7/HlWRRR7L4C2cf/+TnJfTVDV3uT7IIBXUHtLUQ98vYJu8n2w4Hz+qpaW8Z5omXHUwL4rcvnzIor9bQDtIvJdEZkB4EcAdhWQx7eIyJzkxAlEZA6AH6D2lqLeBWBLcnsLgFcLzOVv1Moy3mnLjKPgfVf48ueqWvUvABswdkb+fwE8WUQOKXndCuB/kq/uonMD8DLG3taNYOzcxmMAmgDsA3AUwH8DaKyh3P4TwGEA72OssFoLym0txt6ivw+gK/naUPS+M/Kqyn7j5bJEQfAEHVEQLHaiIFjsREGw2ImCYLETBcFiJwqCxU4UxP8BsslT7Ehy+dEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2 starts**"
      ],
      "metadata": {
        "id": "Ni3O_BhnZaTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "qiVcaMR7V-sX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640c6a07-ae62-4d6d-eda6-00aa55082b3d"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdGRoHZQgVVI",
        "outputId": "2aecd3dc-ae5f-41b7-e40e-4954f18c5fdc"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten each image into a 1-d array to input to the network"
      ],
      "metadata": {
        "id": "YKQrN4fNiuy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)"
      ],
      "metadata": {
        "id": "k5yzGo1ng9n1"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalise the array to [0,1] interval"
      ],
      "metadata": {
        "id": "OIHk2sEwfOTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train = x_train + 1\n",
        "# x_test = x_test + 1\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "metadata": {
        "id": "tGjhIWq1fUhf"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz62n2oYirjJ",
        "outputId": "556eb8dc-2df9-4798-c956-9f76327b01c6"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaK-eQ1litfw",
        "outputId": "ad8fae18-ac18-45a3-eba3-df9ab46ee288"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical encoding for labels"
      ],
      "metadata": {
        "id": "lspua0Nui5xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "num_categories = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
        "y_test = keras.utils.to_categorical(y_test, num_categories)"
      ],
      "metadata": {
        "id": "pL7JqMSdhIos"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTD9Syza4m-M",
        "outputId": "bc760b97-bce4-46c4-c0ef-c7bddf92215c"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40wZGQrf4pSd",
        "outputId": "3383040b-0c16-47bd-a456-faff01bcf12c"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zUtb8_A5IZG",
        "outputId": "1ba471cf-e93e-43e1-dd14-951d846e313c"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Activation().computeReluGrad(np.array([100,-5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRALWu5uhrGK",
        "outputId": "e9a61339-0fac-441c-d1ce-79aaca7c75e4"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation:\n",
        "    def computeSoftmaxGrad(self,H):\n",
        "      grad_softmax_jacobian = np.zeros(H.shape[0]*H.shape[0]).reshape(H.shape[0],H.shape[0])\n",
        "      for i in range(H.shape[0]):\n",
        "        for j in range(H.shape[0]):\n",
        "          if(i == j):\n",
        "            grad_softmax_jacobian[i][j] = H[i]*(1-H[j])\n",
        "          else:\n",
        "            grad_softmax_jacobian[i][j] = -H[i]*H[j]\n",
        "      return grad_softmax_jacobian\n",
        "  \n",
        "    def computeSigmoidGrad(self,H):\n",
        "      # print(\"Grad Sigmoid \",H)\n",
        "      # print(\"number of non-zeros in H:\",np.count_nonzero(H))\n",
        "      ret = H*(1-H)\n",
        "      # print(\"Ret \",ret)\n",
        "      # print(\"number of non-zeros in ret:\",np.count_nonzero(ret))\n",
        "      return ret \n",
        "\n",
        "    def computeTanhGrad(self,H):\n",
        "      ret = 1 - H**2\n",
        "      if(~(np.isfinite(ret).all())):\n",
        "        if(np.isnan(ret).any()):\n",
        "          print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
        "          print(\"Gradient Tanh ret\",ret)\n",
        "        ret = replaceNanWithMaxAndMin(ret)\n",
        "      return ret \n",
        "    \n",
        "    def computeReluGrad(self,A):\n",
        "       return 1.0 * (A > 0)\n",
        "\n",
        "    def sigmoid(self, X):\n",
        "      # print(\"Sigmoid\",X)\n",
        "      exp = np.exp(-X)\n",
        "      # print(\"Exp:\",exp)\n",
        "      if(~(np.isfinite(exp).all())):\n",
        "        if(np.isnan(exp).any()):\n",
        "          print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
        "          print(\"Sigmoid X\",X)\n",
        "          print(\"Sigmoid exp before\",exp)\n",
        "        exp = replaceNanWithMaxAndMin(exp)\n",
        "      \n",
        "      ret = 1.0 / (1.0 + exp)\n",
        "      # print(\"Ret sigmoid:\",ret)\n",
        "      return ret\n",
        "\n",
        "    def relu(self,X):\n",
        "      ret = np.maximum(0.0,X)\n",
        "      return ret\n",
        "    \n",
        "    def tanh(self,X):\n",
        "      ret = np.tanh(X)\n",
        "      if(~(np.isfinite(ret).all())):\n",
        "        if(np.isnan(ret).any()):\n",
        "          print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
        "          print(\"Tanh ret\",ret)\n",
        "        ret = replaceNanWithMaxAndMin(ret)\n",
        "      return ret\n",
        "\n",
        "    def softmax(self, X):\n",
        "      Z = X-max(X)\n",
        "      exps = np.exp(Z)\n",
        "      if(~(np.isfinite(exps).all())):\n",
        "        if(np.isnan(exps).any()):\n",
        "          print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
        "          print(\"softmax X\",X)\n",
        "          print(\"softmax exps\",exps)\n",
        "        exps = replaceNanWithMaxAndMin(exps)\n",
        "      \n",
        "      sum = np.sum(exps)\n",
        "      if(~(np.isfinite(sum).all())):\n",
        "        if(np.isnan(sum).any()):\n",
        "          print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
        "          print(\"softmax sum\",sum)\n",
        "        sum = replaceNanWithMaxAndMin(sum)\n",
        "\n",
        "      ret = exps / sum\n",
        "      if(~(np.isfinite(ret).all())):\n",
        "        if(np.isnan(ret).any()):\n",
        "          print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
        "          print(\"softmax exps\",exps)\n",
        "          print(\"softmax sum\",sum)\n",
        "          print(\"softmax ret\",ret)\n",
        "        ret = replaceNanWithMaxAndMin(ret)\n",
        "\n",
        "      if(~(np.isfinite(ret).all())):\n",
        "          print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
        "          print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
        "          print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
        "          print(\"softmax X\",X)\n",
        "          print(\"softmax np.sum(exps)\",np.sum(exps))\n",
        "          print(\"softmax exps\",exps)\n",
        "      return ret"
      ],
      "metadata": {
        "id": "CEe2B3JRpLzW"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def replaceNanWithMaxAndMin(X):\n",
        "    if(np.isscalar(X)):\n",
        "      if(X == float(\"inf\")):\n",
        "          X = 1e+306\n",
        "      elif(X == float(\"-inf\")):\n",
        "          X = 1e-306\n",
        "      else:\n",
        "        X = 1e-306\n",
        "    else:\n",
        "      if(~(np.isfinite(X).all())):\n",
        "        nan_indices = np.argwhere(~(np.isfinite(X))).flatten()\n",
        "        # print(\"nan_indices\",nan_indices)\n",
        "        for ind in nan_indices:\n",
        "          # print(\"Ind\",ind)\n",
        "          # print(\"X[ind]\",X[ind])\n",
        "          if(X[ind] == float(\"inf\")):\n",
        "            X[ind] = 1e+306\n",
        "          elif(X[ind] == float(\"-inf\")):\n",
        "            X[ind] = 1e-306\n",
        "          else:\n",
        "            X[ind] = 1e-306\n",
        "    return X\n",
        "      "
      ],
      "metadata": {
        "id": "nAKowVdj8BWb"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InputLayer:\n",
        "  number_of_inputs=0\n",
        "\n",
        "  def __init__(self,number_of_inputs) -> None:\n",
        "      self.number_of_inputs = number_of_inputs"
      ],
      "metadata": {
        "id": "kqlkEUzksmv6"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "  number_of_neurons=0\n",
        "  activation = 'sigmoid'\n",
        "  \n",
        "  def __init__(self,number_of_neurons,activation) -> None:\n",
        "      self.number_of_neurons = number_of_neurons\n",
        "      self.activation = activation"
      ],
      "metadata": {
        "id": "Z0JrCQg4qdnn"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ANNModel:\n",
        "  def __init__(self):\n",
        "    self.layers = []\n",
        "\n",
        "  def addInputLayer(self,input_layer_obj):\n",
        "    self.input_layer_obj = input_layer_obj\n",
        "  \n",
        "  def addLayer(self,layer_obj):\n",
        "    self.layers.append(layer_obj)\n",
        "  \n",
        "  def compile(self,loss):\n",
        "    self.loss = loss\n",
        "    self.randInitWeights()\n",
        "    self.randInitBiases()\n",
        "    self.initAH()\n",
        "    self.array_grad_L_by_A = [None]*(len(self.layers))\n",
        "    self.array_grad_L_by_weight = [None]*(len(self.layers))\n",
        "    self.array_grad_L_by_bias = [None]*(len(self.layers))\n",
        "    self.array_grad_L_by_H = [None]*(len(self.layers))\n",
        "    \n",
        "  def initAH(self):\n",
        "    self.A = []\n",
        "    for l in range(len(self.layers)):\n",
        "      self.A.append(np.zeros(self.layers[l].number_of_neurons))\n",
        "    \n",
        "    self.H = []\n",
        "    self.H.append(np.zeros(self.input_layer_obj.number_of_inputs))\n",
        "    for l in range(1,len(self.layers)+1):\n",
        "      self.H.append(np.zeros(self.layers[l-1].number_of_neurons))\n",
        "    \n",
        "    # print(self.A)\n",
        "    # print(self.H)\n",
        "\n",
        "  def randInitWeights(self):\n",
        "    self.weight_array=[np.random.normal(size=(self.input_layer_obj.number_of_inputs,self.layers[0].number_of_neurons))]\n",
        "    # print(self.weight_array)\n",
        "    # print(self.weight_array[0].shape)\n",
        "    for l in range(1,len(self.layers)):\n",
        "      self.weight_array.append(np.random.normal(size=(self.layers[l-1].number_of_neurons,self.layers[l].number_of_neurons)))\n",
        "    #   print(self.weight_array[l].shape)\n",
        "    # print(self.weight_array)\n",
        "    # print(len(self.weight_array))\n",
        "\n",
        "  def randInitBiases(self):\n",
        "    self.bias = []\n",
        "    for l in range(len(self.layers)):\n",
        "      self.bias.append(np.random.rand(self.layers[l].number_of_neurons))\n",
        "      # print(self.bias)\n",
        "      # print(self.bias[l].shape)\n",
        "\n",
        "  def predict(self,x_test):\n",
        "    y_pred = [None]*x_test.shape[0]\n",
        "    for index in range(x_test.shape[0]):\n",
        "      y_pred[index] = self.feed_forward(x_test[index])\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    return y_pred\n",
        "  \n",
        "  def initializeOptimizerStructures(self,optimizer='vanilla'):\n",
        "    if(optimizer == 'momentum'):\n",
        "      self.prev_weight_update=[np.zeros((self.input_layer_obj.number_of_inputs,self.layers[0].number_of_neurons))]\n",
        "      for l in range(1,len(self.layers)):\n",
        "        self.prev_weight_update.append(np.zeros((self.layers[l-1].number_of_neurons,self.layers[l].number_of_neurons)))\n",
        "      \n",
        "      self.prev_bias_update = []\n",
        "      for l in range(len(self.layers)):\n",
        "       self.prev_bias_update.append(np.zeros(self.layers[l].number_of_neurons))\n",
        "  \n",
        "  # x_valid and y_valid is used only to just check test accuracy during each epoch. It is strictly not part of training\n",
        "  def train(self,x_train,y_train,epochs,optimizer='vanilla',learning_rate=1,verbose=1,x_valid=None,y_valid=None):\n",
        "    self.initializeOptimizerStructures(optimizer)\n",
        "    self.verbose=verbose\n",
        "    if(self.verbose >= 4):\n",
        "      self.print_state()\n",
        "    for current_epoch in range(epochs):\n",
        "      if(self.verbose >=2):\n",
        "        print(\"\\n &&&&&&&&&&&&&&&&&&&&  Epoch \",current_epoch,\" &&&&&&&&&&&&&&&&&&&&&&&&\")\n",
        "      sum_of_loss = 0\n",
        "      for index in tqdm(range(10)):\n",
        "      # for index in tqdm(range(x_train.shape[0])):\n",
        "        if(self.verbose >= 3):\n",
        "          print(\"Data point number:\",index)\n",
        "        y_pred = self.feed_forward(x_train[index])\n",
        "        self.back_prop(y_pred,y_train[index])\n",
        "        self.updateParameters(optimizer,learning_rate)\n",
        "        if(self.verbose >= 3):\n",
        "          print(\"Predicted output:\",y_pred)\n",
        "          print(\"Actual output:\",y_train[index])\n",
        "        current_loss = computeLoss(y_pred,y_train[index],self.loss)\n",
        "        sum_of_loss = sum_of_loss + current_loss\n",
        "        if(self.verbose >= 4):\n",
        "          self.print_state()\n",
        "        if(self.verbose >= 3):\n",
        "          print(\"Loss:\",current_loss)\n",
        "      \n",
        "      if(self.verbose >= 2):\n",
        "        print(\"Average \",self.loss, \" loss: \",(sum_of_loss/x_train.shape[0]))\n",
        "        self.showTrainAndTestAccuracyPostTraining(x_train,y_train,x_valid,y_valid)\n",
        "  \n",
        "  def showTrainAndTestAccuracyPostTraining(self,x_train,y_train,x_valid,y_valid):\n",
        "    y_pred_train = self.predict(x_train)\n",
        "    train_accuracy = calculateClassificationAccuracy(y_pred_train,y_train)\n",
        "    print(\"Train accuracy \",train_accuracy)\n",
        "    if(not(x_valid is None or y_valid is None)):\n",
        "      y_pred_test = self.predict(x_valid)\n",
        "      test_accuracy = calculateClassificationAccuracy(y_pred_test,y_valid)\n",
        "      print(\"Test accuracy \",test_accuracy)\n",
        "\n",
        "  def updateParameters(self,optimizer='vanilla',learning_rate=1):\n",
        "    if(optimizer == 'vanilla'):\n",
        "      for l in range(len(self.layers)):\n",
        "        self.weight_array[l] = self.weight_array[l] - (learning_rate)*self.array_grad_L_by_weight[l]\n",
        "        self.bias[l]=(self.bias[l] - (learning_rate)*self.array_grad_L_by_bias[l])[0]\n",
        "    elif(optimizer == 'momentum'):\n",
        "      gamma = 0.9\n",
        "\n",
        "      for l in range(len(self.layers)):\n",
        "        self.prev_weight_update[l] = gamma * self.prev_weight_update[l] + (learning_rate)* self.array_grad_L_by_weight[l]\n",
        "        self.prev_bias_update[l] = (gamma * self.prev_bias_update[l] + (learning_rate)* self.array_grad_L_by_bias[l])[0]  \n",
        "        self.weight_array[l] = self.weight_array[l] - self.prev_weight_update[l]\n",
        "        self.bias[l]=self.bias[l] - self.prev_bias_update[l]\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "\n",
        "  def feed_forward(self,inpX):\n",
        "    self.H[0]= inpX\n",
        "    for l in range(len(self.layers)):\n",
        "      self.A[l]=np.matmul(self.H[l],self.weight_array[l]) + self.bias[l]\n",
        "      self.H[l+1] = calculateActivation(self.layers[l].activation,self.A[l])\n",
        "    return self.H[len(self.layers)]\n",
        "  \n",
        "  def back_prop(self,y_pred,y_train):\n",
        "    if(self.verbose >= 5):\n",
        "      print(\"Back prop starts ===========================\")\n",
        "    self.grad_L_by_ypred = computeLossGradient(y_pred,y_train,self.loss)\n",
        "    self.grad_ypred_by_Aoutput = computeGradientHwrtA(y_pred,self.A[len(self.layers)-1],self.layers[len(self.layers)-1].activation)\n",
        "    if(len(self.grad_ypred_by_Aoutput.shape)==2):\n",
        "      self.array_grad_L_by_A[len(self.layers)-1]=np.matmul(self.grad_L_by_ypred,self.grad_ypred_by_Aoutput)\n",
        "    else:\n",
        "      self.array_grad_L_by_A[len(self.layers)-1]=np.multiply(self.grad_L_by_ypred,self.grad_ypred_by_Aoutput)\n",
        "    \n",
        "    for l in reversed(range(len(self.layers))):\n",
        "      current_H=self.H[l]\n",
        "      current_H=current_H[np.newaxis].T\n",
        "      if(self.verbose >= 5):\n",
        "        print(\"current_H:[\",l,\"]:\",current_H.T)\n",
        "        print(\"current_H shape:[\",l,\"]:\",current_H.shape)\n",
        "      current_grad_L_by_A = self.array_grad_L_by_A[l]\n",
        "      if(len(current_grad_L_by_A.shape)==1):\n",
        "        current_grad_L_by_A = current_grad_L_by_A[np.newaxis]\n",
        "      \n",
        "      if(self.verbose >= 5):\n",
        "        print(\"current_grad_L_by_A[\",l,\" ]:\",current_grad_L_by_A)\n",
        "        print(\"current_grad_L_by_A[\",l,\" ] shape:\",current_grad_L_by_A.shape)\n",
        "      \n",
        "      self.array_grad_L_by_weight[l]=np.matmul(current_H,current_grad_L_by_A)\n",
        "      \n",
        "      if(self.verbose >= 5):\n",
        "        print(\"self.array_grad_L_by_weight[\",l,\"]:\",self.array_grad_L_by_weight[l])\n",
        "        print(\"number of non-zeros in weight gradient:\",np.count_nonzero(self.array_grad_L_by_weight[l]))\n",
        "      \n",
        "      allzeros = not np.any(self.array_grad_L_by_weight[l])\n",
        "      if(allzeros == True):\n",
        "        self.verbose=5\n",
        "        print(\"Weight update zero %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
        "      \n",
        "      self.array_grad_L_by_bias[l] = current_grad_L_by_A\n",
        "      \n",
        "      if(self.verbose >= 5):\n",
        "        print(\"self.array_grad_L_by_bias[\",l,\"]:\",self.array_grad_L_by_bias[l])\n",
        "      \n",
        "      self.array_grad_L_by_H[l] = np.matmul(self.weight_array[l],current_grad_L_by_A.T)\n",
        "      \n",
        "      # if(self.verbose >= 5):\n",
        "      #   print(\"self.array_grad_L_by_H[\",l,\"]:\",self.array_grad_L_by_H[l].T)\n",
        "      \n",
        "      if(l >= 1):\n",
        "        current_grad_H_by_A = computeGradientHwrtA(self.H[l],self.A[l-1],self.layers[l-1].activation)\n",
        "        current_grad_H_by_A = current_grad_H_by_A[np.newaxis]\n",
        "        if(self.verbose >= 5):\n",
        "          print(\"current_grad_H_by_A[\",l,\"]:\",current_grad_H_by_A)\n",
        "        self.array_grad_L_by_A[l-1] = np.multiply(self.array_grad_L_by_H[l].T,current_grad_H_by_A)\n",
        "        if(self.verbose >= 5):\n",
        "          print(\"self.array_grad_L_by_A[\",(l-1),\"]:\",self.array_grad_L_by_A[l-1])\n",
        "\n",
        "\n",
        "\n",
        "  def print_state(self):\n",
        "    for l in range(len(self.layers)):\n",
        "      print(\"Layer\",l)\n",
        "      print(\"============================\")\n",
        "      print(\"Activation:\",self.layers[l].activation)\n",
        "      print(\"Number of units:\",self.layers[l].number_of_neurons)\n",
        "      print(\"Weights\",self.weight_array[l])\n",
        "      print(\"Biases\",self.bias[l])\n",
        "      # print(\"H's [ \",l,\" ]:\",self.H[l])\n",
        "      print(\"A's\",self.A[l])\n",
        "      print(\"**************************\")"
      ],
      "metadata": {
        "id": "4TKfIP47ijGu"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateClassificationAccuracy(y_pred,y_actual):\n",
        "  total_samples = y_pred.shape[0]\n",
        "  correctly_classified_count = 0.0\n",
        "  for it in range(y_pred.shape[0]):\n",
        "    classification_index = np.argmax(y_pred[it])\n",
        "    if(y_actual[it][classification_index]== 1):\n",
        "      correctly_classified_count= correctly_classified_count + 1\n",
        "  accuracy = correctly_classified_count/total_samples\n",
        "  print(\"Correctly classified:\",correctly_classified_count)\n",
        "  print(\"total_samples:\",total_samples)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "2Y_VeP9ORLR2"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateActivation(activation,A):\n",
        "  if(activation =='sigmoid'):\n",
        "    return Activation().sigmoid(A)\n",
        "  elif(activation == 'softmax'):\n",
        "    return Activation().softmax(A)\n",
        "  elif(activation == 'tanh'):\n",
        "    return Activation().tanh(A)\n",
        "  elif(activation == 'relu'):\n",
        "    return Activation().relu(A)\n",
        "  else:\n",
        "    print(\"Invalid activation function\")\n",
        "\n",
        "def computeLoss(y_pred,y_actual,loss):\n",
        "  loss_value=0\n",
        "  if(loss=='categorical_crossentropy'):\n",
        "    # This small epsilon is needed to avoid log(0)=undefined\n",
        "    epsilon = 1e-300\n",
        "    # To hold label index from y_actual\n",
        "    correct_index=findLabelIndex(y_actual)\n",
        "    loss_value = -math.log(np.maximum(y_pred[correct_index],epsilon),2)\n",
        "    # loss_value = -np.log2(((y_pred[correct_index])+epsilon))\n",
        "  return loss_value\n",
        "\n",
        "def computeLossGradient(y_pred,y_actual,loss):\n",
        "  grad_L_y = np.zeros(len(y_pred))\n",
        "  if(loss=='categorical_crossentropy'):\n",
        "    # This small epsilon is needed to avoid 1/0=inf\n",
        "    epsilon = 1e-300\n",
        "    # To hold label index from y_actual\n",
        "    correct_index=findLabelIndex(y_actual)\n",
        "    grad_L_y[correct_index] = -1/(np.maximum(y_pred[correct_index],epsilon))\n",
        "  \n",
        "  return grad_L_y\n",
        "\n",
        "def findLabelIndex(y_actual):\n",
        "  for j in range(len(y_actual)):\n",
        "    if(y_actual[j]==1):\n",
        "      return j\n",
        "\n",
        "def computeGradientHwrtA(H,A,activation):\n",
        "  grad_H_by_A = []\n",
        "  # Gradient is a kxk jacobian\n",
        "  if(activation == 'softmax'):\n",
        "    grad_H_by_A = Activation().computeSoftmaxGrad(H)\n",
        "  elif(activation == 'sigmoid'):\n",
        "    grad_H_by_A = Activation().computeSigmoidGrad(H)\n",
        "  elif(activation == 'tanh'):\n",
        "    grad_H_by_A = Activation().computeTanhGrad(H)\n",
        "  elif(activation == 'relu'):\n",
        "    grad_H_by_A = Activation().computeReluGrad(H)\n",
        "  return grad_H_by_A\n"
      ],
      "metadata": {
        "id": "J-Eyf5NShTFT"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def runToyTest():\n",
        "  ann_model = ANNModel()\n",
        "  input_layer = InputLayer(2)\n",
        "  hidden_layer1 = Layer(5,activation='sigmoid')\n",
        "  hidden_layer2 = Layer(10,activation='sigmoid')\n",
        "  output_layer = Layer(4,activation='softmax')\n",
        "\n",
        "  ann_model.addInputLayer(input_layer)\n",
        "  ann_model.addLayer(hidden_layer1)\n",
        "  # ann_model.addLayer(hidden_layer2)\n",
        "  ann_model.addLayer(output_layer)\n",
        "\n",
        "  ann_model.compile('categorical_crossentropy')\n",
        "  ann_model.train(sample_xtrain,sample_ytrain,1,'momentum',1,4)\n",
        "  # ann_model.print_state()\n",
        "  y_pred_test = ann_model.predict(sample_xtrain)\n",
        "  print(y_pred_test)\n",
        "  test_accuracy = calculateClassificationAccuracy(y_pred_test,sample_ytrain)\n",
        "  print(\"Test Accuracy:\",test_accuracy)"
      ],
      "metadata": {
        "id": "SsI2dEwpxU--"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# runToyTest()"
      ],
      "metadata": {
        "id": "YOz6Av2Qxe2Q"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.seterr(all='warn')\n",
        "ann_model = ANNModel()\n",
        "input_layer = InputLayer(x_train.shape[1])\n",
        "hidden_layer1 = Layer(64,activation='sigmoid')\n",
        "hidden_layer2 = Layer(10,activation='tanh')\n",
        "hidden_layer3 = Layer(32,activation='relu')\n",
        "output_layer = Layer(10,activation='softmax')\n",
        "\n",
        "ann_model.addInputLayer(input_layer)\n",
        "# ann_model.addLayer(hidden_layer1)\n",
        "# ann_model.addLayer(hidden_layer2)\n",
        "ann_model.addLayer(hidden_layer3)\n",
        "ann_model.addLayer(output_layer)\n",
        "\n",
        "ann_model.compile('categorical_crossentropy')\n",
        "ann_model.train(x_train,y_train,1,\"momentum\",0.1,5,x_test,y_test)\n",
        "# ann_model.print_state()\n",
        "y_pred_test = ann_model.predict(x_test)\n",
        "test_accuracy = calculateClassificationAccuracy(y_pred_test,y_test)\n",
        "print(\"Test accuracy at end:\",test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "aa8dc5dbb6294beeb0a4960908a387b8",
            "4a7d25b195d04a2db15af0dc68d14575",
            "412676d3cf9546d08d9c5ba192ed476e",
            "d72729632cb14cc18e866669ed304c4a",
            "f56992e773734ac1b9f97164416dd602",
            "7b09061c36f5489a88840c3615c5b53f",
            "f5055c28866c418cb219ea70501c55ef",
            "d2e022780edc4955a28e86db0d646b0a",
            "ffa628075321491685286a678ede4c93",
            "3543361b867140d4990954e1be01017f",
            "d4d3252944934d7b81a9ff6b797890d7"
          ]
        },
        "id": "MqcfAefoqcty",
        "outputId": "23fe6de4-2f9a-493d-93af-b2c571ab7f66"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n",
            "Biases [0.73690705 0.42796968 0.5522685  0.81376714 0.98261353 0.81738447\n",
            " 0.83994874 0.68813938 0.41215904 0.49585371 0.41275672 0.51312683\n",
            " 0.45157875 0.02501608 0.53425787 0.56508585 0.40744959 0.24587539\n",
            " 0.78152873 0.64635273 0.3383225  0.83934688 0.05278587 0.33130372\n",
            " 0.79193843 0.48510933 0.19969615 0.28992577 0.83813795 0.57247313\n",
            " 0.57434252 0.22424953]\n",
            "A's [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 0.02486971  2.46523039 -0.89701457 -0.00406045 -0.66953299 -1.94642287\n",
            "   0.17622831 -0.30321011  0.74185169  1.26453163]\n",
            " [ 1.45202164  1.05731147 -0.26526813  0.71298223  0.11633998  1.34039607\n",
            "  -0.72026458  0.536021   -0.1147328  -0.85238334]\n",
            " [ 0.19940426 -0.93157851 -1.28533239 -0.75092915 -0.25216599 -0.81523568\n",
            "  -1.45862209  0.04461023  1.01582961 -0.46790005]\n",
            " [ 0.02852031  0.20440974  1.59754677  0.56840898  2.51397538  0.93449606\n",
            "   0.83088503  0.19360052 -0.52808687  0.32855402]\n",
            " [ 0.56485443  0.59445809 -1.69647492  0.61153035  0.45203847 -0.51058193\n",
            "   0.14776303  0.85263285  0.61401368  1.1441531 ]\n",
            " [ 1.60933497  0.66410306  0.7775757  -0.00943842  0.1616238   0.84501642\n",
            "  -0.14069216  1.0495381   1.21544638  0.50684308]\n",
            " [ 1.73782607  0.2821797   0.27023143 -1.27763898 -0.25939202  1.0520684\n",
            "   0.67083626 -0.44026176  0.55905452  0.08487246]\n",
            " [ 1.43882626  0.73926027 -1.48315104  0.38721164 -1.83417412 -1.39587437\n",
            "   2.08574814  2.12492358  0.63153749  1.78827276]\n",
            " [ 1.36135882 -1.24683987 -0.28057126  0.01333576 -0.68156831  0.76613861\n",
            "  -2.2865673  -1.05911023  0.67012474  2.07277217]\n",
            " [ 0.84167083  0.07115869 -0.30014327 -1.88102474 -2.05799275  0.12142546\n",
            "  -0.08130369 -0.88103138  1.1325719   0.14083608]\n",
            " [-0.15023084  1.03930763  0.7291683   1.0262029  -1.09021236  0.27526408\n",
            "  -0.19673703  1.68387065 -1.1225331   0.00689092]\n",
            " [-1.73676242  0.39919869 -1.52415861 -0.55366246 -0.69530452  0.18054354\n",
            "  -0.33766861 -1.28131826  0.05898181  0.75676224]\n",
            " [ 0.73956874 -0.46902191 -0.41205808 -0.45992392  0.11231659 -0.96794387\n",
            "   0.60702528 -0.54033737 -0.6607981   0.28037989]\n",
            " [ 0.45710512  0.84246858  1.92183715 -0.40057712  1.20509059  0.11472622\n",
            "  -0.32686671  1.14392147  0.72884546  0.04679561]\n",
            " [-1.2021908   0.67689264 -0.94291231  1.33328936 -0.27574651 -0.03449987\n",
            "   1.49006107 -0.08142865 -0.01167482 -0.1696141 ]\n",
            " [-0.19605701  0.16759149 -0.44654897  1.57364207  0.71283608  0.84103131\n",
            "  -0.69375819 -1.13758541 -0.12143217  0.43217995]\n",
            " [-1.87205504  0.15396864  0.00715297  0.68425244 -1.04532001  0.84917234\n",
            "  -0.42099343 -0.44808443 -0.01581228  0.66798167]\n",
            " [ 0.63468307  1.84482447  0.34956419 -0.52041262  0.1672082  -2.03435087\n",
            "   1.31231916 -0.02957268  1.90631102  0.73117577]\n",
            " [ 1.3930949   0.55640313  0.16030895  0.70382998 -1.06670368 -0.88535136\n",
            "  -0.28052922 -0.8776164   0.82686335 -1.67612503]\n",
            " [-1.63710912 -1.09585299 -0.10810315 -0.15576554 -1.16267201 -0.65311163\n",
            "  -0.85737389 -0.46716968  0.03114076  0.62599495]\n",
            " [-0.1467437  -0.94367311  1.65475333  0.84909942  0.77126441 -2.21848462\n",
            "  -0.11469189  1.33975112 -0.11843857 -0.00683069]\n",
            " [ 1.15483391  0.43446433  0.39329007 -0.10853948 -0.65833489 -0.37490774\n",
            "  -0.14161155  1.29862515 -0.61554061 -1.83201023]\n",
            " [ 0.68414485 -1.43595713 -1.04511258 -0.48202756 -1.23161507 -1.352923\n",
            "   0.67843308  0.21326907 -1.3137253  -1.40888345]\n",
            " [-0.75846623 -0.78220337  0.21034988  1.10359682  1.24189986 -0.30412354\n",
            "   0.8491469  -2.02661392  0.55068966  0.69516841]\n",
            " [-1.07118177  0.76543446  1.58340823  1.66858562  0.41632777  0.08657977\n",
            "  -0.77724997  1.16988627  0.72385902  2.0493148 ]\n",
            " [ 0.32838711 -2.28986326  0.15917115  1.97732032  1.41118835 -0.78147465\n",
            "   0.01592791 -0.51826717 -0.58312659 -0.67936502]\n",
            " [ 0.35362674 -1.15211746 -1.12159934  0.27198168  1.40136595 -0.42754978\n",
            "  -0.28471013  0.3254941  -1.23769283  0.82997527]\n",
            " [-0.67280755 -1.39539147  0.05310319  1.07934849  1.95042188  0.78023984\n",
            "   0.67784875  1.43402964 -0.1197567   1.51230093]\n",
            " [ 0.08108198 -0.09907129  0.4478459   0.42657239 -0.32265361  0.85516149\n",
            "  -1.45797387  0.23397283 -0.50143702 -0.69362195]\n",
            " [ 0.38221867 -0.0695748  -0.32446705  1.36236839  2.0734625  -0.04259274\n",
            "  -0.22708557  1.43743222 -0.25119683 -1.12825308]\n",
            " [-0.78002152 -0.22698913 -0.32727231  1.12507331  0.41477926 -1.13569562\n",
            "   1.31769772  0.58103166  1.35488671  1.29482924]\n",
            " [ 0.72260728  0.6880381   0.54853488 -0.15671519  0.30025416 -0.7022573\n",
            "   0.71593046 -0.70757154  1.1243482  -0.76365316]]\n",
            "Biases [0.88871364 0.70190615 0.41362187 0.80268521 0.06611734 0.00692364\n",
            " 0.31411998 0.05465222 0.84911997 0.97275652]\n",
            "A's [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "**************************\n",
            "\n",
            " &&&&&&&&&&&&&&&&&&&&  Epoch  0  &&&&&&&&&&&&&&&&&&&&&&&&\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa8dc5dbb6294beeb0a4960908a387b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data point number: 0\n",
            "Back prop starts ===========================\n",
            "current_H:[ 1 ]: [[ 0.          0.          3.21146683  8.35034807 21.85091652  0.\n",
            "   0.          7.84625325 16.27492608  0.          0.          0.\n",
            "   6.92920188  0.          8.00554901  0.          0.          3.84018615\n",
            "   0.         13.91844021  6.53597882 27.31114145  0.24188582  4.84476784\n",
            "  20.36125684  0.          0.          2.75849123  0.          8.82325594\n",
            "   9.44095118  0.        ]]\n",
            "current_H shape:[ 1 ]: (32, 1)\n",
            "current_grad_L_by_A[ 1  ]: [[ 1.45817797e-30  4.20318675e-39  1.54001375e-42  7.14946212e-01\n",
            "   5.39277355e-33  4.03970460e-67  2.28000472e-44  2.12180640e-01\n",
            "   5.18727124e-22 -9.27126852e-01]]\n",
            "current_grad_L_by_A[ 1  ] shape: (1, 10)\n",
            "self.array_grad_L_by_weight[ 1 ]: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 4.68289016e-30  1.34983948e-38  4.94570305e-42  2.29602604e+00\n",
            "   1.73187133e-32  1.29733773e-66  7.32215952e-44  6.81411086e-01\n",
            "   1.66587495e-21 -2.97743713e+00]\n",
            " [ 1.21762936e-29  3.50980724e-38  1.28596508e-41  5.97004972e+00\n",
            "   4.50315362e-32  3.37329395e-66  1.90388330e-43  1.77178220e+00\n",
            "   4.33155204e-21 -7.74183192e+00]\n",
            " [ 3.18625250e-29  9.18434828e-38  3.36507118e-41  1.56222300e+01\n",
            "   1.17837045e-31  8.82712480e-66  4.98201928e-43  4.63634145e+00\n",
            "   1.13346631e-20 -2.02585715e+01]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 1.14412336e-29  3.29792677e-38  1.20833379e-41  5.60964904e+00\n",
            "   4.23130670e-32  3.16965454e-66  1.78894944e-43  1.66482304e+00\n",
            "   4.07006438e-21 -7.27447208e+00]\n",
            " [ 2.37317386e-29  6.84065537e-38  2.50636099e-41  1.16356968e+01\n",
            "   8.77669908e-32  6.57458938e-66  3.71069083e-43  3.45322423e+00\n",
            "   8.44224560e-21 -1.50889210e+01]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 1.01040095e-29  2.91247295e-38  1.06710661e-41  4.95400664e+00\n",
            "   3.73676166e-32  2.79919287e-66  1.57986130e-43  1.47024249e+00\n",
            "   3.59436496e-21 -6.42424912e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 1.16735152e-29  3.36488175e-38  1.23286555e-41  5.72353694e+00\n",
            "   4.31721129e-32  3.23400532e-66  1.82526895e-43  1.69862251e+00\n",
            "   4.15269541e-21 -7.42215945e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 5.59967483e-30  1.61410195e-38  5.91393946e-42  2.74552654e+00\n",
            "   2.07092543e-32  1.55132177e-66  8.75564255e-44  8.14813154e-01\n",
            "   1.99200872e-21 -3.56033970e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 2.02955628e-29  5.85018035e-38  2.14345892e-41  9.95093611e+00\n",
            "   7.50589962e-32  5.62263870e-66  3.17341094e-43  2.95322355e+00\n",
            "   7.21987246e-21 -1.29041597e+01]\n",
            " [ 9.53062031e-30  2.74719396e-38  1.00654972e-41  4.67287330e+00\n",
            "   3.52470537e-32  2.64034237e-66  1.49020626e-43  1.38680817e+00\n",
            "   3.39038950e-21 -6.05968147e+00]\n",
            " [ 3.98245047e-29  1.14793828e-37  4.20595332e-41  1.95259971e+01\n",
            "   1.47282801e-31  1.10328944e-65  6.22695314e-43  5.79489547e+00\n",
            "   1.41670299e-20 -2.53208926e+01]\n",
            " [ 3.52712577e-31  1.01669129e-39  3.72507492e-43  1.72935353e-01\n",
            "   1.30443547e-33  9.77147272e-68  5.51500818e-45  5.13234887e-02\n",
            "   1.25472737e-22 -2.24258842e-01]\n",
            " [ 7.06453371e-30  2.03634640e-38  7.46100906e-42  3.46374841e+00\n",
            "   2.61267358e-32  1.95714309e-66  1.10460935e-43  1.02796594e+00\n",
            "   2.51311249e-21 -4.49171435e+00]\n",
            " [ 2.96903361e-29  8.55821650e-38  3.13566154e-41  1.45572035e+01\n",
            "   1.09803647e-31  8.22534629e-66  4.64237617e-43  4.32026450e+00\n",
            "   1.05619362e-20 -1.88774680e+01]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 4.02237113e-30  1.15944538e-38  4.24811441e-42  1.97217285e+00\n",
            "   1.48759185e-32  1.11434897e-66  6.28937302e-44  5.85298433e-01\n",
            "   1.43090422e-21 -2.55747129e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 1.28658774e-29  3.70857925e-38  1.35879354e-41  6.30815342e+00\n",
            "   4.75818212e-32  3.56433476e-66  2.01170652e-43  1.87212409e+00\n",
            "   4.57686218e-21 -8.18027751e+00]\n",
            " [ 1.37665870e-29  3.96820809e-38  1.45391946e-41  6.74977228e+00\n",
            "   5.09129118e-32  3.81386539e-66  2.15254132e-43  2.00318706e+00\n",
            "   4.89727745e-21 -8.75295935e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]]\n",
            "number of non-zeros in weight gradient: 170\n",
            "self.array_grad_L_by_bias[ 1 ]: [[ 1.45817797e-30  4.20318675e-39  1.54001375e-42  7.14946212e-01\n",
            "   5.39277355e-33  4.03970460e-67  2.28000472e-44  2.12180640e-01\n",
            "   5.18727124e-22 -9.27126852e-01]]\n",
            "current_grad_H_by_A[ 1 ]: [[0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            "  1. 0. 0. 1. 0. 1. 1. 0.]]\n",
            "self.array_grad_L_by_A[ 0 ]: [[-0.          0.         -0.09360582  0.14284887 -0.44265157 -0.\n",
            "  -0.         -0.93025255 -2.13691107 -0.          0.         -0.\n",
            "  -0.70341771 -0.          1.09320638  0.         -0.         -1.05623446\n",
            "   0.         -0.79086507  0.89766258  1.8964491   1.00684147 -0.28550517\n",
            "  -0.45879859  0.         -0.         -0.32614535  0.          2.32504913\n",
            "  -0.27282039  0.        ]]\n",
            "current_H:[ 0 ]: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
            "  0.         0.00392157 0.01568627 0.         0.         0.\n",
            "  0.         0.00392157 0.00392157 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.01176471 0.\n",
            "  0.14117647 0.53333333 0.49803922 0.24313725 0.21176471 0.\n",
            "  0.         0.         0.00392157 0.01176471 0.01568627 0.\n",
            "  0.         0.01176471 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.02352941 0.         0.4        0.8\n",
            "  0.69019608 0.5254902  0.56470588 0.48235294 0.09019608 0.\n",
            "  0.         0.         0.         0.04705882 0.03921569 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
            "  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
            "  0.30196078 0.50980392 0.28235294 0.05882353 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.         0.27058824\n",
            "  0.81176471 0.8745098  0.85490196 0.84705882 0.84705882 0.63921569\n",
            "  0.49803922 0.4745098  0.47843137 0.57254902 0.55294118 0.34509804\n",
            "  0.6745098  0.25882353 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392\n",
            "  0.91372549 0.89803922 0.8745098  0.8745098  0.84313725 0.83529412\n",
            "  0.64313725 0.49803922 0.48235294 0.76862745 0.89803922 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
            "  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
            "  0.8745098  0.96078431 0.67843137 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.75686275\n",
            "  0.89411765 0.85490196 0.83529412 0.77647059 0.70588235 0.83137255\n",
            "  0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118\n",
            "  0.79215686 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255\n",
            "  0.85490196 0.75294118 0.6627451  0.89019608 0.81568627 0.85490196\n",
            "  0.87843137 0.83137255 0.88627451 0.77254902 0.81960784 0.20392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.02352941 0.\n",
            "  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
            "  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
            "  0.96078431 0.46666667 0.65490196 0.21960784 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.01568627 0.         0.         0.21568627 0.9254902\n",
            "  0.89411765 0.90196078 0.89411765 0.94117647 0.90980392 0.83529412\n",
            "  0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784\n",
            "  0.36078431 0.         0.         0.         0.00392157 0.01568627\n",
            "  0.02352941 0.02745098 0.00784314 0.         0.         0.\n",
            "  0.         0.         0.92941176 0.88627451 0.85098039 0.8745098\n",
            "  0.87058824 0.85882353 0.87058824 0.86666667 0.84705882 0.8745098\n",
            "  0.89803922 0.84313725 0.85490196 1.         0.30196078 0.\n",
            "  0.         0.01176471 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.24313725 0.56862745 0.8\n",
            "  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
            "  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
            "  0.87843137 0.95686275 0.62352941 0.         0.         0.\n",
            "  0.         0.         0.07058824 0.17254902 0.32156863 0.41960784\n",
            "  0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451\n",
            "  0.78431373 0.80392157 0.82745098 0.90196078 0.87843137 0.91764706\n",
            "  0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333\n",
            "  0.84313725 0.         0.         0.22352941 0.73333333 0.81568627\n",
            "  0.87843137 0.86666667 0.87843137 0.81568627 0.8        0.83921569\n",
            "  0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275\n",
            "  0.80784314 0.8745098  1.         1.         0.86666667 0.91764706\n",
            "  0.86666667 0.82745098 0.8627451  0.90980392 0.96470588 0.\n",
            "  0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
            "  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
            "  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
            "  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
            "  0.87058824 0.89411765 0.88235294 0.         0.38431373 0.91372549\n",
            "  0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706\n",
            "  0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804\n",
            "  0.25490196 0.28627451 0.41568627 0.45882353 0.65882353 0.85882353\n",
            "  0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137\n",
            "  0.89803922 0.11372549 0.29411765 0.8        0.83137255 0.8\n",
            "  0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902\n",
            "  0.77254902 0.80784314 0.77647059 0.83529412 0.94117647 0.76470588\n",
            "  0.89019608 0.96078431 0.9372549  0.8745098  0.85490196 0.83137255\n",
            "  0.81960784 0.87058824 0.8627451  0.86666667 0.90196078 0.2627451\n",
            "  0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
            "  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
            "  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
            "  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
            "  0.70980392 0.80392157 0.80784314 0.45098039 0.         0.47843137\n",
            "  0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745\n",
            "  0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941\n",
            "  0.78431373 0.76862745 0.76078431 0.74901961 0.76470588 0.74901961\n",
            "  0.77647059 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765\n",
            "  0.82352941 0.36078431 0.         0.         0.29019608 0.74117647\n",
            "  0.83137255 0.74901961 0.68627451 0.6745098  0.68627451 0.70980392\n",
            "  0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059\n",
            "  0.8        0.81960784 0.82352941 0.82352941 0.82745098 0.7372549\n",
            "  0.7372549  0.76078431 0.75294118 0.84705882 0.66666667 0.\n",
            "  0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
            "  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
            "  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
            "  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
            "  0.38823529 0.22745098 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.15686275\n",
            "  0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "current_H shape:[ 0 ]: (784, 1)\n",
            "current_grad_L_by_A[ 0  ]: [[-0.          0.         -0.09360582  0.14284887 -0.44265157 -0.\n",
            "  -0.         -0.93025255 -2.13691107 -0.          0.         -0.\n",
            "  -0.70341771 -0.          1.09320638  0.         -0.         -1.05623446\n",
            "   0.         -0.79086507  0.89766258  1.8964491   1.00684147 -0.28550517\n",
            "  -0.45879859  0.         -0.         -0.32614535  0.          2.32504913\n",
            "  -0.27282039  0.        ]]\n",
            "current_grad_L_by_A[ 0  ] shape: (1, 32)\n",
            "self.array_grad_L_by_weight[ 0 ]: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 7361\n",
            "self.array_grad_L_by_bias[ 0 ]: [[-0.          0.         -0.09360582  0.14284887 -0.44265157 -0.\n",
            "  -0.         -0.93025255 -2.13691107 -0.          0.         -0.\n",
            "  -0.70341771 -0.          1.09320638  0.         -0.         -1.05623446\n",
            "   0.         -0.79086507  0.89766258  1.8964491   1.00684147 -0.28550517\n",
            "  -0.45879859  0.         -0.         -0.32614535  0.          2.32504913\n",
            "  -0.27282039  0.        ]]\n",
            "Predicted output: [1.45817797e-30 4.20318675e-39 1.54001375e-42 7.14946212e-01\n",
            " 5.39277355e-33 4.03970460e-67 2.28000472e-44 2.12180640e-01\n",
            " 5.18727124e-22 7.28731479e-02]\n",
            "Actual output: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n",
            "Biases [ 0.73690705  0.42796968  0.56162908  0.79948225  1.02687869  0.81738447\n",
            "  0.83994874  0.78116463  0.62585015  0.49585371  0.41275672  0.51312683\n",
            "  0.52192052  0.02501608  0.42493723  0.56508585  0.40744959  0.35149883\n",
            "  0.78152873  0.72543924  0.24855624  0.64970197 -0.04789828  0.35985423\n",
            "  0.83781829  0.48510933  0.19969615  0.3225403   0.83813795  0.33996822\n",
            "  0.60162456  0.22424953]\n",
            "A's [-11.1376803  -28.98138741   3.21146683   8.35034807  21.85091652\n",
            " -22.80098461 -10.55188849   7.84625325  16.27492608  -2.17046677\n",
            " -15.83699274  -7.85578766   6.92920188  -2.52104325   8.00554901\n",
            "  -7.20918165  -4.32811593   3.84018615  -6.03420283  13.91844021\n",
            "   6.53597882  27.31114145   0.24188582   4.84476784  20.36125684\n",
            "  -8.0475966  -41.28777134   2.75849123 -24.7922894    8.82325594\n",
            "   9.44095118 -10.65731563]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 0.02486971  2.46523039 -0.89701457 -0.00406045 -0.66953299 -1.94642287\n",
            "   0.17622831 -0.30321011  0.74185169  1.26453163]\n",
            " [ 1.45202164  1.05731147 -0.26526813  0.71298223  0.11633998  1.34039607\n",
            "  -0.72026458  0.536021   -0.1147328  -0.85238334]\n",
            " [ 0.19940426 -0.93157851 -1.28533239 -0.98053176 -0.25216599 -0.81523568\n",
            "  -1.45862209 -0.02353088  1.01582961 -0.17015634]\n",
            " [ 0.02852031  0.20440974  1.59754677 -0.028596    2.51397538  0.93449606\n",
            "   0.83088503  0.0164223  -0.52808687  1.10273721]\n",
            " [ 0.56485443  0.59445809 -1.69647492 -0.95069265  0.45203847 -0.51058193\n",
            "   0.14776303  0.3889987   0.61401368  3.17001025]\n",
            " [ 1.60933497  0.66410306  0.7775757  -0.00943842  0.1616238   0.84501642\n",
            "  -0.14069216  1.0495381   1.21544638  0.50684308]\n",
            " [ 1.73782607  0.2821797   0.27023143 -1.27763898 -0.25939202  1.0520684\n",
            "   0.67083626 -0.44026176  0.55905452  0.08487246]\n",
            " [ 1.43882626  0.73926027 -1.48315104 -0.17375326 -1.83417412 -1.39587437\n",
            "   2.08574814  1.95844128  0.63153749  2.51571996]\n",
            " [ 1.36135882 -1.24683987 -0.28057126 -1.15023392 -0.68156831  0.76613861\n",
            "  -2.2865673  -1.40443265  0.67012474  3.58166427]\n",
            " [ 0.84167083  0.07115869 -0.30014327 -1.88102474 -2.05799275  0.12142546\n",
            "  -0.08130369 -0.88103138  1.1325719   0.14083608]\n",
            " [-0.15023084  1.03930763  0.7291683   1.0262029  -1.09021236  0.27526408\n",
            "  -0.19673703  1.68387065 -1.1225331   0.00689092]\n",
            " [-1.73676242  0.39919869 -1.52415861 -0.55366246 -0.69530452  0.18054354\n",
            "  -0.33766861 -1.28131826  0.05898181  0.75676224]\n",
            " [ 0.73956874 -0.46902191 -0.41205808 -0.95532458  0.11231659 -0.96794387\n",
            "   0.60702528 -0.68736161 -0.6607981   0.9228048 ]\n",
            " [ 0.45710512  0.84246858  1.92183715 -0.40057712  1.20509059  0.11472622\n",
            "  -0.32686671  1.14392147  0.72884546  0.04679561]\n",
            " [-1.2021908   0.67689264 -0.94291231  0.76093567 -0.27574651 -0.03449987\n",
            "   1.49006107 -0.2512909  -0.01167482  0.57260185]\n",
            " [-0.19605701  0.16759149 -0.44654897  1.57364207  0.71283608  0.84103131\n",
            "  -0.69375819 -1.13758541 -0.12143217  0.43217995]\n",
            " [-1.87205504  0.15396864  0.00715297  0.68425244 -1.04532001  0.84917234\n",
            "  -0.42099343 -0.44808443 -0.01581228  0.66798167]\n",
            " [ 0.63468307  1.84482447  0.34956419 -0.79496527  0.1672082  -2.03435087\n",
            "   1.31231916 -0.11105399  1.90631102  1.08720974]\n",
            " [ 1.3930949   0.55640313  0.16030895  0.70382998 -1.06670368 -0.88535136\n",
            "  -0.28052922 -0.8776164   0.82686335 -1.67612503]\n",
            " [-1.63710912 -1.09585299 -0.10810315 -1.15085915 -1.16267201 -0.65311163\n",
            "  -0.85737389 -0.76249204  0.03114076  1.91641092]\n",
            " [-0.1467437  -0.94367311  1.65475333  0.38181209  0.77126441 -2.21848462\n",
            "  -0.11469189  1.2010703  -0.11843857  0.59913746]\n",
            " [ 1.15483391  0.43446433  0.39329007 -2.06113919 -0.65833489 -0.37490774\n",
            "  -0.14161155  0.7191356  -0.61554061  0.70007903]\n",
            " [ 0.68414485 -1.43595713 -1.04511258 -0.4993211  -1.23161507 -1.352923\n",
            "   0.67843308  0.20813672 -1.3137253  -1.38645757]\n",
            " [-0.75846623 -0.78220337  0.21034988  0.75722198  1.24189986 -0.30412354\n",
            "   0.8491469  -2.12941051  0.55068966  1.14433984]\n",
            " [-1.07118177  0.76543446  1.58340823  0.21286528  0.41632777  0.08657977\n",
            "  -0.77724997  0.73785982  0.72385902  3.93706159]\n",
            " [ 0.32838711 -2.28986326  0.15917115  1.97732032  1.41118835 -0.78147465\n",
            "   0.01592791 -0.51826717 -0.58312659 -0.67936502]\n",
            " [ 0.35362674 -1.15211746 -1.12159934  0.27198168  1.40136595 -0.42754978\n",
            "  -0.28471013  0.3254941  -1.23769283  0.82997527]\n",
            " [-0.67280755 -1.39539147  0.05310319  0.88213121  1.95042188  0.78023984\n",
            "   0.67784875  1.3754998  -0.1197567   1.76804805]\n",
            " [ 0.08108198 -0.09907129  0.4478459   0.42657239 -0.32265361  0.85516149\n",
            "  -1.45797387  0.23397283 -0.50143702 -0.69362195]\n",
            " [ 0.38221867 -0.0695748  -0.32446705  0.73155305  2.0734625  -0.04259274\n",
            "  -0.22708557  1.25021981 -0.25119683 -0.31022533]\n",
            " [-0.78002152 -0.22698913 -0.32727231  0.45009608  0.41477926 -1.13569562\n",
            "   1.31769772  0.38071296  1.35488671  2.17012517]\n",
            " [ 0.72260728  0.6880381   0.54853488 -0.15671519  0.30025416 -0.7022573\n",
            "   0.71593046 -0.70757154  1.1243482  -0.76365316]]\n",
            "Biases [0.88871364 0.70190615 0.41362187 0.73119059 0.06611734 0.00692364\n",
            " 0.31411998 0.03343416 0.84911997 1.06546921]\n",
            "A's [ 22.12030179   2.45569126  -5.45611567  90.48511893  16.52041865\n",
            " -62.05636277  -9.66889968  89.2703496   41.81000263  88.20163184]\n",
            "**************************\n",
            "Loss: 3.7784688782575007\n",
            "Data point number: 1\n",
            "Back prop starts ===========================\n",
            "current_H:[ 1 ]: [[ 3.97981147  0.          0.         32.66262172 36.35895458  0.\n",
            "   0.          4.10919306 43.37380769  3.54285996  0.          6.86092357\n",
            "   3.42604564  8.92911518  0.          0.          3.59487476 19.27819445\n",
            "   0.         15.21918562  0.          0.          0.         25.59051343\n",
            "   5.91599759  0.          0.          0.          0.          0.\n",
            "  29.37103585  0.        ]]\n",
            "current_H shape:[ 1 ]: (32, 1)\n",
            "current_grad_L_by_A[ 1  ]: [[-1.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
            "current_grad_L_by_A[ 1  ] shape: (1, 10)\n",
            "self.array_grad_L_by_weight[ 1 ]: [[ -3.97981147   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           3.97981147]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [-32.66262172   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.          32.66262172]\n",
            " [-36.35895458   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.          36.35895458]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [ -4.10919306   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           4.10919306]\n",
            " [-43.37380769   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.          43.37380769]\n",
            " [ -3.54285996   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           3.54285996]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [ -6.86092357   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           6.86092357]\n",
            " [ -3.42604564   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           3.42604564]\n",
            " [ -8.92911518   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           8.92911518]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [ -3.59487476   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           3.59487476]\n",
            " [-19.27819445   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.          19.27819445]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [-15.21918562   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.          15.21918562]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [-25.59051343   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.          25.59051343]\n",
            " [ -5.91599759   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           5.91599759]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [-29.37103585   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.          29.37103585]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]]\n",
            "number of non-zeros in weight gradient: 30\n",
            "self.array_grad_L_by_bias[ 1 ]: [[-1.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
            "current_grad_H_by_A[ 1 ]: [[1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1.\n",
            "  1. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "self.array_grad_L_by_A[ 0 ]: [[ 1.23966192 -0.         -0.          1.0742169   2.60515582 -0.\n",
            "  -0.          1.07689371  2.22030545 -0.70083476  0.          2.49352467\n",
            "   0.18323606 -0.41030951  0.          0.          2.54003671  0.45252667\n",
            "  -0.          3.55352004  0.         -0.         -0.          1.90280607\n",
            "   5.00824337 -0.          0.          0.         -0.         -0.\n",
            "   2.95014669 -0.        ]]\n",
            "current_H:[ 0 ]: [[0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.         0.         0.         0.16078431 0.7372549\n",
            "  0.40392157 0.21176471 0.18823529 0.16862745 0.34117647 0.65882353\n",
            "  0.52156863 0.0627451  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.         0.         0.         0.19215686\n",
            "  0.53333333 0.85882353 0.84705882 0.89411765 0.9254902  1.\n",
            "  1.         1.         1.         0.85098039 0.84313725 0.99607843\n",
            "  0.90588235 0.62745098 0.17647059 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.05490196 0.69019608 0.87058824 0.87843137 0.83137255\n",
            "  0.79607843 0.77647059 0.76862745 0.78431373 0.84313725 0.8\n",
            "  0.79215686 0.78823529 0.78823529 0.78823529 0.81960784 0.85490196\n",
            "  0.87843137 0.64313725 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.7372549\n",
            "  0.85882353 0.78431373 0.77647059 0.79215686 0.77647059 0.78039216\n",
            "  0.78039216 0.78823529 0.76862745 0.77647059 0.77647059 0.78431373\n",
            "  0.78431373 0.78431373 0.78431373 0.78823529 0.78431373 0.88235294\n",
            "  0.16078431 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.2        0.85882353 0.78039216 0.79607843\n",
            "  0.79607843 0.83137255 0.93333333 0.97254902 0.98039216 0.96078431\n",
            "  0.97647059 0.96470588 0.96862745 0.98823529 0.97254902 0.92156863\n",
            "  0.81176471 0.79607843 0.79607843 0.87058824 0.54901961 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.45490196 0.88627451 0.80784314 0.8        0.81176471 0.8\n",
            "  0.39607843 0.29411765 0.18431373 0.28627451 0.18823529 0.19607843\n",
            "  0.17647059 0.2        0.24705882 0.44313725 0.87058824 0.79215686\n",
            "  0.80784314 0.8627451  0.87843137 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.78431373 0.87058824\n",
            "  0.81960784 0.79607843 0.84313725 0.78431373 0.         0.2745098\n",
            "  0.38431373 0.         0.40392157 0.23137255 0.26666667 0.27843137\n",
            "  0.19215686 0.         0.85882353 0.80784314 0.83921569 0.82352941\n",
            "  0.98039216 0.14901961 0.         0.         0.         0.\n",
            "  0.         0.         0.96862745 0.85490196 0.83137255 0.82352941\n",
            "  0.84313725 0.83921569 0.         0.99607843 0.95294118 0.54509804\n",
            "  1.         0.68235294 0.98431373 1.         0.80392157 0.\n",
            "  0.84313725 0.85098039 0.83921569 0.81568627 0.8627451  0.37254902\n",
            "  0.         0.         0.         0.         0.         0.17647059\n",
            "  0.88627451 0.83921569 0.83921569 0.84313725 0.87843137 0.80392157\n",
            "  0.         0.16470588 0.1372549  0.23529412 0.0627451  0.06666667\n",
            "  0.04705882 0.05098039 0.2745098  0.         0.74117647 0.84705882\n",
            "  0.83137255 0.80784314 0.83137255 0.61176471 0.         0.\n",
            "  0.         0.         0.         0.64313725 0.92156863 0.83921569\n",
            "  0.82745098 0.8627451  0.84705882 0.78823529 0.20392157 0.27843137\n",
            "  0.34901961 0.36862745 0.3254902  0.30588235 0.2745098  0.29803922\n",
            "  0.36078431 0.34117647 0.80784314 0.81176471 0.87058824 0.83529412\n",
            "  0.85882353 0.81568627 0.         0.         0.         0.\n",
            "  0.         0.41568627 0.73333333 0.8745098  0.92941176 0.97254902\n",
            "  0.82745098 0.77647059 0.98823529 0.98039216 0.97254902 0.96078431\n",
            "  0.97254902 0.98823529 0.99215686 0.98039216 0.98823529 0.9372549\n",
            "  0.78823529 0.83137255 0.88235294 0.84313725 0.75686275 0.44313725\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.06666667 0.21176471 0.62352941 0.87058824 0.75686275\n",
            "  0.81568627 0.75294118 0.77254902 0.78431373 0.78431373 0.78431373\n",
            "  0.78431373 0.78823529 0.79607843 0.76470588 0.82352941 0.64705882\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.18431373 0.88235294 0.75294118 0.83921569 0.79607843\n",
            "  0.80784314 0.8        0.8        0.80392157 0.80784314 0.8\n",
            "  0.83137255 0.77254902 0.85490196 0.41960784 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.00392157 0.02352941 0.         0.18039216\n",
            "  0.83137255 0.76470588 0.83137255 0.79215686 0.80784314 0.80392157\n",
            "  0.8        0.80392157 0.80784314 0.8        0.83137255 0.78431373\n",
            "  0.85490196 0.35686275 0.         0.01176471 0.00392157 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.         0.04313725 0.77254902 0.78039216\n",
            "  0.80392157 0.79215686 0.80392157 0.80784314 0.8        0.80392157\n",
            "  0.81176471 0.8        0.80392157 0.80392157 0.85490196 0.30196078\n",
            "  0.         0.01960784 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.01176471\n",
            "  0.         0.00784314 0.74901961 0.77647059 0.78823529 0.80392157\n",
            "  0.80784314 0.80392157 0.80392157 0.80784314 0.81960784 0.80784314\n",
            "  0.78039216 0.81960784 0.85882353 0.29019608 0.         0.01960784\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00784314 0.         0.\n",
            "  0.7372549  0.77254902 0.78431373 0.81176471 0.81176471 0.8\n",
            "  0.81176471 0.81176471 0.82352941 0.81568627 0.77647059 0.81176471\n",
            "  0.86666667 0.28235294 0.         0.01568627 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00784314 0.         0.         0.84313725 0.77647059\n",
            "  0.79607843 0.80784314 0.81568627 0.80392157 0.81176471 0.81176471\n",
            "  0.82352941 0.81568627 0.78431373 0.79215686 0.87058824 0.29411765\n",
            "  0.         0.01568627 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.         0.83137255 0.77647059 0.81960784 0.80784314\n",
            "  0.81960784 0.80784314 0.81568627 0.81176471 0.82745098 0.80784314\n",
            "  0.80392157 0.77647059 0.86666667 0.31372549 0.         0.01176471\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.         0.\n",
            "  0.8        0.78823529 0.80392157 0.81568627 0.81176471 0.80392157\n",
            "  0.82745098 0.80392157 0.82352941 0.82352941 0.81960784 0.76470588\n",
            "  0.86666667 0.37647059 0.         0.01176471 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.         0.         0.79215686 0.78823529\n",
            "  0.80392157 0.81960784 0.81176471 0.80392157 0.83529412 0.80784314\n",
            "  0.82352941 0.81960784 0.82352941 0.76078431 0.85098039 0.41176471\n",
            "  0.         0.00784314 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.         0.8        0.8        0.80392157 0.81568627\n",
            "  0.81176471 0.80392157 0.84313725 0.81176471 0.82352941 0.81568627\n",
            "  0.82745098 0.75686275 0.83529412 0.45098039 0.         0.00784314\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.8        0.81176471 0.81176471 0.81568627 0.80784314 0.80784314\n",
            "  0.84313725 0.82352941 0.82352941 0.81176471 0.83137255 0.76470588\n",
            "  0.82352941 0.4627451  0.         0.00784314 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.         0.         0.77647059 0.81568627\n",
            "  0.81568627 0.81568627 0.8        0.81176471 0.83137255 0.83137255\n",
            "  0.82352941 0.81176471 0.82745098 0.76862745 0.81176471 0.4745098\n",
            "  0.         0.00392157 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.         0.77647059 0.82352941 0.81176471 0.81568627\n",
            "  0.80784314 0.81960784 0.83529412 0.83137255 0.82745098 0.81176471\n",
            "  0.82352941 0.77254902 0.81176471 0.48627451 0.         0.00392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.6745098  0.82352941 0.79607843 0.78823529 0.78039216 0.8\n",
            "  0.81176471 0.80392157 0.8        0.78823529 0.80392157 0.77254902\n",
            "  0.80784314 0.49803922 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.7372549  0.86666667\n",
            "  0.83921569 0.91764706 0.9254902  0.93333333 0.95686275 0.95686275\n",
            "  0.95686275 0.94117647 0.95294118 0.83921569 0.87843137 0.63529412\n",
            "  0.         0.00784314 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.         0.54509804 0.57254902 0.50980392 0.52941176\n",
            "  0.52941176 0.5372549  0.49019608 0.48627451 0.49019608 0.4745098\n",
            "  0.46666667 0.44705882 0.50980392 0.29803922 0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "current_H shape:[ 0 ]: (784, 1)\n",
            "current_grad_L_by_A[ 0  ]: [[ 1.23966192 -0.         -0.          1.0742169   2.60515582 -0.\n",
            "  -0.          1.07689371  2.22030545 -0.70083476  0.          2.49352467\n",
            "   0.18323606 -0.41030951  0.          0.          2.54003671  0.45252667\n",
            "  -0.          3.55352004  0.         -0.         -0.          1.90280607\n",
            "   5.00824337 -0.          0.          0.         -0.         -0.\n",
            "   2.95014669 -0.        ]]\n",
            "current_grad_L_by_A[ 0  ] shape: (1, 32)\n",
            "self.array_grad_L_by_weight[ 0 ]: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 7305\n",
            "self.array_grad_L_by_bias[ 0 ]: [[ 1.23966192 -0.         -0.          1.0742169   2.60515582 -0.\n",
            "  -0.          1.07689371  2.22030545 -0.70083476  0.          2.49352467\n",
            "   0.18323606 -0.41030951  0.          0.          2.54003671  0.45252667\n",
            "  -0.          3.55352004  0.         -0.         -0.          1.90280607\n",
            "   5.00824337 -0.          0.          0.         -0.         -0.\n",
            "   2.95014669 -0.        ]]\n",
            "Predicted output: [5.48620719e-211 5.20181225e-221 1.60025644e-225 1.77553388e-261\n",
            " 5.61150926e-181 1.50521546e-242 9.31513765e-216 8.03427250e-261\n",
            " 1.30006861e-155 1.00000000e+000]\n",
            "Actual output: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n",
            "Biases [ 0.61294085  0.42796968  0.5700536   0.67920416  0.80620175  0.81738447\n",
            "  0.83994874  0.75719799  0.5961416   0.56593719  0.41275672  0.26377437\n",
            "  0.56690451  0.06604703  0.32654865  0.56508585  0.15344592  0.40130727\n",
            "  0.78152873  0.44126509  0.16776661  0.47902155 -0.13851401  0.19526909\n",
            "  0.37828582  0.48510933  0.19969615  0.35189339  0.83813795  0.1307138\n",
            "  0.33116373  0.22424953]\n",
            "A's [  3.97981147 -17.57005906 -13.75579934  32.66262172  36.35895458\n",
            " -23.00153919 -16.63945118   4.10919306  43.37380769   3.54285996\n",
            " -17.16632689   6.86092357   3.42604564   8.92911518  -1.60923519\n",
            "  -2.79074678   3.59487476  19.27819445 -13.33737391  15.21918562\n",
            " -21.06824821  -8.47969321 -21.74291519  25.59051343   5.91599759\n",
            "  -7.13795422 -23.20268641  -3.70457016 -20.88918361 -37.36640584\n",
            "  29.37103585  -6.66724306]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 4.22850855e-01  2.46523039e+00 -8.97014575e-01 -4.06045483e-03\n",
            "  -6.69532988e-01 -1.94642287e+00  1.76228313e-01 -3.03210110e-01\n",
            "   7.41851688e-01  8.66550481e-01]\n",
            " [ 1.45202164e+00  1.05731147e+00 -2.65268128e-01  7.12982227e-01\n",
            "   1.16339981e-01  1.34039607e+00 -7.20264578e-01  5.36020997e-01\n",
            "  -1.14732803e-01 -8.52383342e-01]\n",
            " [ 1.99404259e-01 -9.31578510e-01 -1.28533239e+00 -1.18717410e+00\n",
            "  -2.52165990e-01 -8.15235685e-01 -1.45862209e+00 -8.48578729e-02\n",
            "   1.01582961e+00  9.78130005e-02]\n",
            " [ 3.29478249e+00  2.04409738e-01  1.59754677e+00 -5.65900471e-01\n",
            "   2.51397538e+00  9.34496056e-01  8.30885034e-01 -1.43038099e-01\n",
            "  -5.28086871e-01 -1.46676009e+00]\n",
            " [ 4.20074988e+00  5.94458093e-01 -1.69647492e+00 -2.35669335e+00\n",
            "   4.52038471e-01 -5.10581933e-01  1.47763031e-01 -2.82720283e-02\n",
            "   6.14013681e-01  1.35738622e+00]\n",
            " [ 1.60933497e+00  6.64103061e-01  7.77575698e-01 -9.43842109e-03\n",
            "   1.61623803e-01  8.45016415e-01 -1.40692164e-01  1.04953810e+00\n",
            "   1.21544638e+00  5.06843077e-01]\n",
            " [ 1.73782607e+00  2.82179697e-01  2.70231433e-01 -1.27763898e+00\n",
            "  -2.59392017e-01  1.05206840e+00  6.70836257e-01 -4.40261755e-01\n",
            "   5.59054517e-01  8.48724554e-02]\n",
            " [ 1.84974556e+00  7.39260273e-01 -1.48315104e+00 -6.78621678e-01\n",
            "  -1.83417412e+00 -1.39587437e+00  2.08574814e+00  1.80860721e+00\n",
            "   6.31537488e-01  2.75950315e+00]\n",
            " [ 5.69873959e+00 -1.24683987e+00 -2.80571263e-01 -2.19744662e+00\n",
            "  -6.81568306e-01  7.66138607e-01 -2.28656730e+00 -1.71522283e+00\n",
            "   6.70124736e-01  6.02286386e-01]\n",
            " [ 1.19595683e+00  7.11586925e-02 -3.00143268e-01 -1.88102474e+00\n",
            "  -2.05799275e+00  1.21425460e-01 -8.13036872e-02 -8.81031380e-01\n",
            "   1.13257190e+00 -2.13449920e-01]\n",
            " [-1.50230842e-01  1.03930763e+00  7.29168297e-01  1.02620290e+00\n",
            "  -1.09021236e+00  2.75264079e-01 -1.96737026e-01  1.68387065e+00\n",
            "  -1.12253310e+00  6.89092159e-03]\n",
            " [-1.05067007e+00  3.99198686e-01 -1.52415861e+00 -5.53662461e-01\n",
            "  -6.95304516e-01  1.80543543e-01 -3.37668606e-01 -1.28131826e+00\n",
            "   5.89818080e-02  7.06698851e-02]\n",
            " [ 1.08217330e+00 -4.69021914e-01 -4.12058082e-01 -1.40118518e+00\n",
            "   1.12316593e-01 -9.67943868e-01  6.07025278e-01 -8.19683438e-01\n",
            "  -6.60798098e-01  1.15838266e+00]\n",
            " [ 1.35001663e+00  8.42468575e-01  1.92183715e+00 -4.00577120e-01\n",
            "   1.20509059e+00  1.14726221e-01 -3.26866712e-01  1.14392147e+00\n",
            "   7.28845462e-01 -8.46115907e-01]\n",
            " [-1.20219080e+00  6.76892638e-01 -9.42912310e-01  2.45817342e-01\n",
            "  -2.75746506e-01 -3.44998721e-02  1.49006107e+00 -4.04166925e-01\n",
            "  -1.16748214e-02  1.24059620e+00]\n",
            " [-1.96057007e-01  1.67591488e-01 -4.46548969e-01  1.57364207e+00\n",
            "   7.12836079e-01  8.41031306e-01 -6.93758189e-01 -1.13758541e+00\n",
            "  -1.21432166e-01  4.32179953e-01]\n",
            " [-1.51256757e+00  1.53968645e-01  7.15296631e-03  6.84252444e-01\n",
            "  -1.04532001e+00  8.49172338e-01 -4.20993426e-01 -4.48084427e-01\n",
            "  -1.58122829e-02  3.08494196e-01]\n",
            " [ 2.56250251e+00  1.84482447e+00  3.49564185e-01 -1.04206266e+00\n",
            "   1.67208203e-01 -2.03435087e+00  1.31231916e+00 -1.84387176e-01\n",
            "   1.90631102e+00 -5.20179136e-01]\n",
            " [ 1.39309490e+00  5.56403132e-01  1.60308951e-01  7.03829981e-01\n",
            "  -1.06670368e+00 -8.85351361e-01 -2.80529220e-01 -8.77616397e-01\n",
            "   8.26863347e-01 -1.67612503e+00]\n",
            " [-1.15190559e-01 -1.09585299e+00 -1.08103152e-01 -2.04644340e+00\n",
            "  -1.16267201e+00 -6.53111631e-01 -8.57373891e-01 -1.02828215e+00\n",
            "   3.11407572e-02  1.55586673e+00]\n",
            " [-1.46743702e-01 -9.43673115e-01  1.65475333e+00 -3.87465093e-02\n",
            "   7.71264415e-01 -2.21848462e+00 -1.14691887e-01  1.07625757e+00\n",
            "  -1.18438568e-01  1.14450879e+00]\n",
            " [ 1.15483391e+00  4.34464327e-01  3.93290067e-01 -3.81847894e+00\n",
            "  -6.58334895e-01 -3.74907738e-01 -1.41611555e-01  1.97595010e-01\n",
            "  -6.15540612e-01  2.97895936e+00]\n",
            " [ 6.84144849e-01 -1.43595713e+00 -1.04511258e+00 -5.14885279e-01\n",
            "  -1.23161507e+00 -1.35292300e+00  6.78433076e-01  2.03517605e-01\n",
            "  -1.31372530e+00 -1.36627427e+00]\n",
            " [ 1.80058512e+00 -7.82203372e-01  2.10349878e-01  4.45484618e-01\n",
            "   1.24189986e+00 -3.04123536e-01  8.49146897e-01 -2.22192745e+00\n",
            "   5.50689660e-01 -1.01045721e+00]\n",
            " [-4.79582016e-01  7.65434462e-01  1.58340823e+00 -1.09728304e+00\n",
            "   4.16327772e-01  8.65797709e-02 -7.77249968e-01  3.49036014e-01\n",
            "   7.23859020e-01  5.04443395e+00]\n",
            " [ 3.28387106e-01 -2.28986326e+00  1.59171146e-01  1.97732032e+00\n",
            "   1.41118835e+00 -7.81474646e-01  1.59279133e-02 -5.18267173e-01\n",
            "  -5.83126593e-01 -6.79365021e-01]\n",
            " [ 3.53626738e-01 -1.15211746e+00 -1.12159934e+00  2.71981678e-01\n",
            "   1.40136595e+00 -4.27549781e-01 -2.84710131e-01  3.25494097e-01\n",
            "  -1.23769283e+00  8.29975266e-01]\n",
            " [-6.72807553e-01 -1.39539147e+00  5.31031853e-02  7.04635649e-01\n",
            "   1.95042188e+00  7.80239841e-01  6.77848751e-01  1.32282294e+00\n",
            "  -1.19756701e-01  1.99822047e+00]\n",
            " [ 8.10819802e-02 -9.90712935e-02  4.47845897e-01  4.26572385e-01\n",
            "  -3.22653610e-01  8.55161491e-01 -1.45797387e+00  2.33972834e-01\n",
            "  -5.01437020e-01 -6.93621946e-01]\n",
            " [ 3.82218675e-01 -6.95748040e-02 -3.24467046e-01  1.63819239e-01\n",
            "   2.07346250e+00 -4.25927450e-02 -2.27085566e-01  1.08172864e+00\n",
            "  -2.51196835e-01  4.25999645e-01]\n",
            " [ 2.15708207e+00 -2.26989131e-01 -3.27272311e-01 -1.57383429e-01\n",
            "   4.14779258e-01 -1.13569562e+00  1.31769772e+00  2.00426122e-01\n",
            "   1.35488671e+00  2.07879293e-02]\n",
            " [ 7.22607280e-01  6.88038100e-01  5.48534881e-01 -1.56715187e-01\n",
            "   3.00254157e-01 -7.02257301e-01  7.15930457e-01 -7.07571535e-01\n",
            "   1.12434820e+00 -7.63653157e-01]]\n",
            "Biases [0.98871364 0.70190615 0.41362187 0.66684543 0.06611734 0.00692364\n",
            " 0.31411998 0.0143379  0.84911997 1.04891062]\n",
            "A's [ 17.0315373   -6.04754371 -16.43672727 -99.22585335  86.13167265\n",
            " -55.64190169   6.04801546 -97.71623805 144.53648239 501.17475476]\n",
            "**************************\n",
            "Loss: 698.4710189138225\n",
            "Data point number: 2\n",
            "Back prop starts ===========================\n",
            "current_H:[ 1 ]: [[0.         0.         0.15484089 3.1785374  0.         0.\n",
            "  0.         0.58599553 4.42938787 7.45796121 0.         0.\n",
            "  0.         1.83374718 0.         0.         0.         5.84047761\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]]\n",
            "current_H shape:[ 1 ]: (32, 1)\n",
            "current_grad_L_by_A[ 1  ]: [[0.00000000e+00 1.05215869e-24 8.98761081e-26 1.26271027e-42\n",
            "  3.54490519e-32 6.43541865e-31 1.77772784e-28 4.79544729e-34\n",
            "  2.34059625e-18 5.50701781e-31]]\n",
            "current_grad_L_by_A[ 1  ] shape: (1, 10)\n",
            "self.array_grad_L_by_weight[ 1 ]: [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 1.62917189e-25 1.39164966e-26 1.95519183e-43\n",
            "  5.48896278e-33 9.96465956e-32 2.75264962e-29 7.42531330e-35\n",
            "  3.62420009e-19 8.52711544e-32]\n",
            " [0.00000000e+00 3.34432574e-24 2.85674571e-25 4.01357182e-42\n",
            "  1.12676137e-31 2.04552189e-30 5.65057442e-28 1.52425086e-33\n",
            "  7.43967274e-18 1.75042621e-30]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 6.16560290e-25 5.26669978e-26 7.39942576e-43\n",
            "  2.07729861e-32 3.77112658e-31 1.04174057e-28 2.81011069e-34\n",
            "  1.37157895e-18 3.22708783e-31]\n",
            " [0.00000000e+00 4.66041893e-24 3.98096143e-25 5.59303355e-42\n",
            "  1.57017601e-31 2.85049653e-30 7.87424611e-28 2.12408961e-33\n",
            "  1.03674086e-17 2.43927179e-30]\n",
            " [0.00000000e+00 7.84695868e-24 6.70292528e-25 9.41724420e-42\n",
            "  2.64377654e-31 4.79951026e-30 1.32582252e-27 3.57642599e-33\n",
            "  1.74560761e-17 4.10711252e-30]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 1.92939303e-24 1.64810060e-25 2.31549139e-42\n",
            "  6.50045990e-32 1.18009308e-30 3.25990341e-28 8.79363795e-34\n",
            "  4.29206178e-18 1.00984784e-30]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 6.14510925e-24 5.24919397e-25 7.37483104e-42\n",
            "  2.07039394e-31 3.75859185e-30 1.03827796e-27 2.80077025e-33\n",
            "  1.36702000e-17 3.21636142e-30]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n",
            "number of non-zeros in weight gradient: 63\n",
            "self.array_grad_L_by_bias[ 1 ]: [[0.00000000e+00 1.05215869e-24 8.98761081e-26 1.26271027e-42\n",
            "  3.54490519e-32 6.43541865e-31 1.77772784e-28 4.79544729e-34\n",
            "  2.34059625e-18 5.50701781e-31]]\n",
            "current_grad_H_by_A[ 1 ]: [[0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "self.array_grad_L_by_A[ 0 ]: [[ 0.00000000e+00 -0.00000000e+00  2.37764589e-18 -1.23603779e-18\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.47817492e-18\n",
            "   1.56849011e-18  2.65089358e-18 -0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  1.70593402e-18 -0.00000000e+00 -0.00000000e+00\n",
            "  -0.00000000e+00  4.46190641e-18  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
            "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "current_H:[ 0 ]: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.08627451 0.4627451  0.09411765\n",
            "  0.         0.         0.         0.         0.         0.18823529\n",
            "  0.34509804 0.01960784 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.04705882 0.39215686 0.83137255 0.80392157 0.7254902  0.70196078\n",
            "  0.67843137 0.72941176 0.75686275 0.86666667 0.55686275 0.33333333\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.33333333\n",
            "  0.29803922 0.78039216 0.88235294 0.97254902 1.         0.93333333\n",
            "  0.88627451 0.61568627 0.26666667 0.31372549 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.35686275 0.27058824 0.35686275\n",
            "  0.78823529 0.85490196 0.88235294 0.81960784 0.61960784 0.23921569\n",
            "  0.36470588 0.28235294 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.30980392 0.34901961 0.23921569 0.23137255 0.34117647\n",
            "  0.42352941 0.29411765 0.21960784 0.29803922 0.38039216 0.28627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.29411765\n",
            "  0.34901961 0.31372549 0.31372549 0.2627451  0.24705882 0.28627451\n",
            "  0.3254902  0.31372549 0.37647059 0.28235294 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.30196078 0.34509804 0.30196078\n",
            "  0.31372549 0.3254902  0.3254902  0.3254902  0.3254902  0.31764706\n",
            "  0.37254902 0.29803922 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.34901961 0.37647059 0.31372549 0.3254902  0.31764706\n",
            "  0.32941176 0.33333333 0.33333333 0.33333333 0.38039216 0.32941176\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.36470588\n",
            "  0.38039216 0.31764706 0.33333333 0.32941176 0.33333333 0.34117647\n",
            "  0.34509804 0.32941176 0.38823529 0.34117647 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.37254902 0.34117647 0.32941176\n",
            "  0.34117647 0.34509804 0.33333333 0.34117647 0.34117647 0.32941176\n",
            "  0.36078431 0.34117647 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.38039216 0.34117647 0.34117647 0.33333333 0.34509804\n",
            "  0.34117647 0.34117647 0.34117647 0.34509804 0.33333333 0.41960784\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.06666667 0.39215686\n",
            "  0.34509804 0.34117647 0.34117647 0.34509804 0.34117647 0.34117647\n",
            "  0.33333333 0.34901961 0.30196078 0.4627451  0.03137255 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.03921569 0.36470588 0.34117647 0.34117647\n",
            "  0.34117647 0.34117647 0.34117647 0.34509804 0.34117647 0.34901961\n",
            "  0.31372549 0.40392157 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.03529412 0.37647059 0.34117647 0.34117647 0.34117647 0.34117647\n",
            "  0.34117647 0.34509804 0.34117647 0.34509804 0.34117647 0.40392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.04705882 0.37647059\n",
            "  0.33333333 0.34117647 0.34117647 0.34117647 0.33333333 0.34117647\n",
            "  0.34117647 0.34509804 0.34901961 0.39215686 0.00784314 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.07843137 0.37254902 0.32941176 0.34509804\n",
            "  0.33333333 0.34117647 0.34509804 0.34509804 0.34509804 0.34901961\n",
            "  0.34509804 0.38823529 0.03137255 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.08235294 0.37647059 0.33333333 0.34117647 0.33333333 0.34509804\n",
            "  0.34509804 0.34509804 0.34509804 0.34901961 0.34901961 0.38823529\n",
            "  0.03921569 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.09411765 0.37647059\n",
            "  0.33333333 0.34117647 0.33333333 0.34117647 0.34509804 0.34509804\n",
            "  0.34901961 0.34509804 0.35686275 0.4        0.05490196 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.09803922 0.36470588 0.32941176 0.34509804\n",
            "  0.34117647 0.34117647 0.34117647 0.34117647 0.34117647 0.34901961\n",
            "  0.35686275 0.40392157 0.11372549 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.11764706 0.37254902 0.33333333 0.34509804 0.34509804 0.34117647\n",
            "  0.34117647 0.34117647 0.34117647 0.34901961 0.34509804 0.4\n",
            "  0.14509804 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.13333333 0.37647059\n",
            "  0.34509804 0.34117647 0.34117647 0.34117647 0.34117647 0.34117647\n",
            "  0.34117647 0.33333333 0.33333333 0.38039216 0.14901961 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.15686275 0.37647059 0.34117647 0.33333333\n",
            "  0.34117647 0.34117647 0.34117647 0.34117647 0.34117647 0.33333333\n",
            "  0.32941176 0.36078431 0.19215686 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.18039216 0.37254902 0.3254902  0.32941176 0.34117647 0.34117647\n",
            "  0.34117647 0.34117647 0.34117647 0.34117647 0.32941176 0.34117647\n",
            "  0.32941176 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.28235294 0.37254902\n",
            "  0.33333333 0.32941176 0.33333333 0.34509804 0.34117647 0.34117647\n",
            "  0.34901961 0.34117647 0.33333333 0.3254902  0.24705882 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.25098039 0.39215686 0.32941176 0.34117647\n",
            "  0.34509804 0.33333333 0.34509804 0.34509804 0.32941176 0.34117647\n",
            "  0.3254902  0.37254902 0.20784314 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.03921569 0.4        0.39215686 0.35686275 0.35686275 0.34901961\n",
            "  0.33333333 0.32941176 0.32941176 0.34117647 0.42352941 0.41568627\n",
            "  0.05490196 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.03137255\n",
            "  0.28627451 0.36470588 0.40784314 0.41960784 0.40392157 0.40392157\n",
            "  0.41568627 0.4        0.29411765 0.03921569 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.00392157 0.         0.         0.\n",
            "  0.07058824 0.16470588 0.22352941 0.21960784 0.1254902  0.03137255\n",
            "  0.         0.         0.00392157 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "current_H shape:[ 0 ]: (784, 1)\n",
            "current_grad_L_by_A[ 0  ]: [[ 0.00000000e+00 -0.00000000e+00  2.37764589e-18 -1.23603779e-18\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.47817492e-18\n",
            "   1.56849011e-18  2.65089358e-18 -0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  1.70593402e-18 -0.00000000e+00 -0.00000000e+00\n",
            "  -0.00000000e+00  4.46190641e-18  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
            "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "current_grad_L_by_A[ 0  ] shape: (1, 32)\n",
            "self.array_grad_L_by_weight[ 0 ]: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 2303\n",
            "self.array_grad_L_by_bias[ 0 ]: [[ 0.00000000e+00 -0.00000000e+00  2.37764589e-18 -1.23603779e-18\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.47817492e-18\n",
            "   1.56849011e-18  2.65089358e-18 -0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00  1.70593402e-18 -0.00000000e+00 -0.00000000e+00\n",
            "  -0.00000000e+00  4.46190641e-18  0.00000000e+00  0.00000000e+00\n",
            "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
            "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "Predicted output: [1.00000000e+00 1.05215869e-24 8.98761081e-26 1.26271027e-42\n",
            " 3.54490519e-32 6.43541865e-31 1.77772784e-28 4.79544729e-34\n",
            " 2.34059625e-18 5.50701781e-31]\n",
            "Actual output: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n",
            "Biases [ 0.50137128  0.42796968  0.57763567  0.57095388  0.6075925   0.81738447\n",
            "  0.83994874  0.73562801  0.5694039   0.62901232  0.41275672  0.03935715\n",
            "  0.6073901   0.10297489  0.23799894  0.56508585 -0.07515739  0.44613486\n",
            "  0.78152873  0.18550836  0.09505594  0.32540917 -0.22006817  0.04714247\n",
            " -0.0352934   0.48510933  0.19969615  0.37831116  0.83813795 -0.05761518\n",
            "  0.08774898  0.22424953]\n",
            "A's [-11.82899252  -1.27585976   0.15484089   3.1785374   -2.8166776\n",
            " -10.8321239  -14.21641052   0.58599553   4.42938787   7.45796121\n",
            "  -1.64679572 -27.52760599  -4.00166552   1.83374718  -3.672474\n",
            "  -4.13577456 -25.03323644   5.84047761  -8.47538775 -21.69919053\n",
            " -14.41926959  -9.925071   -13.696711    -6.46121313 -30.05806249\n",
            "  -5.51287869 -14.12916022  -3.41765667  -6.27309034 -33.97996994\n",
            " -18.59075253  -6.75564434]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 7.81033887e-01  2.46523039e+00 -8.97014575e-01 -4.06045483e-03\n",
            "  -6.69532988e-01 -1.94642287e+00  1.76228313e-01 -3.03210110e-01\n",
            "   7.41851688e-01  5.08367448e-01]\n",
            " [ 1.45202164e+00  1.05731147e+00 -2.65268128e-01  7.12982227e-01\n",
            "   1.16339981e-01  1.34039607e+00 -7.20264578e-01  5.36020997e-01\n",
            "  -1.14732803e-01 -8.52383342e-01]\n",
            " [ 1.99404259e-01 -9.31578510e-01 -1.28533239e+00 -1.37315221e+00\n",
            "  -2.52165990e-01 -8.15235685e-01 -1.45862209e+00 -1.40052171e-01\n",
            "   1.01582961e+00  3.38985408e-01]\n",
            " [ 6.23441844e+00  2.04409738e-01  1.59754677e+00 -1.04947450e+00\n",
            "   2.51397538e+00  9.34496056e-01  8.30885034e-01 -2.86552457e-01\n",
            "  -5.28086871e-01 -3.77930766e+00]\n",
            " [ 7.47305580e+00  5.94458093e-01 -1.69647492e+00 -3.62209398e+00\n",
            "   4.52038471e-01 -5.10581933e-01  1.47763031e-01 -4.03815686e-01\n",
            "   6.14013681e-01 -2.73975406e-01]\n",
            " [ 1.60933497e+00  6.64103061e-01  7.77575698e-01 -9.43842109e-03\n",
            "   1.61623803e-01  8.45016415e-01 -1.40692164e-01  1.04953810e+00\n",
            "   1.21544638e+00  5.06843077e-01]\n",
            " [ 1.73782607e+00  2.82179697e-01  2.70231433e-01 -1.27763898e+00\n",
            "  -2.59392017e-01  1.05206840e+00  6.70836257e-01 -4.40261755e-01\n",
            "   5.59054517e-01  8.48724554e-02]\n",
            " [ 2.21957294e+00  7.39260273e-01 -1.48315104e+00 -1.13300325e+00\n",
            "  -1.83417412e+00 -1.39587437e+00  2.08574814e+00  1.67375654e+00\n",
            "   6.31537488e-01  2.97890801e+00]\n",
            " [ 9.60238228e+00 -1.24683987e+00 -2.80571263e-01 -3.13993806e+00\n",
            "  -6.81568306e-01  7.66138607e-01 -2.28656730e+00 -1.99493399e+00\n",
            "   6.70124736e-01 -2.07915371e+00]\n",
            " [ 1.51481422e+00  7.11586925e-02 -3.00143268e-01 -1.88102474e+00\n",
            "  -2.05799275e+00  1.21425460e-01 -8.13036872e-02 -8.81031380e-01\n",
            "   1.13257190e+00 -5.32307316e-01]\n",
            " [-1.50230842e-01  1.03930763e+00  7.29168297e-01  1.02620290e+00\n",
            "  -1.09021236e+00  2.75264079e-01 -1.96737026e-01  1.68387065e+00\n",
            "  -1.12253310e+00  6.89092159e-03]\n",
            " [-4.33186946e-01  3.99198686e-01 -1.52415861e+00 -5.53662461e-01\n",
            "  -6.95304516e-01  1.80543543e-01 -3.37668606e-01 -1.28131826e+00\n",
            "   5.89818080e-02 -5.46813236e-01]\n",
            " [ 1.39051741e+00 -4.69021914e-01 -4.12058082e-01 -1.80245972e+00\n",
            "   1.12316593e-01 -9.67943868e-01  6.07025278e-01 -9.38773079e-01\n",
            "  -6.60798098e-01  1.37040273e+00]\n",
            " [ 2.15363700e+00  8.42468575e-01  1.92183715e+00 -4.00577120e-01\n",
            "   1.20509059e+00  1.14726221e-01 -3.26866712e-01  1.14392147e+00\n",
            "   7.28845462e-01 -1.64973627e+00]\n",
            " [-1.20219080e+00  6.76892638e-01 -9.42912310e-01 -2.17789151e-01\n",
            "  -2.75746506e-01 -3.44998721e-02  1.49006107e+00 -5.41755348e-01\n",
            "  -1.16748214e-02  1.84179112e+00]\n",
            " [-1.96057007e-01  1.67591488e-01 -4.46548969e-01  1.57364207e+00\n",
            "   7.12836079e-01  8.41031306e-01 -6.93758189e-01 -1.13758541e+00\n",
            "  -1.21432166e-01  4.32179953e-01]\n",
            " [-1.18902884e+00  1.53968645e-01  7.15296631e-03  6.84252444e-01\n",
            "  -1.04532001e+00  8.49172338e-01 -4.20993426e-01 -4.48084427e-01\n",
            "  -1.58122829e-02 -1.50445326e-02]\n",
            " [ 4.29754001e+00  1.84482447e+00  3.49564185e-01 -1.26445031e+00\n",
            "   1.67208203e-01 -2.03435087e+00  1.31231916e+00 -2.50387042e-01\n",
            "   1.90631102e+00 -1.96682912e+00]\n",
            " [ 1.39309490e+00  5.56403132e-01  1.60308951e-01  7.03829981e-01\n",
            "  -1.06670368e+00 -8.85351361e-01 -2.80529220e-01 -8.77616397e-01\n",
            "   8.26863347e-01 -1.67612503e+00]\n",
            " [ 1.25453615e+00 -1.09585299e+00 -1.08103152e-01 -2.85246922e+00\n",
            "  -1.16267201e+00 -6.53111631e-01 -8.57373891e-01 -1.26749326e+00\n",
            "   3.11407572e-02  1.23137695e+00]\n",
            " [-1.46743702e-01 -9.43673115e-01  1.65475333e+00 -4.17249247e-01\n",
            "   7.71264415e-01 -2.21848462e+00 -1.14691887e-01  9.63926105e-01\n",
            "  -1.18438568e-01  1.63534299e+00]\n",
            " [ 1.15483391e+00  4.34464327e-01  3.93290067e-01 -5.40008470e+00\n",
            "  -6.58334895e-01 -3.74907738e-01 -1.41611555e-01 -2.71791523e-01\n",
            "  -6.15540612e-01  5.02995166e+00]\n",
            " [ 6.84144849e-01 -1.43595713e+00 -1.04511258e+00 -5.28893043e-01\n",
            "  -1.23161507e+00 -1.35292300e+00  6.78433076e-01  1.99360402e-01\n",
            "  -1.31372530e+00 -1.34810931e+00]\n",
            " [ 4.10373132e+00 -7.82203372e-01  2.10349878e-01  1.64920996e-01\n",
            "   1.24189986e+00 -3.04123536e-01  8.49146897e-01 -2.30519269e+00\n",
            "   5.50689660e-01 -2.94977456e+00]\n",
            " [ 5.28577674e-02  7.65434462e-01  1.58340823e+00 -2.27641652e+00\n",
            "   4.16327772e-01  8.65797709e-02 -7.77249968e-01 -9.05410712e-04\n",
            "   7.23859020e-01  6.04106907e+00]\n",
            " [ 3.28387106e-01 -2.28986326e+00  1.59171146e-01  1.97732032e+00\n",
            "   1.41118835e+00 -7.81474646e-01  1.59279133e-02 -5.18267173e-01\n",
            "  -5.83126593e-01 -6.79365021e-01]\n",
            " [ 3.53626738e-01 -1.15211746e+00 -1.12159934e+00  2.71981678e-01\n",
            "   1.40136595e+00 -4.27549781e-01 -2.84710131e-01  3.25494097e-01\n",
            "  -1.23769283e+00  8.29975266e-01]\n",
            " [-6.72807553e-01 -1.39539147e+00  5.31031853e-02  5.44889648e-01\n",
            "   1.95042188e+00  7.80239841e-01  6.77848751e-01  1.27541377e+00\n",
            "  -1.19756701e-01  2.20537564e+00]\n",
            " [ 8.10819802e-02 -9.90712935e-02  4.47845897e-01  4.26572385e-01\n",
            "  -3.22653610e-01  8.55161491e-01 -1.45797387e+00  2.33972834e-01\n",
            "  -5.01437020e-01 -6.93621946e-01]\n",
            " [ 3.82218675e-01 -6.95748040e-02 -3.24467046e-01 -3.47141187e-01\n",
            "   2.07346250e+00 -4.25927450e-02 -2.27085566e-01  9.30086591e-01\n",
            "  -2.51196835e-01  1.08860212e+00]\n",
            " [ 4.80047529e+00 -2.26989131e-01 -3.27272311e-01 -7.04114984e-01\n",
            "   4.14779258e-01 -1.13569562e+00  1.31769772e+00  3.81679704e-02\n",
            "   1.35488671e+00 -1.91361559e+00]\n",
            " [ 7.22607280e-01  6.88038100e-01  5.48534881e-01 -1.56715187e-01\n",
            "   3.00254157e-01 -7.02257301e-01  7.15930457e-01 -7.07571535e-01\n",
            "   1.12434820e+00 -7.63653157e-01]]\n",
            "Biases [ 1.07871364  0.70190615  0.41362187  0.60893478  0.06611734  0.00692364\n",
            "  0.31411998 -0.00284873  0.84911997  1.0340079 ]\n",
            "A's [ 64.17927695   8.96807867   6.50791159 -32.29603653  -8.23793461\n",
            "  -5.33904403   0.2822304  -12.54094922  23.58315099  -5.49483768]\n",
            "**************************\n",
            "Loss: -0.0\n",
            "Data point number: 3\n",
            "Back prop starts ===========================\n",
            "current_H:[ 1 ]: [[ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.         23.81523426  0.          0.\n",
            "   9.97561797  6.58805261  0.          0.          0.         13.99626773\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.        ]]\n",
            "current_H shape:[ 1 ]: (32, 1)\n",
            "current_grad_L_by_A[ 1  ]: [[ 1.00000000e+00  1.54312244e-42  2.94425095e-52 -1.00000000e+00\n",
            "   1.77635522e-71  3.83008309e-70  3.32989633e-46  1.33543048e-66\n",
            "   2.80643809e-32  5.75972461e-71]]\n",
            "current_grad_L_by_A[ 1  ] shape: (1, 10)\n",
            "self.array_grad_L_by_weight[ 1 ]: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 2.38152343e+01  3.67498223e-41  7.01180261e-51 -2.38152343e+01\n",
            "   4.23043157e-70  9.12143260e-69  7.93022612e-45  3.18035897e-65\n",
            "   6.68359805e-31  1.37169191e-69]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 9.97561797e+00  1.53935999e-41  2.93707227e-51 -9.97561797e+00\n",
            "   1.77202411e-70  3.82074457e-69  3.32177737e-45  1.33217443e-65\n",
            "   2.79959542e-31  5.74568123e-70]\n",
            " [ 6.58805261e+00  1.01661718e-41  1.93968801e-51 -6.58805261e+00\n",
            "   1.17027216e-70  2.52327889e-69  2.19375322e-45  8.79788625e-66\n",
            "   1.84889618e-31  3.79453687e-70]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 1.39962677e+01  2.15979547e-41  4.12085245e-51 -1.39962677e+01\n",
            "   2.48623433e-70  5.36068683e-69  4.66061206e-45  1.86910425e-65\n",
            "   3.92796588e-31  8.06146477e-70]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]]\n",
            "number of non-zeros in weight gradient: 40\n",
            "self.array_grad_L_by_bias[ 1 ]: [[ 1.00000000e+00  1.54312244e-42  2.94425095e-52 -1.00000000e+00\n",
            "   1.77635522e-71  3.83008309e-70  3.32989633e-46  1.33543048e-66\n",
            "   2.80643809e-32  5.75972461e-71]]\n",
            "current_grad_H_by_A[ 1 ]: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "self.array_grad_L_by_A[ 0 ]: [[ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          3.39583897 -0.          0.\n",
            "   3.19297713  2.55421412 -0.         -0.         -0.          5.56199032\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.         -0.          0.         -0.         -0.          0.\n",
            "   0.          0.        ]]\n",
            "current_H:[ 0 ]: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.12941176 0.37647059 0.68627451 0.61176471\n",
            "  0.25098039 0.05490196 0.21176471 0.5372549  0.8        0.76078431\n",
            "  0.4        0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.28627451 0.72941176\n",
            "  0.69411765 0.71764706 0.68627451 0.7372549  0.90980392 1.\n",
            "  0.8745098  0.85882353 0.76078431 0.70196078 0.72941176 0.83529412\n",
            "  0.57254902 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.1372549  0.63921569 0.54901961 0.58823529 0.59607843\n",
            "  0.58823529 0.57254902 0.68627451 0.68627451 0.67843137 0.67058824\n",
            "  0.61176471 0.59607843 0.58039216 0.50588235 0.61176471 0.54901961\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.58823529\n",
            "  0.55686275 0.54901961 0.59607843 0.62745098 0.61176471 0.57254902\n",
            "  0.55686275 0.49803922 0.52941176 0.52156863 0.54901961 0.54901961\n",
            "  0.5372549  0.52156863 0.49019608 0.6627451  0.29411765 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.21176471 0.65490196 0.57254902\n",
            "  0.50588235 0.55686275 0.5372549  0.5372549  0.51372549 0.58039216\n",
            "  0.58039216 0.52156863 0.51372549 0.51372549 0.51372549 0.49019608\n",
            "  0.54901961 0.54901961 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.43137255 0.7372549  0.52156863 0.57254902\n",
            "  0.59607843 0.52156863 0.49019608 0.49803922 0.46666667 0.50588235\n",
            "  0.52156863 0.46666667 0.54901961 0.51372549 0.58823529 0.05490196\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.86666667 0.61960784 0.5372549  0.52941176 0.48235294\n",
            "  0.43137255 0.43137255 0.44705882 0.42352941 0.43921569 0.45882353\n",
            "  0.49803922 0.55686275 0.30196078 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.01568627 0.         0.09803922\n",
            "  0.61960784 0.5372549  0.49019608 0.46666667 0.46666667 0.43137255\n",
            "  0.45882353 0.45882353 0.43137255 0.46666667 0.49803922 0.56470588\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.48235294 0.61176471\n",
            "  0.50588235 0.43921569 0.43137255 0.4        0.43921569 0.39215686\n",
            "  0.4745098  0.45882353 0.50588235 0.44705882 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.49019608 0.6627451  0.49803922 0.46666667\n",
            "  0.41568627 0.42352941 0.40784314 0.36862745 0.4745098  0.44705882\n",
            "  0.50588235 0.35686275 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.00784314 0.\n",
            "  0.38431373 0.67058824 0.50588235 0.43921569 0.40784314 0.44705882\n",
            "  0.41568627 0.4        0.43921569 0.40784314 0.52156863 0.25098039\n",
            "  0.         0.01568627 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.00784314 0.         0.25882353 0.67843137\n",
            "  0.52941176 0.50588235 0.38431373 0.39215686 0.46666667 0.4\n",
            "  0.42352941 0.38431373 0.52941176 0.23529412 0.         0.01568627\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00784314 0.         0.21960784 0.67058824 0.52941176 0.49803922\n",
            "  0.39215686 0.42352941 0.45882353 0.33333333 0.41568627 0.43137255\n",
            "  0.52941176 0.25882353 0.         0.01568627 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.20392157 0.58823529 0.50588235 0.43137255 0.39215686 0.35686275\n",
            "  0.4        0.36862745 0.3254902  0.40784314 0.48235294 0.25882353\n",
            "  0.         0.01568627 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.00784314 0.         0.25882353 0.65490196\n",
            "  0.54901961 0.58039216 0.58039216 0.49803922 0.5372549  0.59607843\n",
            "  0.57254902 0.57254902 0.58039216 0.37647059 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.17647059 0.48235294 0.36862745 0.40784314\n",
            "  0.37647059 0.46666667 0.4745098  0.41568627 0.38431373 0.43921569\n",
            "  0.34117647 0.44705882 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.41568627 0.34901961 0.22745098 0.19607843 0.14509804 0.19607843\n",
            "  0.25882353 0.21960784 0.19607843 0.29411765 0.29411765 0.5372549\n",
            "  0.08627451 0.         0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00784314 0.         0.11372549 0.58039216 0.44705882\n",
            "  0.41568627 0.49019608 0.34901961 0.39215686 0.52156863 0.45882353\n",
            "  0.51372549 0.51372549 0.51372549 0.49019608 0.43921569 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.39215686 0.41568627 0.44705882 0.35686275 0.5372549\n",
            "  0.24313725 0.4        0.51372549 0.34901961 0.52941176 0.43921569\n",
            "  0.51372549 0.42352941 0.52941176 0.14509804 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.57254902\n",
            "  0.39215686 0.42352941 0.38431373 0.56470588 0.24313725 0.41568627\n",
            "  0.51372549 0.34117647 0.52156863 0.40784314 0.62745098 0.45882353\n",
            "  0.4745098  0.26666667 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.12941176 0.4745098  0.42352941 0.37647059\n",
            "  0.39215686 0.54901961 0.27843137 0.41568627 0.49803922 0.33333333\n",
            "  0.54901961 0.40784314 0.58823529 0.54901961 0.44705882 0.34901961\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.24313725 0.46666667 0.43921569 0.4        0.43137255 0.5372549\n",
            "  0.29411765 0.41568627 0.56470588 0.31764706 0.56470588 0.42352941\n",
            "  0.45882353 0.60392157 0.45882353 0.40784314 0.07058824 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.25882353 0.4745098\n",
            "  0.4        0.43921569 0.45882353 0.51372549 0.28627451 0.40784314\n",
            "  0.61176471 0.30196078 0.5372549  0.52941176 0.3254902  0.70196078\n",
            "  0.50588235 0.4745098  0.1372549  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.33333333 0.49803922 0.31764706 0.49019608\n",
            "  0.52156863 0.46666667 0.30980392 0.39215686 0.6627451  0.3254902\n",
            "  0.50588235 0.68627451 0.23529412 0.63921569 0.52941176 0.57254902\n",
            "  0.15294118 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.41568627 0.50588235 0.24313725 0.54901961 0.56470588 0.42352941\n",
            "  0.33333333 0.3254902  0.61960784 0.33333333 0.50588235 0.68627451\n",
            "  0.18823529 0.57254902 0.52156863 0.52941176 0.25098039 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.45882353 0.46666667\n",
            "  0.30980392 0.54901961 0.59607843 0.4        0.34901961 0.43137255\n",
            "  0.5372549  0.37647059 0.58823529 0.76862745 0.3254902  0.56470588\n",
            "  0.52941176 0.52156863 0.30196078 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60392157 0.4745098  0.34117647 0.54901961\n",
            "  0.60392157 0.43921569 0.36862745 0.20392157 0.55686275 0.39215686\n",
            "  0.3254902  0.59607843 0.33333333 0.62745098 0.52156863 0.39215686\n",
            "  0.04705882 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01568627 0.         0.00784314 0.         0.1372549  0.01568627\n",
            "  0.12941176 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "current_H shape:[ 0 ]: (784, 1)\n",
            "current_grad_L_by_A[ 0  ]: [[ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          3.39583897 -0.          0.\n",
            "   3.19297713  2.55421412 -0.         -0.         -0.          5.56199032\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.         -0.          0.         -0.         -0.          0.\n",
            "   0.          0.        ]]\n",
            "current_grad_L_by_A[ 0  ] shape: (1, 32)\n",
            "self.array_grad_L_by_weight[ 0 ]: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 1632\n",
            "self.array_grad_L_by_bias[ 0 ]: [[ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          3.39583897 -0.          0.\n",
            "   3.19297713  2.55421412 -0.         -0.         -0.          5.56199032\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.         -0.          0.         -0.         -0.          0.\n",
            "   0.          0.        ]]\n",
            "Predicted output: [1.00000000e+00 1.54312244e-42 2.94425095e-52 5.29329755e-91\n",
            " 1.77635522e-71 3.83008309e-70 3.32989633e-46 1.33543048e-66\n",
            " 2.80643809e-32 5.75972461e-71]\n",
            "Actual output: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n",
            "Biases [ 0.40095867  0.42796968  0.58445954  0.47352863  0.42884418  0.81738447\n",
            "  0.83994874  0.71621503  0.54533998  0.34619603  0.41275672 -0.16261835\n",
            "  0.32452941 -0.11921145  0.15830419  0.56508585 -0.28090036 -0.06971934\n",
            "  0.78152873 -0.0446727   0.02961634  0.18715803 -0.29346691 -0.0861715\n",
            " -0.40751469  0.48510933  0.19969615  0.40208716  0.83813795 -0.22711126\n",
            " -0.1313243   0.22424953]\n",
            "A's [-3.05190179e+01 -5.17688556e+00 -8.78569555e-02 -1.34564129e+01\n",
            " -3.03201185e+01 -1.39960524e+01 -1.28450487e+01 -8.65081721e+00\n",
            " -5.87394690e+00  2.38152343e+01 -1.16254566e+01 -5.90348096e+01\n",
            "  9.97561797e+00  6.58805261e+00 -1.26914910e+01 -7.21939711e+00\n",
            " -6.87536285e+01  1.39962677e+01 -1.01083834e+01 -6.91270901e+01\n",
            " -2.60446596e+01 -2.43423239e+01 -2.52846787e+01 -3.58748475e+01\n",
            " -1.03349407e+02 -1.37793763e+00 -1.55835886e+01 -6.24397425e+00\n",
            " -1.13397516e+01 -5.36544103e+01 -5.72818164e+01 -9.93859770e+00]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 1.10339862e+00  2.46523039e+00 -8.97014575e-01 -4.06045483e-03\n",
            "  -6.69532988e-01 -1.94642287e+00  1.76228313e-01 -3.03210110e-01\n",
            "   7.41851688e-01  1.86002719e-01]\n",
            " [ 1.45202164e+00  1.05731147e+00 -2.65268128e-01  7.12982227e-01\n",
            "   1.16339981e-01  1.34039607e+00 -7.20264578e-01  5.36020997e-01\n",
            "  -1.14732803e-01 -8.52383342e-01]\n",
            " [ 1.99404259e-01 -9.31578510e-01 -1.28533239e+00 -1.54053251e+00\n",
            "  -2.52165990e-01 -8.15235685e-01 -1.45862209e+00 -1.89727039e-01\n",
            "   1.01582961e+00  5.56040575e-01]\n",
            " [ 8.88009080e+00  2.04409738e-01  1.59754677e+00 -1.48469112e+00\n",
            "   2.51397538e+00  9.34496056e-01  8.30885034e-01 -4.15715379e-01\n",
            "  -5.28086871e-01 -5.86060047e+00]\n",
            " [ 1.04181311e+01  5.94458093e-01 -1.69647492e+00 -4.76095455e+00\n",
            "   4.52038471e-01 -5.10581933e-01  1.47763031e-01 -7.41804977e-01\n",
            "   6.14013681e-01 -1.74220087e+00]\n",
            " [ 1.60933497e+00  6.64103061e-01  7.77575698e-01 -9.43842109e-03\n",
            "   1.61623803e-01  8.45016415e-01 -1.40692164e-01  1.04953810e+00\n",
            "   1.21544638e+00  5.06843077e-01]\n",
            " [ 1.73782607e+00  2.82179697e-01  2.70231433e-01 -1.27763898e+00\n",
            "  -2.59392017e-01  1.05206840e+00  6.70836257e-01 -4.40261755e-01\n",
            "   5.59054517e-01  8.48724554e-02]\n",
            " [ 2.55241758e+00  7.39260273e-01 -1.48315104e+00 -1.54194667e+00\n",
            "  -1.83417412e+00 -1.39587437e+00  2.08574814e+00  1.55239094e+00\n",
            "   6.31537488e-01  3.17637238e+00]\n",
            " [ 1.31156607e+01 -1.24683987e+00 -2.80571263e-01 -3.98818035e+00\n",
            "  -6.81568306e-01  7.66138607e-01 -2.28656730e+00 -2.24667404e+00\n",
            "   6.70124736e-01 -4.49244979e+00]\n",
            " [-5.79737546e-01  7.11586925e-02 -3.00143268e-01  5.00498682e-01\n",
            "  -2.05799275e+00  1.21425460e-01 -8.13036872e-02 -8.81031380e-01\n",
            "   1.13257190e+00 -8.19278973e-01]\n",
            " [-1.50230842e-01  1.03930763e+00  7.29168297e-01  1.02620290e+00\n",
            "  -1.09021236e+00  2.75264079e-01 -1.96737026e-01  1.68387065e+00\n",
            "  -1.12253310e+00  6.89092159e-03]\n",
            " [ 1.22547863e-01  3.99198686e-01 -1.52415861e+00 -5.53662461e-01\n",
            "  -6.95304516e-01  1.80543543e-01 -3.37668606e-01 -1.28131826e+00\n",
            "   5.89818080e-02 -1.10254805e+00]\n",
            " [ 6.70465308e-01 -4.69021914e-01 -4.12058082e-01 -1.16604500e+00\n",
            "   1.12316593e-01 -9.67943868e-01  6.07025278e-01 -1.04595376e+00\n",
            "  -6.60798098e-01  1.56122079e+00]\n",
            " [ 2.21809007e+00  8.42468575e-01  1.92183715e+00  2.58228140e-01\n",
            "   1.20509059e+00  1.14726221e-01 -3.26866712e-01  1.14392147e+00\n",
            "   7.28845462e-01 -2.37299460e+00]\n",
            " [-1.20219080e+00  6.76892638e-01 -9.42912310e-01 -6.35034994e-01\n",
            "  -2.75746506e-01 -3.44998721e-02  1.49006107e+00 -6.65584929e-01\n",
            "  -1.16748214e-02  2.38286654e+00]\n",
            " [-1.96057007e-01  1.67591488e-01 -4.46548969e-01  1.57364207e+00\n",
            "   7.12836079e-01  8.41031306e-01 -6.93758189e-01 -1.13758541e+00\n",
            "  -1.21432166e-01  4.32179953e-01]\n",
            " [-8.97843981e-01  1.53968645e-01  7.15296631e-03  6.84252444e-01\n",
            "  -1.04532001e+00  8.49172338e-01 -4.20993426e-01 -4.48084427e-01\n",
            "  -1.58122829e-02 -3.06229388e-01]\n",
            " [ 4.45944699e+00  1.84482447e+00  3.49564185e-01 -6.49724212e-02\n",
            "   1.67208203e-01 -2.03435087e+00  1.31231916e+00 -3.09786921e-01\n",
            "   1.90631102e+00 -3.26881411e+00]\n",
            " [ 1.39309490e+00  5.56403132e-01  1.60308951e-01  7.03829981e-01\n",
            "  -1.06670368e+00 -8.85351361e-01 -2.80529220e-01 -8.77616397e-01\n",
            "   8.26863347e-01 -1.67612503e+00]\n",
            " [ 2.48729018e+00 -1.09585299e+00 -1.08103152e-01 -3.57789247e+00\n",
            "  -1.16267201e+00 -6.53111631e-01 -8.57373891e-01 -1.48278326e+00\n",
            "   3.11407572e-02  9.39336158e-01]\n",
            " [-1.46743702e-01 -9.43673115e-01  1.65475333e+00 -7.57901711e-01\n",
            "   7.71264415e-01 -2.21848462e+00 -1.14691887e-01  8.62827790e-01\n",
            "  -1.18438568e-01  2.07709377e+00]\n",
            " [ 1.15483391e+00  4.34464327e-01  3.93290067e-01 -6.82352990e+00\n",
            "  -6.58334895e-01 -3.74907738e-01 -1.41611555e-01 -6.94239402e-01\n",
            "  -6.15540612e-01  6.87584473e+00]\n",
            " [ 6.84144849e-01 -1.43595713e+00 -1.04511258e+00 -5.41500030e-01\n",
            "  -1.23161507e+00 -1.35292300e+00  6.78433076e-01  1.95618920e-01\n",
            "  -1.31372530e+00 -1.33176084e+00]\n",
            " [ 6.17656291e+00 -7.82203372e-01  2.10349878e-01 -8.75862634e-02\n",
            "   1.24189986e+00 -3.04123536e-01  8.49146897e-01 -2.38013141e+00\n",
            "   5.50689660e-01 -4.69516017e+00]\n",
            " [ 5.32053572e-01  7.65434462e-01  1.58340823e+00 -3.33763665e+00\n",
            "   4.16327772e-01  8.65797709e-02 -7.77249968e-01 -3.15852693e-01\n",
            "   7.23859020e-01  6.93804068e+00]\n",
            " [ 3.28387106e-01 -2.28986326e+00  1.59171146e-01  1.97732032e+00\n",
            "   1.41118835e+00 -7.81474646e-01  1.59279133e-02 -5.18267173e-01\n",
            "  -5.83126593e-01 -6.79365021e-01]\n",
            " [ 3.53626738e-01 -1.15211746e+00 -1.12159934e+00  2.71981678e-01\n",
            "   1.40136595e+00 -4.27549781e-01 -2.84710131e-01  3.25494097e-01\n",
            "  -1.23769283e+00  8.29975266e-01]\n",
            " [-6.72807553e-01 -1.39539147e+00  5.31031853e-02  4.01118246e-01\n",
            "   1.95042188e+00  7.80239841e-01  6.77848751e-01  1.23274551e+00\n",
            "  -1.19756701e-01  2.39181530e+00]\n",
            " [ 8.10819802e-02 -9.90712935e-02  4.47845897e-01  4.26572385e-01\n",
            "  -3.22653610e-01  8.55161491e-01 -1.45797387e+00  2.33972834e-01\n",
            "  -5.01437020e-01 -6.93621946e-01]\n",
            " [ 3.82218675e-01 -6.95748040e-02 -3.24467046e-01 -8.07005571e-01\n",
            "   2.07346250e+00 -4.25927450e-02 -2.27085566e-01  7.93608745e-01\n",
            "  -2.51196835e-01  1.68494435e+00]\n",
            " [ 7.17952920e+00 -2.26989131e-01 -3.27272311e-01 -1.19617338e+00\n",
            "   4.14779258e-01 -1.13569562e+00  1.31769772e+00 -1.07864366e-01\n",
            "   1.35488671e+00 -3.65457876e+00]\n",
            " [ 7.22607280e-01  6.88038100e-01  5.48534881e-01 -1.56715187e-01\n",
            "   3.00254157e-01 -7.02257301e-01  7.15930457e-01 -7.07571535e-01\n",
            "   1.12434820e+00 -7.63653157e-01]]\n",
            "Biases [ 1.05971364  0.70190615  0.41362187  0.6568152   0.06611734  0.00692364\n",
            "  0.31411998 -0.0183167   0.84911997  1.02059545]\n",
            "A's [125.36343416  29.08866818   6.70886376 -82.50536789 -37.5455438\n",
            " -34.47463585  20.64746106 -26.31792828  52.71262728 -36.36921778]\n",
            "**************************\n",
            "Loss: 299.89128988212855\n",
            "Data point number: 4\n",
            "Back prop starts ===========================\n",
            "current_H:[ 1 ]: [[ 0.          0.          3.13737352  0.          0.          0.\n",
            "   0.          0.          0.          5.52823212  0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.         12.47700382  0.          6.03078632  0.          0.\n",
            "   0.          0.        ]]\n",
            "current_H shape:[ 1 ]: (32, 1)\n",
            "current_grad_L_by_A[ 1  ]: [[-1.00000000e+00  9.78479370e-29  3.59971870e-13  9.99778010e-01\n",
            "   2.21989817e-04  6.91360381e-15  4.59675596e-12  7.68531548e-14\n",
            "   7.00789650e-11  4.61402312e-10]]\n",
            "current_grad_L_by_A[ 1  ] shape: (1, 10)\n",
            "self.array_grad_L_by_weight[ 1 ]: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-3.13737352e+00  3.06985527e-28  1.12936621e-12  3.13667706e+00\n",
            "   6.96464973e-04  2.16905576e-14  1.44217404e-11  2.41117053e-13\n",
            "   2.19863889e-10  1.44759140e-09]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-5.52823212e+00  5.40926108e-28  1.99000805e-12  5.52700491e+00\n",
            "   1.22721124e-03  3.82200067e-14  2.54119339e-11  4.24862079e-13\n",
            "   3.87412785e-10  2.55073908e-09]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-1.24770038e+01  1.22084908e-27  4.49137039e-12  1.24742340e+01\n",
            "   2.76976779e-03  8.62610612e-14  5.73537416e-11  9.58897107e-13\n",
            "   8.74375514e-10  5.75691841e-09]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-6.03078632e+00  5.90099999e-28  2.17091342e-12  6.02944754e+00\n",
            "   1.33877315e-03  4.16944673e-14  2.77220529e-11  4.63484954e-13\n",
            "   4.22631263e-10  2.78261875e-09]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]]\n",
            "number of non-zeros in weight gradient: 40\n",
            "self.array_grad_L_by_bias[ 1 ]: [[-1.00000000e+00  9.78479370e-29  3.59971870e-13  9.99778010e-01\n",
            "   2.21989817e-04  6.91360381e-15  4.59675596e-12  7.68531548e-14\n",
            "   7.00789650e-11  4.61402312e-10]]\n",
            "current_grad_H_by_A[ 1 ]: [[0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 1. 0. 1. 0. 0. 0. 0.]]\n",
            "self.array_grad_L_by_A[ 0 ]: [[-0.         -0.         -1.73965076 -0.         -0.         -0.\n",
            "  -0.         -0.         -0.          1.07966827  0.         -0.\n",
            "  -0.         -0.          0.          0.          0.         -0.\n",
            "  -0.         -0.         -0.         -0.         -0.         -0.\n",
            "  -0.          1.64880754 -0.          1.07426973  0.         -0.\n",
            "  -0.         -0.        ]]\n",
            "current_H:[ 0 ]: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: underflow encountered in double_scalars\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.10196078\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.74117647 0.80784314 0.73333333 0.1254902  0.         0.\n",
            "  0.         0.10196078 0.85098039 0.88627451 0.76862745 0.04313725\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.75294118 0.89019608\n",
            "  0.91764706 0.95294118 0.90196078 0.57647059 0.9372549  0.94901961\n",
            "  0.91764706 0.85490196 0.81960784 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.67843137 0.88235294 0.84313725 0.91372549\n",
            "  0.99607843 0.         0.76078431 0.94117647 0.85098039 0.86666667\n",
            "  0.74509804 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.54509804 0.89803922 0.83137255 0.88627451 1.         0.\n",
            "  0.63529412 1.         0.83529412 0.88627451 0.78431373 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.38431373 0.90980392\n",
            "  0.82745098 0.84313725 0.97647059 0.18039216 0.63529412 0.96470588\n",
            "  0.83921569 0.90196078 0.72941176 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.2745098  0.89411765 0.83529412 0.8627451\n",
            "  0.87843137 0.98823529 0.9372549  0.85882353 0.85098039 0.90588235\n",
            "  0.67058824 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.17647059 0.87058824 0.83921569 0.85490196 0.84705882 0.82352941\n",
            "  0.84313725 0.85098039 0.79215686 0.87843137 0.6745098  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.09411765 0.99607843\n",
            "  0.83921569 0.82352941 0.82745098 0.83921569 0.84313725 0.83137255\n",
            "  0.79607843 0.86666667 0.65490196 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99607843 0.84705882 0.84313725\n",
            "  0.85098039 0.85098039 0.84705882 0.84705882 0.80784314 0.88235294\n",
            "  0.58823529 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.96862745 0.84705882 0.83921569 0.85098039 0.84705882\n",
            "  0.83921569 0.83137255 0.79607843 0.88627451 0.53333333 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.96078431\n",
            "  0.84705882 0.83921569 0.84705882 0.85098039 0.84313725 0.82745098\n",
            "  0.8        0.88235294 0.49019608 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.96862745 0.84705882 0.83921569\n",
            "  0.85098039 0.8627451  0.85098039 0.83529412 0.79607843 0.87058824\n",
            "  0.57647059 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.97254902 0.84705882 0.84313725 0.85490196 0.87058824\n",
            "  0.84705882 0.83921569 0.81176471 0.85490196 0.70196078 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.97647059\n",
            "  0.84705882 0.85098039 0.85882353 0.87058824 0.85098039 0.83921569\n",
            "  0.82352941 0.84313725 0.82745098 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.14901961 1.         0.83921569 0.85490196\n",
            "  0.85882353 0.87843137 0.85490196 0.84313725 0.82745098 0.82745098\n",
            "  0.90588235 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.30980392 0.89019608 0.81960784 0.85882353 0.85882353 0.89019608\n",
            "  0.85882353 0.84313725 0.83529412 0.80784314 0.99607843 0.22745098\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.57254902 0.88627451\n",
            "  0.82745098 0.8627451  0.85882353 0.89411765 0.85490196 0.84313725\n",
            "  0.84705882 0.80392157 0.85882353 0.63921569 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.79215686 0.86666667 0.83921569 0.86666667\n",
            "  0.85882353 0.90588235 0.85490196 0.84313725 0.85490196 0.83529412\n",
            "  0.83137255 0.8627451  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.91764706 0.85098039 0.84705882 0.8627451  0.85882353 0.91764706\n",
            "  0.85098039 0.84313725 0.85490196 0.84705882 0.8745098  0.96862745\n",
            "  0.02745098 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.06666667 0.99607843 0.83137255\n",
            "  0.85882353 0.85882353 0.8627451  0.91372549 0.83921569 0.84705882\n",
            "  0.85882353 0.87058824 0.6        0.93333333 0.22745098 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.25882353 1.         0.81568627 0.8627451  0.85882353\n",
            "  0.87058824 0.94509804 0.8627451  0.85490196 0.85490196 0.85490196\n",
            "  0.75294118 0.94901961 0.38823529 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.55686275\n",
            "  0.92156863 0.79607843 0.85490196 0.84705882 0.90588235 0.94901961\n",
            "  0.88235294 0.91372549 0.85882353 0.83921569 0.84705882 0.93333333\n",
            "  0.56470588 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.69411765 0.97254902 0.89019608\n",
            "  0.89803922 0.82745098 1.         0.29803922 0.         0.96862745\n",
            "  0.95294118 0.90196078 0.90196078 0.97647059 0.73333333 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.39607843 0.94509804 0.89411765 0.89411765 0.8627451\n",
            "  1.         0.25098039 0.         0.95294118 0.92941176 0.90196078\n",
            "  0.89019608 0.94509804 0.55686275 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  1.         0.94901961 0.87058824 0.85490196 1.         0.24313725\n",
            "  0.         0.8745098  0.93333333 0.88235294 0.93333333 1.\n",
            "  0.12156863 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.17647059 1.\n",
            "  0.94901961 0.92156863 1.         0.32941176 0.         0.96470588\n",
            "  1.         0.94901961 1.         0.2745098  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.23921569 0.4\n",
            "  0.65882353 0.09803922 0.         0.54509804 0.63137255 0.29019608\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "current_H shape:[ 0 ]: (784, 1)\n",
            "current_grad_L_by_A[ 0  ]: [[-0.         -0.         -1.73965076 -0.         -0.         -0.\n",
            "  -0.         -0.         -0.          1.07966827  0.         -0.\n",
            "  -0.         -0.          0.          0.          0.         -0.\n",
            "  -0.         -0.         -0.         -0.         -0.         -0.\n",
            "  -0.          1.64880754 -0.          1.07426973  0.         -0.\n",
            "  -0.         -0.        ]]\n",
            "current_grad_L_by_A[ 0  ] shape: (1, 32)\n",
            "self.array_grad_L_by_weight[ 0 ]: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 1212\n",
            "self.array_grad_L_by_bias[ 0 ]: [[-0.         -0.         -1.73965076 -0.         -0.         -0.\n",
            "  -0.         -0.         -0.          1.07966827  0.         -0.\n",
            "  -0.         -0.          0.          0.          0.         -0.\n",
            "  -0.         -0.         -0.         -0.         -0.         -0.\n",
            "  -0.          1.64880754 -0.          1.07426973  0.         -0.\n",
            "  -0.         -0.        ]]\n",
            "Predicted output: [1.60058534e-12 9.78479370e-29 3.59971870e-13 9.99778010e-01\n",
            " 2.21989817e-04 6.91360381e-15 4.59675596e-12 7.68531548e-14\n",
            " 7.00789650e-11 4.61402312e-10]\n",
            "Actual output: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n",
            "Biases [ 0.31058731  0.42796968  0.76456609  0.3858459   0.26797069  0.81738447\n",
            "  0.83994874  0.69874335  0.52368245 -0.01630545  0.41275672 -0.3443963\n",
            "  0.0699548  -0.31917916  0.08657892  0.56508585 -0.46606904 -0.53398812\n",
            "  0.78152873 -0.25183565 -0.0292793   0.062732   -0.35952578 -0.20615407\n",
            " -0.74251386  0.32022858  0.19969615  0.31605858  0.83813795 -0.37965774\n",
            " -0.32849025  0.22424953]\n",
            "A's [ -63.74110707  -18.9067486     3.13737352  -28.87803455  -79.18107351\n",
            "  -19.37825772  -17.30550368  -15.22944726   -0.52920415    5.52823212\n",
            "   -8.05307864 -123.04707527  -28.28985245   -6.69067343  -26.52216534\n",
            "  -13.65170522 -129.43371571  -31.10985352  -15.33690141 -134.80953859\n",
            "  -59.16234931  -65.14462256  -57.26118682  -66.21549166 -218.95740877\n",
            "   12.47700382  -33.66797477    6.03078632  -21.35249864 -116.99988661\n",
            " -123.60834836  -12.59195652]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 1.39352687e+00  2.46523039e+00 -8.97014575e-01 -4.06045483e-03\n",
            "  -6.69532988e-01 -1.94642287e+00  1.76228313e-01 -3.03210110e-01\n",
            "   7.41851688e-01 -1.04125537e-01]\n",
            " [ 1.45202164e+00  1.05731147e+00 -2.65268128e-01  7.12982227e-01\n",
            "   1.16339981e-01  1.34039607e+00 -7.20264578e-01  5.36020997e-01\n",
            "  -1.14732803e-01 -8.52383342e-01]\n",
            " [ 5.13141612e-01 -9.31578510e-01 -1.28533239e+00 -2.00484248e+00\n",
            "  -2.52235636e-01 -8.15235685e-01 -1.45862209e+00 -2.34434420e-01\n",
            "   1.01582961e+00  7.51390224e-01]\n",
            " [ 1.12611959e+01  2.04409738e-01  1.59754677e+00 -1.87638609e+00\n",
            "   2.51397538e+00  9.34496056e-01  8.30885034e-01 -5.31962009e-01\n",
            "  -5.28086871e-01 -7.73376400e+00]\n",
            " [ 1.30686989e+01  5.94458093e-01 -1.69647492e+00 -5.78592906e+00\n",
            "   4.52038471e-01 -5.10581933e-01  1.47763031e-01 -1.04599534e+00\n",
            "   6.14013681e-01 -3.06360378e+00]\n",
            " [ 1.60933497e+00  6.64103061e-01  7.77575698e-01 -9.43842109e-03\n",
            "   1.61623803e-01  8.45016415e-01 -1.40692164e-01  1.04953810e+00\n",
            "   1.21544638e+00  5.06843077e-01]\n",
            " [ 1.73782607e+00  2.82179697e-01  2.70231433e-01 -1.27763898e+00\n",
            "  -2.59392017e-01  1.05206840e+00  6.70836257e-01 -4.40261755e-01\n",
            "   5.59054517e-01  8.48724554e-02]\n",
            " [ 2.85197775e+00  7.39260273e-01 -1.48315104e+00 -1.90999574e+00\n",
            "  -1.83417412e+00 -1.39587437e+00  2.08574814e+00  1.44316190e+00\n",
            "   6.31537488e-01  3.35409032e+00]\n",
            " [ 1.62776113e+01 -1.24683987e+00 -2.80571263e-01 -4.75159842e+00\n",
            "  -6.81568306e-01  7.66138607e-01 -2.28656730e+00 -2.47324008e+00\n",
            "   6.70124736e-01 -6.66441626e+00]\n",
            " [-1.91201093e+00  7.11586925e-02 -3.00143268e-01  2.09116927e+00\n",
            "  -2.05811548e+00  1.21425460e-01 -8.13036872e-02 -8.81031380e-01\n",
            "   1.13257190e+00 -1.07755346e+00]\n",
            " [-1.50230842e-01  1.03930763e+00  7.29168297e-01  1.02620290e+00\n",
            "  -1.09021236e+00  2.75264079e-01 -1.96737026e-01  1.68387065e+00\n",
            "  -1.12253310e+00  6.89092159e-03]\n",
            " [ 6.22709192e-01  3.99198686e-01 -1.52415861e+00 -5.53662461e-01\n",
            "  -6.95304516e-01  1.80543543e-01 -3.37668606e-01 -1.28131826e+00\n",
            "   5.89818080e-02 -1.60270937e+00]\n",
            " [ 2.24184177e-02 -4.69021914e-01 -4.12058082e-01 -5.93271762e-01\n",
            "   1.12316593e-01 -9.67943868e-01  6.07025278e-01 -1.14241637e+00\n",
            "  -6.60798098e-01  1.73295705e+00]\n",
            " [ 2.27609783e+00  8.42468575e-01  1.92183715e+00  8.51152875e-01\n",
            "   1.20509059e+00  1.14726221e-01 -3.26866712e-01  1.14392147e+00\n",
            "   7.28845462e-01 -3.02392710e+00]\n",
            " [-1.20219080e+00  6.76892638e-01 -9.42912310e-01 -1.01055625e+00\n",
            "  -2.75746506e-01 -3.44998721e-02  1.49006107e+00 -7.77031552e-01\n",
            "  -1.16748214e-02  2.86983442e+00]\n",
            " [-1.96057007e-01  1.67591488e-01 -4.46548969e-01  1.57364207e+00\n",
            "   7.12836079e-01  8.41031306e-01 -6.93758189e-01 -1.13758541e+00\n",
            "  -1.21432166e-01  4.32179953e-01]\n",
            " [-6.35777612e-01  1.53968645e-01  7.15296631e-03  6.84252444e-01\n",
            "  -1.04532001e+00  8.49172338e-01 -4.20993426e-01 -4.48084427e-01\n",
            "  -1.58122829e-02 -5.68295758e-01]\n",
            " [ 4.60516327e+00  1.84482447e+00  3.49564185e-01  1.01455768e+00\n",
            "   1.67208203e-01 -2.03435087e+00  1.31231916e+00 -3.63246812e-01\n",
            "   1.90631102e+00 -4.44060060e+00]\n",
            " [ 1.39309490e+00  5.56403132e-01  1.60308951e-01  7.03829981e-01\n",
            "  -1.06670368e+00 -8.85351361e-01 -2.80529220e-01 -8.77616397e-01\n",
            "   8.26863347e-01 -1.67612503e+00]\n",
            " [ 3.59676881e+00 -1.09585299e+00 -1.08103152e-01 -4.23077338e+00\n",
            "  -1.16267201e+00 -6.53111631e-01 -8.57373891e-01 -1.67654426e+00\n",
            "   3.11407572e-02  6.76499442e-01]\n",
            " [-1.46743702e-01 -9.43673115e-01  1.65475333e+00 -1.06448893e+00\n",
            "   7.71264415e-01 -2.21848462e+00 -1.14691887e-01  7.71839306e-01\n",
            "  -1.18438568e-01  2.47466947e+00]\n",
            " [ 1.15483391e+00  4.34464327e-01  3.93290067e-01 -8.10463057e+00\n",
            "  -6.58334895e-01 -3.74907738e-01 -1.41611555e-01 -1.07444249e+00\n",
            "  -6.15540612e-01  8.53714850e+00]\n",
            " [ 6.84144849e-01 -1.43595713e+00 -1.04511258e+00 -5.52846318e-01\n",
            "  -1.23161507e+00 -1.35292300e+00  6.78433076e-01  1.92251586e-01\n",
            "  -1.31372530e+00 -1.31704722e+00]\n",
            " [ 8.04211134e+00 -7.82203372e-01  2.10349878e-01 -3.14842797e-01\n",
            "   1.24189986e+00 -3.04123536e-01  8.49146897e-01 -2.44757625e+00\n",
            "   5.50689660e-01 -6.26600722e+00]\n",
            " [ 9.63329797e-01  7.65434462e-01  1.58340823e+00 -4.29273477e+00\n",
            "   4.16327772e-01  8.65797709e-02 -7.77249968e-01 -5.99305247e-01\n",
            "   7.23859020e-01  7.74531513e+00]\n",
            " [ 1.57608749e+00 -2.28986326e+00  1.59171146e-01  7.29896919e-01\n",
            "   1.41091137e+00 -7.81474646e-01  1.59279133e-02 -5.18267173e-01\n",
            "  -5.83126593e-01 -6.79365021e-01]\n",
            " [ 3.53626738e-01 -1.15211746e+00 -1.12159934e+00  2.71981678e-01\n",
            "   1.40136595e+00 -4.27549781e-01 -2.84710131e-01  3.25494097e-01\n",
            "  -1.23769283e+00  8.29975266e-01]\n",
            " [-6.97289210e-02 -1.39539147e+00  5.31031853e-02 -3.31220769e-01\n",
            "   1.95028801e+00  7.80239841e-01  6.77848751e-01  1.19434408e+00\n",
            "  -1.19756701e-01  2.55961099e+00]\n",
            " [ 8.10819802e-02 -9.90712935e-02  4.47845897e-01  4.26572385e-01\n",
            "  -3.22653610e-01  8.55161491e-01 -1.45797387e+00  2.33972834e-01\n",
            "  -5.01437020e-01 -6.93621946e-01]\n",
            " [ 3.82218675e-01 -6.95748040e-02 -3.24467046e-01 -1.22088352e+00\n",
            "   2.07346250e+00 -4.25927450e-02 -2.27085566e-01  6.70778684e-01\n",
            "  -2.51196835e-01  2.22165236e+00]\n",
            " [ 9.32067771e+00 -2.26989131e-01 -3.27272311e-01 -1.63902594e+00\n",
            "   4.14779258e-01 -1.13569562e+00  1.31769772e+00 -2.39293469e-01\n",
            "   1.35488671e+00 -5.22144561e+00]\n",
            " [ 7.22607280e-01  6.88038100e-01  5.48534881e-01 -1.56715187e-01\n",
            "   3.00254157e-01 -7.02257301e-01  7.15930457e-01 -7.07571535e-01\n",
            "   1.12434820e+00 -7.63653157e-01]]\n",
            "Biases [ 1.14261364  0.70190615  0.41362187  0.59992978  0.06609515  0.00692364\n",
            "  0.31411998 -0.03223787  0.84911997  1.00852424]\n",
            "A's [ -1.47987584 -38.8133623   -2.97197463  25.68055386  17.26789683\n",
            "  -6.92450948  -0.42489441  -4.516104     2.29937744   4.18402512]\n",
            "**************************\n",
            "Loss: 39.18453753707892\n",
            "Data point number: 5\n",
            "Back prop starts ===========================\n",
            "current_H:[ 1 ]: [[ 0.          0.         26.56744119  0.          0.          0.\n",
            "   0.          7.48359827  0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          3.99606646  0.          0.\n",
            "   0.          0.        ]]\n",
            "current_H shape:[ 1 ]: (32, 1)\n",
            "current_grad_L_by_A[ 1  ]: [[ 1.30092223e-09  1.22005626e-35 -1.00000000e+00  7.85597274e-55\n",
            "   1.23314858e-30  9.18965392e-38  6.47343106e-34  3.92108594e-21\n",
            "   3.04373885e-11  9.99999999e-01]]\n",
            "current_grad_L_by_A[ 1  ] shape: (1, 10)\n",
            "self.array_grad_L_by_weight[ 1 ]: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 3.45621748e-08  3.24137730e-34 -2.65674412e+01  2.08713094e-53\n",
            "   3.27616023e-29  2.44145590e-36  1.71982499e-32  1.04173220e-19\n",
            "   8.08643528e-10  2.65674412e+01]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 9.73557933e-09  9.13041093e-35 -7.48359827e+00  5.87909440e-54\n",
            "   9.22838856e-30  6.87716782e-37  4.84445575e-33  2.93438319e-20\n",
            "   2.27781188e-10  7.48359826e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 5.19857168e-09  4.87542590e-35 -3.99606646e+00  3.13929892e-54\n",
            "   4.92774367e-30  3.67224678e-37  2.58682607e-33  1.56689200e-20\n",
            "   1.21629827e-10  3.99606645e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]]\n",
            "number of non-zeros in weight gradient: 30\n",
            "self.array_grad_L_by_bias[ 1 ]: [[ 1.30092223e-09  1.22005626e-35 -1.00000000e+00  7.85597274e-55\n",
            "   1.23314858e-30  9.18965392e-38  6.47343106e-34  3.92108594e-21\n",
            "   3.04373885e-11  9.99999999e-01]]\n",
            "current_grad_H_by_A[ 1 ]: [[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "self.array_grad_L_by_A[ 0 ]: [[ 0.         -0.          2.03672261 -0.         -0.         -0.\n",
            "  -0.          4.83724136 -0.         -0.         -0.         -0.\n",
            "   0.         -0.          0.          0.         -0.         -0.\n",
            "  -0.          0.          0.          0.         -0.         -0.\n",
            "   0.         -0.          0.          2.5065078  -0.          0.\n",
            "  -0.         -0.        ]]\n",
            "current_H:[ 0 ]: [[0.         0.         0.         0.         0.00392157 0.\n",
            "  0.         0.         0.         0.08627451 0.34509804 0.7372549\n",
            "  0.6745098  0.51764706 0.49019608 0.55294118 0.78039216 0.56078431\n",
            "  0.03529412 0.         0.         0.         0.00392157 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.         0.         0.07843137 0.51372549\n",
            "  0.78039216 0.80784314 0.76862745 0.79215686 0.94901961 1.\n",
            "  1.         0.98039216 0.87058824 0.77254902 0.80784314 0.7372549\n",
            "  0.49411765 0.06666667 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.1372549  0.83921569 0.74901961 0.71764706 0.69803922\n",
            "  0.68627451 0.65882353 0.58823529 0.63529412 0.62352941 0.59607843\n",
            "  0.61960784 0.70196078 0.71764706 0.74117647 0.76470588 0.7254902\n",
            "  0.32156863 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.66666667\n",
            "  0.74509804 0.6745098  0.69411765 0.69019608 0.67058824 0.6627451\n",
            "  0.63529412 0.60784314 0.58039216 0.60392157 0.6627451  0.68235294\n",
            "  0.68627451 0.68627451 0.69411765 0.71764706 0.7372549  0.04705882\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.09803922 0.76078431 0.70588235 0.69803922\n",
            "  0.68235294 0.72156863 0.73333333 0.74117647 0.73333333 0.72156863\n",
            "  0.70980392 0.74117647 0.78431373 0.77254902 0.75686275 0.74509804\n",
            "  0.69803922 0.68627451 0.76078431 0.35294118 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.16470588 0.85490196 0.74901961 0.77254902 0.81568627 0.8\n",
            "  0.82745098 0.81960784 0.82352941 0.83137255 0.82745098 0.83921569\n",
            "  0.84313725 0.83529412 0.83921569 0.82745098 0.82745098 0.74901961\n",
            "  0.78431373 0.61960784 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.34509804 0.86666667\n",
            "  0.84313725 0.85098039 0.85882353 0.82745098 0.7254902  0.58823529\n",
            "  0.4627451  0.41960784 0.38823529 0.34509804 0.3254902  0.35294118\n",
            "  0.52941176 0.83137255 0.79607843 0.81176471 0.85882353 0.6627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.10588235 0.4627451  0.63529412\n",
            "  0.15686275 0.         0.         0.         0.03921569 0.0745098\n",
            "  0.10980392 0.15294118 0.18431373 0.14117647 0.         0.\n",
            "  0.79607843 0.90196078 0.8627451  0.79607843 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.54117647 0.53333333 0.27843137 0.27058824 0.21176471 0.84705882\n",
            "  0.85098039 0.79607843 0.72156863 0.65882353 0.63921569 0.63529412\n",
            "  0.63921569 0.69803922 0.86666667 0.72941176 0.14901961 0.10196078\n",
            "  0.02745098 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.2627451  0.5254902\n",
            "  0.60392157 0.87843137 0.50588235 0.25882353 0.31764706 0.45882353\n",
            "  0.50588235 0.50196078 0.51764706 0.5372549  0.51372549 0.50588235\n",
            "  0.3372549  0.28627451 0.61568627 0.59215686 0.5254902  0.84705882\n",
            "  0.07058824 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.79607843 0.77647059 0.6745098  0.71764706\n",
            "  0.80784314 1.         1.         0.98039216 0.95294118 0.94117647\n",
            "  0.9372549  0.92156863 0.93333333 0.95686275 1.         0.93333333\n",
            "  0.72156863 0.62745098 0.3372549  0.38431373 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.47843137 0.7372549  0.87843137 0.59215686 0.41176471 0.49803922\n",
            "  0.38039216 0.39215686 0.41176471 0.44705882 0.45882353 0.45882353\n",
            "  0.44313725 0.40392157 0.38431373 0.43529412 0.55686275 0.99607843\n",
            "  0.74901961 1.         0.19215686 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.63921569 0.70196078\n",
            "  0.78431373 0.37254902 0.60392157 0.77647059 0.77254902 0.78431373\n",
            "  0.78431373 0.77647059 0.77254902 0.77647059 0.78039216 0.79215686\n",
            "  0.78431373 0.69019608 0.3372549  0.80784314 0.61568627 0.63529412\n",
            "  0.03921569 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.77254902 0.78823529 0.89803922 0.27843137\n",
            "  0.56470588 0.76078431 0.70980392 0.71764706 0.70196078 0.71372549\n",
            "  0.70588235 0.70196078 0.70588235 0.74509804 0.7254902  0.77254902\n",
            "  0.29803922 0.85882353 0.7254902  0.78823529 0.13333333 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.78039216 0.75686275 0.88627451 0.22745098 0.60392157 0.75294118\n",
            "  0.72156863 0.73333333 0.72156863 0.72941176 0.72156863 0.7254902\n",
            "  0.71764706 0.75294118 0.74901961 0.78431373 0.21960784 0.85882353\n",
            "  0.79607843 0.81176471 0.23529412 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.78823529 0.76078431\n",
            "  0.87843137 0.16078431 0.63921569 0.74509804 0.72941176 0.72941176\n",
            "  0.72156863 0.7254902  0.71764706 0.7254902  0.69803922 0.74509804\n",
            "  0.76078431 0.79215686 0.12941176 0.82745098 0.78431373 0.80784314\n",
            "  0.28627451 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.78823529 0.77254902 0.87058824 0.06666667\n",
            "  0.6745098  0.74509804 0.72941176 0.73333333 0.71372549 0.72941176\n",
            "  0.7254902  0.73333333 0.70588235 0.73333333 0.75686275 0.79215686\n",
            "  0.10196078 0.83137255 0.79215686 0.79607843 0.29803922 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.78431373 0.77254902 0.8745098  0.         0.69411765 0.74117647\n",
            "  0.72156863 0.7254902  0.69803922 0.72156863 0.71764706 0.72156863\n",
            "  0.70588235 0.71764706 0.74117647 0.79607843 0.1372549  0.76862745\n",
            "  0.79607843 0.79607843 0.32941176 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.78431373 0.77254902\n",
            "  0.8745098  0.         0.7254902  0.73333333 0.7254902  0.73333333\n",
            "  0.70588235 0.72156863 0.71372549 0.71764706 0.69803922 0.71372549\n",
            "  0.71764706 0.80392157 0.17254902 0.62352941 0.81176471 0.78823529\n",
            "  0.33333333 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.73333333 0.77647059 0.88235294 0.\n",
            "  0.76078431 0.7372549  0.72156863 0.7254902  0.70588235 0.71764706\n",
            "  0.71764706 0.72156863 0.70980392 0.70980392 0.69411765 0.80784314\n",
            "  0.18039216 0.50588235 0.82745098 0.78431373 0.34509804 0.\n",
            "  0.         0.         0.         0.         0.         0.02352941\n",
            "  0.72941176 0.78431373 0.82745098 0.         0.78039216 0.74117647\n",
            "  0.72156863 0.72156863 0.7254902  0.71372549 0.71764706 0.72156863\n",
            "  0.7254902  0.71372549 0.68627451 0.80392157 0.19607843 0.38039216\n",
            "  0.84705882 0.77254902 0.36470588 0.         0.         0.\n",
            "  0.         0.         0.         0.01960784 0.7254902  0.8\n",
            "  0.72156863 0.         0.79215686 0.7372549  0.71372549 0.71372549\n",
            "  0.71764706 0.71764706 0.72156863 0.71372549 0.70588235 0.71372549\n",
            "  0.68235294 0.79215686 0.24705882 0.23137255 0.8627451  0.76862745\n",
            "  0.36862745 0.         0.         0.         0.         0.\n",
            "  0.         0.01960784 0.72156863 0.80784314 0.61568627 0.\n",
            "  0.8        0.73333333 0.73333333 0.74117647 0.75294118 0.74509804\n",
            "  0.74509804 0.74901961 0.74509804 0.73333333 0.71764706 0.79215686\n",
            "  0.30588235 0.1372549  0.87058824 0.77254902 0.37254902 0.\n",
            "  0.         0.         0.         0.         0.         0.01960784\n",
            "  0.71764706 0.81568627 0.49803922 0.         0.77254902 0.65098039\n",
            "  0.6        0.58431373 0.58431373 0.57254902 0.58039216 0.58431373\n",
            "  0.58823529 0.59215686 0.61960784 0.74901961 0.35294118 0.03137255\n",
            "  0.8745098  0.76470588 0.38823529 0.         0.         0.\n",
            "  0.         0.         0.         0.02352941 0.72156863 0.81568627\n",
            "  0.44705882 0.         0.8        0.67843137 0.63137255 0.70588235\n",
            "  0.69019608 0.6745098  0.67843137 0.67843137 0.68235294 0.69019608\n",
            "  0.63529412 0.79215686 0.45098039 0.         0.89803922 0.78039216\n",
            "  0.41176471 0.         0.         0.         0.         0.\n",
            "  0.         0.03529412 0.69803922 0.8        0.45098039 0.\n",
            "  0.4745098  0.52941176 0.44705882 0.45882353 0.44705882 0.44705882\n",
            "  0.45882353 0.4627451  0.46666667 0.45882353 0.44313725 0.57647059\n",
            "  0.24705882 0.         0.88235294 0.76862745 0.41960784 0.\n",
            "  0.         0.         0.         0.         0.         0.07058824\n",
            "  0.70588235 0.80784314 0.51372549 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.87843137 0.77254902 0.48235294 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.55294118 0.59215686\n",
            "  0.29803922 0.         0.00392157 0.00392157 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.52156863 0.65490196\n",
            "  0.28627451 0.         0.         0.        ]]\n",
            "current_H shape:[ 0 ]: (784, 1)\n",
            "current_grad_L_by_A[ 0  ]: [[ 0.         -0.          2.03672261 -0.         -0.         -0.\n",
            "  -0.          4.83724136 -0.         -0.         -0.         -0.\n",
            "   0.         -0.          0.          0.         -0.         -0.\n",
            "  -0.          0.          0.          0.         -0.         -0.\n",
            "   0.         -0.          0.          2.5065078  -0.          0.\n",
            "  -0.         -0.        ]]\n",
            "current_grad_L_by_A[ 0  ] shape: (1, 32)\n",
            "self.array_grad_L_by_weight[ 0 ]: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 1578\n",
            "self.array_grad_L_by_bias[ 0 ]: [[ 0.         -0.          2.03672261 -0.         -0.         -0.\n",
            "  -0.          4.83724136 -0.         -0.         -0.         -0.\n",
            "   0.         -0.          0.          0.         -0.         -0.\n",
            "  -0.          0.          0.          0.         -0.         -0.\n",
            "   0.         -0.          0.          2.5065078  -0.          0.\n",
            "  -0.         -0.        ]]\n",
            "Predicted output: [1.30092223e-09 1.22005626e-35 1.48021988e-44 7.85597274e-55\n",
            " 1.23314858e-30 9.18965392e-38 6.47343106e-34 3.92108594e-21\n",
            " 3.04373885e-11 9.99999999e-01]\n",
            "Actual output: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n",
            "Biases [ 0.22925309  0.42796968  0.72298973  0.30693145  0.12318455  0.81738447\n",
            "  0.83994874  0.1992947   0.50419067 -0.34255678  0.41275672 -0.50799645\n",
            " -0.15916235 -0.4991501   0.02202618  0.56508585 -0.63272085 -0.95183002\n",
            "  0.78152873 -0.43828231 -0.08228538 -0.04925142 -0.41897877 -0.31413838\n",
            " -1.04401311  0.1718359   0.19969615 -0.01201792  0.83813795 -0.51694956\n",
            " -0.5059396   0.22424953]\n",
            "A's [ -89.37831922  -16.62683312   26.56744119  -65.63236497 -116.17769296\n",
            "  -21.64117259   -3.51941469    7.48359827   -1.35903153  -59.44714512\n",
            "  -10.71736858 -177.8626613   -33.60802607  -39.34725662  -66.14547637\n",
            "   -5.35647124 -185.90210727  -82.60734399  -18.28366207 -171.02864521\n",
            "  -68.67710229  -99.24233483  -63.59520582 -107.92345332 -296.46725423\n",
            "  -26.15862049  -33.3458314     3.99606646  -16.35480365 -149.80238391\n",
            " -166.28949023  -14.57522494]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 1.65464230e+00  2.46523039e+00 -8.97014575e-01 -4.06045483e-03\n",
            "  -6.69532988e-01 -1.94642287e+00  1.76228313e-01 -3.03210110e-01\n",
            "   7.41851688e-01 -3.65240968e-01]\n",
            " [ 1.45202164e+00  1.05731147e+00 -2.65268128e-01  7.12982227e-01\n",
            "   1.16339981e-01  1.34039607e+00 -7.20264578e-01  5.36020997e-01\n",
            "  -1.14732803e-01 -8.52383342e-01]\n",
            " [ 7.95505225e-01 -9.31578510e-01  1.37141173e+00 -2.42272146e+00\n",
            "  -2.52298318e-01 -8.15235685e-01 -1.45862209e+00 -2.74671063e-01\n",
            "   1.01582961e+00 -1.72953921e+00]\n",
            " [ 1.34041905e+01  2.04409738e-01  1.59754677e+00 -2.22891155e+00\n",
            "   2.51397538e+00  9.34496056e-01  8.30885034e-01 -6.36583976e-01\n",
            "  -5.28086871e-01 -9.41961118e+00]\n",
            " [ 1.54542099e+01  5.94458093e-01 -1.69647492e+00 -6.70840612e+00\n",
            "   4.52038471e-01 -5.10581933e-01  1.47763031e-01 -1.31976667e+00\n",
            "   6.14013681e-01 -4.25286641e+00]\n",
            " [ 1.60933497e+00  6.64103061e-01  7.77575698e-01 -9.43842109e-03\n",
            "   1.61623803e-01  8.45016415e-01 -1.40692164e-01  1.04953810e+00\n",
            "   1.21544638e+00  5.06843077e-01]\n",
            " [ 1.73782607e+00  2.82179697e-01  2.70231433e-01 -1.27763898e+00\n",
            "  -2.59392017e-01  1.05206840e+00  6.70836257e-01 -4.40261755e-01\n",
            "   5.59054517e-01  8.48724554e-02]\n",
            " [ 3.12158191e+00  7.39260273e-01 -7.34791213e-01 -2.24123991e+00\n",
            "  -1.83417412e+00 -1.39587437e+00  2.08574814e+00  1.34485577e+00\n",
            "   6.31537488e-01  2.76567664e+00]\n",
            " [ 1.91233668e+01 -1.24683987e+00 -2.80571263e-01 -5.43867468e+00\n",
            "  -6.81568306e-01  7.66138607e-01 -2.28656730e+00 -2.67714952e+00\n",
            "   6.70124736e-01 -8.61918609e+00]\n",
            " [-3.11105697e+00  7.11586925e-02 -3.00143268e-01  3.52277281e+00\n",
            "  -2.05822592e+00  1.21425460e-01 -8.13036872e-02 -8.81031380e-01\n",
            "   1.13257190e+00 -1.31000051e+00]\n",
            " [-1.50230842e-01  1.03930763e+00  7.29168297e-01  1.02620290e+00\n",
            "  -1.09021236e+00  2.75264079e-01 -1.96737026e-01  1.68387065e+00\n",
            "  -1.12253310e+00  6.89092159e-03]\n",
            " [ 1.07285439e+00  3.99198686e-01 -1.52415861e+00 -5.53662461e-01\n",
            "  -6.95304516e-01  1.80543543e-01 -3.37668606e-01 -1.28131826e+00\n",
            "   5.89818080e-02 -2.05285457e+00]\n",
            " [-5.60823783e-01 -4.69021914e-01 -4.12058082e-01 -7.77758440e-02\n",
            "   1.12316593e-01 -9.67943868e-01  6.07025278e-01 -1.22923271e+00\n",
            "  -6.60798098e-01  1.88751968e+00]\n",
            " [ 2.32830482e+00  8.42468575e-01  1.92183715e+00  1.38478514e+00\n",
            "   1.20509059e+00  1.14726221e-01 -3.26866712e-01  1.14392147e+00\n",
            "   7.28845462e-01 -3.60976635e+00]\n",
            " [-1.20219080e+00  6.76892638e-01 -9.42912310e-01 -1.34852539e+00\n",
            "  -2.75746506e-01 -3.44998721e-02  1.49006107e+00 -8.77333513e-01\n",
            "  -1.16748214e-02  3.30810551e+00]\n",
            " [-1.96057007e-01  1.67591488e-01 -4.46548969e-01  1.57364207e+00\n",
            "   7.12836079e-01  8.41031306e-01 -6.93758189e-01 -1.13758541e+00\n",
            "  -1.21432166e-01  4.32179953e-01]\n",
            " [-3.99917879e-01  1.53968645e-01  7.15296631e-03  6.84252444e-01\n",
            "  -1.04532001e+00  8.49172338e-01 -4.20993426e-01 -4.48084427e-01\n",
            "  -1.58122829e-02 -8.04155491e-01]\n",
            " [ 4.73630792e+00  1.84482447e+00  3.49564185e-01  1.98613477e+00\n",
            "   1.67208203e-01 -2.03435087e+00  1.31231916e+00 -4.11360714e-01\n",
            "   1.90631102e+00 -5.49520844e+00]\n",
            " [ 1.39309490e+00  5.56403132e-01  1.60308951e-01  7.03829981e-01\n",
            "  -1.06670368e+00 -8.85351361e-01 -2.80529220e-01 -8.77616397e-01\n",
            "   8.26863347e-01 -1.67612503e+00]\n",
            " [ 4.59529958e+00 -1.09585299e+00 -1.08103152e-01 -4.81836621e+00\n",
            "  -1.16267201e+00 -6.53111631e-01 -8.57373891e-01 -1.85092915e+00\n",
            "   3.11407572e-02  4.39946397e-01]\n",
            " [-1.46743702e-01 -9.43673115e-01  1.65475333e+00 -1.34041742e+00\n",
            "   7.71264415e-01 -2.21848462e+00 -1.14691887e-01  6.89949670e-01\n",
            "  -1.18438568e-01  2.83248760e+00]\n",
            " [ 1.15483391e+00  4.34464327e-01  3.93290067e-01 -9.25762117e+00\n",
            "  -6.58334895e-01 -3.74907738e-01 -1.41611555e-01 -1.41662528e+00\n",
            "  -6.15540612e-01  1.00323219e+01]\n",
            " [ 6.84144849e-01 -1.43595713e+00 -1.04511258e+00 -5.63057978e-01\n",
            "  -1.23161507e+00 -1.35292300e+00  6.78433076e-01  1.89220985e-01\n",
            "  -1.31372530e+00 -1.30380495e+00]\n",
            " [ 9.72110493e+00 -7.82203372e-01  2.10349878e-01 -5.19373677e-01\n",
            "   1.24189986e+00 -3.04123536e-01  8.49146897e-01 -2.50827661e+00\n",
            "   5.50689660e-01 -7.67976956e+00]\n",
            " [ 1.35147840e+00  7.65434462e-01  1.58340823e+00 -5.15232307e+00\n",
            "   4.16327772e-01  8.65797709e-02 -7.77249968e-01 -8.54412546e-01\n",
            "   7.23859020e-01  8.47186213e+00]\n",
            " [ 2.69901783e+00 -2.28986326e+00  1.59171146e-01 -3.92784146e-01\n",
            "   1.41066209e+00 -7.81474646e-01  1.59279133e-02 -5.18267173e-01\n",
            "  -5.83126593e-01 -6.79365022e-01]\n",
            " [ 3.53626738e-01 -1.15211746e+00 -1.12159934e+00  2.71981678e-01\n",
            "   1.40136595e+00 -4.27549781e-01 -2.84710131e-01  3.25494097e-01\n",
            "  -1.23769283e+00  8.29975266e-01]\n",
            " [ 4.73041847e-01 -1.39539147e+00  4.52709831e-01 -9.90325882e-01\n",
            "   1.95016752e+00  7.80239841e-01  6.77848751e-01  1.15978279e+00\n",
            "  -1.19756701e-01  2.31102047e+00]\n",
            " [ 8.10819802e-02 -9.90712935e-02  4.47845897e-01  4.26572385e-01\n",
            "  -3.22653610e-01  8.55161491e-01 -1.45797387e+00  2.33972834e-01\n",
            "  -5.01437020e-01 -6.93621946e-01]\n",
            " [ 3.82218675e-01 -6.95748040e-02 -3.24467046e-01 -1.59337367e+00\n",
            "   2.07346250e+00 -4.25927450e-02 -2.27085566e-01  5.60231628e-01\n",
            "  -2.51196835e-01  2.70468957e+00]\n",
            " [ 1.12477114e+01 -2.26989131e-01 -3.27272311e-01 -2.03759325e+00\n",
            "   4.14779258e-01 -1.13569562e+00  1.31769772e+00 -3.57579662e-01\n",
            "   1.35488671e+00 -6.63162578e+00]\n",
            " [ 7.22607280e-01  6.88038100e-01  5.48534881e-01 -1.56715187e-01\n",
            "   3.00254157e-01 -7.02257301e-01  7.15930457e-01 -7.07571535e-01\n",
            "   1.12434820e+00 -7.63653157e-01]]\n",
            "Biases [ 1.21722364  0.70190615  0.51362187  0.5487329   0.06607517  0.00692364\n",
            "  0.31411998 -0.04476693  0.84911997  0.89766015]\n",
            "A's [ 35.8398876  -24.09150127 -44.62147343 -68.280826   -12.56790206\n",
            " -28.98007524 -20.12010688   9.3121617   32.08473064  56.30008001]\n",
            "**************************\n",
            "Loss: 145.59902467439312\n",
            "Data point number: 6\n",
            "Back prop starts ===========================\n",
            "current_H:[ 1 ]: [[ 0.          0.         20.77189493  0.          0.          0.\n",
            "   0.          0.         48.81531433  0.          1.67603498  0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.        ]]\n",
            "current_H shape:[ 1 ]: (32, 1)\n",
            "current_grad_L_by_A[ 1  ]: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "current_grad_L_by_A[ 1  ] shape: (1, 10)\n",
            "self.array_grad_L_by_weight[ 1 ]: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 0\n",
            "Weight update zero %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "self.array_grad_L_by_bias[ 1 ]: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "current_grad_H_by_A[ 1 ]: [[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "self.array_grad_L_by_A[ 0 ]: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "current_H:[ 0 ]: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.00392157 0.         0.01176471 0.00392157 0.         0.01568627\n",
            "  0.         0.         0.         0.00784314 0.         0.\n",
            "  0.         0.         0.01960784 0.00392157 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01568627 0.         0.         0.         0.         0.\n",
            "  0.41568627 0.89803922 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.00392157 0.         0.         0.\n",
            "  0.         0.35294118 0.54117647 0.8745098  0.83921569 0.81960784\n",
            "  0.65490196 0.         0.         0.         0.02352941 0.48627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.00392157 0.\n",
            "  0.         0.         0.14509804 0.47843137 0.70196078 0.97647059\n",
            "  0.83921569 0.76470588 0.70980392 0.83529412 0.94509804 0.\n",
            "  0.         0.         0.36862745 0.70196078 0.         0.\n",
            "  0.         0.         0.         0.00784314 0.         0.02352941\n",
            "  0.         0.         0.         0.         0.0627451  0.58431373\n",
            "  0.9254902  0.88627451 0.78823529 0.76470588 0.78431373 0.8\n",
            "  0.60784314 0.81960784 0.45490196 0.         0.08627451 0.42745098\n",
            "  0.98431373 0.1372549  0.2        0.         0.         0.\n",
            "  0.00392157 0.01176471 0.         0.         0.         0.\n",
            "  0.2627451  0.58823529 0.94117647 0.86666667 0.76078431 0.74509804\n",
            "  0.8        0.83921569 0.80392157 0.76470588 0.81176471 0.7254902\n",
            "  0.80784314 0.91372549 0.87843137 0.70196078 0.00784314 0.03921569\n",
            "  0.08627451 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.43137255 0.83921569 0.92941176 0.81960784\n",
            "  0.76862745 0.75294118 0.84313725 0.84313725 0.83529412 0.83529412\n",
            "  0.81176471 0.75686275 0.72941176 0.78039216 0.80784314 0.68627451\n",
            "  0.         0.         0.48627451 0.90196078 0.78431373 0.14117647\n",
            "  0.         0.19607843 0.46666667 0.61960784 0.65098039 0.75294118\n",
            "  0.8        0.77647059 0.73333333 0.79215686 0.79607843 0.82745098\n",
            "  0.83921569 0.8        0.81960784 0.82352941 0.8        0.77254902\n",
            "  0.74901961 0.74509804 0.74901961 0.89803922 0.90196078 0.94901961\n",
            "  0.83921569 0.75686275 0.79607843 0.5372549  0.42352941 0.74509804\n",
            "  0.78039216 0.78431373 0.76078431 0.78039216 0.76078431 0.76470588\n",
            "  0.78039216 0.78431373 0.74117647 0.73333333 0.74901961 0.74117647\n",
            "  0.77254902 0.77647059 0.80392157 0.78431373 0.78431373 0.81568627\n",
            "  0.83529412 0.84313725 0.83137255 0.83529412 0.81960784 0.79215686\n",
            "  0.84705882 0.5372549  0.05882353 0.21568627 0.44705882 0.61568627\n",
            "  0.7372549  0.81176471 0.84705882 0.8627451  0.85098039 0.85882353\n",
            "  0.86666667 0.94901961 0.94117647 0.95294118 0.97647059 0.99215686\n",
            "  1.         1.         0.95294118 0.90980392 0.88627451 0.87058824\n",
            "  0.86666667 0.83529412 0.84313725 0.77647059 0.81960784 0.24313725\n",
            "  0.0627451  0.04313725 0.         0.         0.02745098 0.15686275\n",
            "  0.29803922 0.42352941 0.5254902  0.55686275 0.56078431 0.56862745\n",
            "  0.56078431 0.48235294 0.43529412 0.36078431 0.29803922 0.23921569\n",
            "  0.17647059 0.1372549  0.09803922 0.09803922 0.12156863 0.1254902\n",
            "  0.1254902  0.04705882 0.00392157 0.         0.         0.04313725\n",
            "  0.09803922 0.10196078 0.10196078 0.08627451 0.04705882 0.07843137\n",
            "  0.05882353 0.05882353 0.07058824 0.06666667 0.0745098  0.10588235\n",
            "  0.11764706 0.14117647 0.16078431 0.19215686 0.22352941 0.25882353\n",
            "  0.30980392 0.32941176 0.30980392 0.3254902  0.36470588 0.31372549\n",
            "  0.29411765 0.17647059 0.         0.         0.         0.\n",
            "  0.         0.03529412 0.05490196 0.06666667 0.10588235 0.13333333\n",
            "  0.15294118 0.15294118 0.16470588 0.17254902 0.16078431 0.16078431\n",
            "  0.16862745 0.18823529 0.16862745 0.11764706 0.12156863 0.1372549\n",
            "  0.15686275 0.14509804 0.15686275 0.14509804 0.10196078 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "current_H shape:[ 0 ]: (784, 1)\n",
            "current_grad_L_by_A[ 0  ]: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "current_grad_L_by_A[ 0  ] shape: (1, 32)\n",
            "self.array_grad_L_by_weight[ 0 ]: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 0\n",
            "Weight update zero %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "self.array_grad_L_by_bias[ 0 ]: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Predicted output: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Actual output: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n",
            "Biases [ 0.1560523   0.42796968  0.685571    0.23590844 -0.00712298  0.81738447\n",
            "  0.83994874 -0.25020908  0.48664807 -0.63618298  0.41275672 -0.65523659\n",
            " -0.36536779 -0.66112394 -0.03607129  0.56508585 -0.78270747 -1.32788773\n",
            "  0.78152873 -0.60608431 -0.12999085 -0.1500365  -0.47248645 -0.41132426\n",
            " -1.31536243  0.03828249  0.19969615 -0.30728677  0.83813795 -0.64051221\n",
            " -0.66564402  0.22424953]\n",
            "A's [ -37.23346585  -13.2984773    20.77189493  -22.970365    -41.15451264\n",
            "   -9.11486637   -3.31864197  -23.54689422   48.81531433  -17.77719075\n",
            "    1.67603498  -74.09211174   -5.18462875   -7.29188427  -47.30931152\n",
            "   -8.92180136  -74.98206525  -15.84670856   -1.37809384  -47.45403139\n",
            "  -35.35249836  -82.23419637  -41.71861686  -32.7058054  -110.90420126\n",
            "  -18.84112072   -5.7887011   -17.89864842  -14.66710314  -86.4504567\n",
            "  -54.29936781   -0.73667733]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 1.88964619e+00  2.46523039e+00 -8.97014575e-01 -4.06045483e-03\n",
            "  -6.69532988e-01 -1.94642287e+00  1.76228313e-01 -3.03210110e-01\n",
            "   7.41851688e-01 -6.00244856e-01]\n",
            " [ 1.45202164e+00  1.05731147e+00 -2.65268128e-01  7.12982227e-01\n",
            "   1.16339981e-01  1.34039607e+00 -7.20264578e-01  5.36020997e-01\n",
            "  -1.14732803e-01 -8.52383342e-01]\n",
            " [ 1.04963248e+00 -9.31578510e-01  3.76248144e+00 -2.79881254e+00\n",
            "  -2.52354732e-01 -8.15235685e-01 -1.45862209e+00 -3.10884042e-01\n",
            "   1.01582961e+00 -3.96237569e+00]\n",
            " [ 1.53328857e+01  2.04409738e-01  1.59754677e+00 -2.54618447e+00\n",
            "   2.51397538e+00  9.34496056e-01  8.30885034e-01 -7.30743746e-01\n",
            "  -5.28086871e-01 -1.09368736e+01]\n",
            " [ 1.76011698e+01  5.94458093e-01 -1.69647492e+00 -7.53863547e+00\n",
            "   4.52038471e-01 -5.10581933e-01  1.47763031e-01 -1.56616086e+00\n",
            "   6.14013681e-01 -5.32320277e+00]\n",
            " [ 1.60933497e+00  6.64103061e-01  7.77575698e-01 -9.43842109e-03\n",
            "   1.61623803e-01  8.45016415e-01 -1.40692164e-01  1.04953810e+00\n",
            "   1.21544638e+00  5.06843077e-01]\n",
            " [ 1.73782607e+00  2.82179697e-01  2.70231433e-01 -1.27763898e+00\n",
            "  -2.59392017e-01  1.05206840e+00  6.70836257e-01 -4.40261755e-01\n",
            "   5.59054517e-01  8.48724554e-02]\n",
            " [ 3.36422565e+00  7.39260273e-01 -6.12673691e-02 -2.53935966e+00\n",
            "  -1.83417412e+00 -1.39587437e+00  2.08574814e+00  1.25638025e+00\n",
            "   6.31537488e-01  2.23610433e+00]\n",
            " [ 2.16845468e+01 -1.24683987e+00 -2.80571263e-01 -6.05704331e+00\n",
            "  -6.81568306e-01  7.66138607e-01 -2.28656730e+00 -2.86066801e+00\n",
            "   6.70124736e-01 -1.03784789e+01]\n",
            " [-4.19019841e+00  7.11586925e-02 -3.00143268e-01  4.81121599e+00\n",
            "  -2.05832533e+00  1.21425460e-01 -8.13036872e-02 -8.81031380e-01\n",
            "   1.13257190e+00 -1.51920284e+00]\n",
            " [-1.50230842e-01  1.03930763e+00  7.29168297e-01  1.02620290e+00\n",
            "  -1.09021236e+00  2.75264079e-01 -1.96737026e-01  1.68387065e+00\n",
            "  -1.12253310e+00  6.89092159e-03]\n",
            " [ 1.47798506e+00  3.99198686e-01 -1.52415861e+00 -5.53662461e-01\n",
            "  -6.95304516e-01  1.80543543e-01 -3.37668606e-01 -1.28131826e+00\n",
            "   5.89818080e-02 -2.45798524e+00]\n",
            " [-1.08574176e+00 -4.69021914e-01 -4.12058082e-01  3.86170482e-01\n",
            "   1.12316593e-01 -9.67943868e-01  6.07025278e-01 -1.30736743e+00\n",
            "  -6.60798098e-01  2.02662605e+00]\n",
            " [ 2.37529110e+00  8.42468575e-01  1.92183715e+00  1.86505417e+00\n",
            "   1.20509059e+00  1.14726221e-01 -3.26866712e-01  1.14392147e+00\n",
            "   7.28845462e-01 -4.13702167e+00]\n",
            " [-1.20219080e+00  6.76892638e-01 -9.42912310e-01 -1.65269760e+00\n",
            "  -2.75746506e-01 -3.44998721e-02  1.49006107e+00 -9.67605278e-01\n",
            "  -1.16748214e-02  3.70254950e+00]\n",
            " [-1.96057007e-01  1.67591488e-01 -4.46548969e-01  1.57364207e+00\n",
            "   7.12836079e-01  8.41031306e-01 -6.93758189e-01 -1.13758541e+00\n",
            "  -1.21432166e-01  4.32179953e-01]\n",
            " [-1.87644119e-01  1.53968645e-01  7.15296631e-03  6.84252444e-01\n",
            "  -1.04532001e+00  8.49172338e-01 -4.20993426e-01 -4.48084427e-01\n",
            "  -1.58122829e-02 -1.01642925e+00]\n",
            " [ 4.85433811e+00  1.84482447e+00  3.49564185e-01  2.86055415e+00\n",
            "   1.67208203e-01 -2.03435087e+00  1.31231916e+00 -4.54663226e-01\n",
            "   1.90631102e+00 -6.44435549e+00]\n",
            " [ 1.39309490e+00  5.56403132e-01  1.60308951e-01  7.03829981e-01\n",
            "  -1.06670368e+00 -8.85351361e-01 -2.80529220e-01 -8.77616397e-01\n",
            "   8.26863347e-01 -1.67612503e+00]\n",
            " [ 5.49397727e+00 -1.09585299e+00 -1.08103152e-01 -5.34719975e+00\n",
            "  -1.16267201e+00 -6.53111631e-01 -8.57373891e-01 -2.00787556e+00\n",
            "   3.11407572e-02  2.27048657e-01]\n",
            " [-1.46743702e-01 -9.43673115e-01  1.65475333e+00 -1.58875307e+00\n",
            "   7.71264415e-01 -2.21848462e+00 -1.14691887e-01  6.16248998e-01\n",
            "  -1.18438568e-01  3.15452392e+00]\n",
            " [ 1.15483391e+00  4.34464327e-01  3.93290067e-01 -1.02953127e+01\n",
            "  -6.58334895e-01 -3.74907738e-01 -1.41611555e-01 -1.72458978e+00\n",
            "  -6.15540612e-01  1.13779779e+01]\n",
            " [ 6.84144849e-01 -1.43595713e+00 -1.04511258e+00 -5.72248472e-01\n",
            "  -1.23161507e+00 -1.35292300e+00  6.78433076e-01  1.86493444e-01\n",
            "  -1.31372530e+00 -1.29188692e+00]\n",
            " [ 1.12321992e+01 -7.82203372e-01  2.10349878e-01 -7.03451469e-01\n",
            "   1.24189986e+00 -3.04123536e-01  8.49146897e-01 -2.56290694e+00\n",
            "   5.50689660e-01 -8.95215567e+00]\n",
            " [ 1.70081214e+00  7.65434462e-01  1.58340823e+00 -5.92595255e+00\n",
            "   4.16327772e-01  8.65797709e-02 -7.77249968e-01 -1.08400911e+00\n",
            "   7.23859020e-01  9.12575444e+00]\n",
            " [ 3.70965514e+00 -2.28986326e+00  1.59171146e-01 -1.40319710e+00\n",
            "   1.41043774e+00 -7.81474646e-01  1.59279132e-02 -5.18267173e-01\n",
            "  -5.83126593e-01 -6.79365022e-01]\n",
            " [ 3.53626738e-01 -1.15211746e+00 -1.12159934e+00  2.71981678e-01\n",
            "   1.40136595e+00 -4.27549781e-01 -2.84710131e-01  3.25494097e-01\n",
            "  -1.23769283e+00  8.29975266e-01]\n",
            " [ 9.61535538e-01 -1.39539147e+00  8.12355812e-01 -1.58352048e+00\n",
            "   1.95005908e+00  7.80239841e-01  6.77848751e-01  1.12867764e+00\n",
            "  -1.19756701e-01  2.08728900e+00]\n",
            " [ 8.10819802e-02 -9.90712935e-02  4.47845897e-01  4.26572385e-01\n",
            "  -3.22653610e-01  8.55161491e-01 -1.45797387e+00  2.33972834e-01\n",
            "  -5.01437020e-01 -6.93621946e-01]\n",
            " [ 3.82218675e-01 -6.95748040e-02 -3.24467046e-01 -1.92861480e+00\n",
            "   2.07346250e+00 -4.25927450e-02 -2.27085566e-01  4.60739278e-01\n",
            "  -2.51196835e-01  3.13942305e+00]\n",
            " [ 1.29820417e+01 -2.26989131e-01 -3.27272311e-01 -2.39630382e+00\n",
            "   4.14779258e-01 -1.13569562e+00  1.31769772e+00 -4.64037236e-01\n",
            "   1.35488671e+00 -7.90078793e+00]\n",
            " [ 7.22607280e-01  6.88038100e-01  5.48534881e-01 -1.56715187e-01\n",
            "   3.00254157e-01 -7.02257301e-01  7.15930457e-01 -7.07571535e-01\n",
            "   1.12434820e+00 -7.63653157e-01]]\n",
            "Biases [ 1.28437264  0.70190615  0.60362187  0.50265571  0.06605719  0.00692364\n",
            "  0.31411998 -0.05604308  0.84911997  0.79788247]\n",
            "A's [ 951.00274419  -77.77170917   16.52637947 -313.54644468  -40.27284416\n",
            "   20.93358279 -141.93346465 -133.61387446   52.78077086 -455.76487539]\n",
            "**************************\n",
            "Loss: 996.5784284662087\n",
            "Data point number: 7\n",
            "Back prop starts ===========================\n",
            "current_H:[ 1 ]: [[ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.         22.57972106  0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.        ]]\n",
            "current_H shape:[ 1 ]: (32, 1)\n",
            "current_grad_L_by_A[ 1  ]: [[ 1.  0. -1.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "current_grad_L_by_A[ 1  ] shape: (1, 10)\n",
            "self.array_grad_L_by_weight[ 1 ]: [[  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [ 22.57972106   0.         -22.57972106   0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]]\n",
            "number of non-zeros in weight gradient: 2\n",
            "self.array_grad_L_by_bias[ 1 ]: [[ 1.  0. -1.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "current_grad_H_by_A[ 1 ]: [[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "self.array_grad_L_by_A[ 0 ]: [[ 0.          0.         -0.          0.          0.          0.\n",
            "   0.          0.         21.96511804 -0.         -0.          0.\n",
            "  -0.          0.         -0.          0.         -0.          0.\n",
            "   0.          0.         -0.          0.          0.          0.\n",
            "   0.          0.          0.          0.         -0.          0.\n",
            "   0.          0.        ]]\n",
            "current_H:[ 0 ]: [[0.         0.         0.         0.         0.         0.00392157\n",
            "  0.00392157 0.         0.         0.         0.         0.24705882\n",
            "  0.10980392 0.         0.         0.         0.12941176 0.33333333\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00784314 0.         0.\n",
            "  0.10980392 0.49411765 0.94509804 1.         1.         1.\n",
            "  1.         1.         1.         0.98823529 0.97254902 0.43529412\n",
            "  0.         0.         0.         0.00784314 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00784314 0.         0.         0.80784314 0.95686275 0.98431373\n",
            "  0.94509804 0.90196078 0.93333333 0.86666667 0.80392157 0.90196078\n",
            "  0.94117647 0.90196078 0.9372549  0.98431373 0.91372549 0.64705882\n",
            "  0.         0.         0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.         0.\n",
            "  0.78039216 0.98431373 0.89411765 0.91764706 0.91372549 0.9254902\n",
            "  0.92156863 0.96078431 0.96862745 0.92941176 0.91764706 0.9372549\n",
            "  0.90196078 0.90196078 0.92156863 1.         0.69019608 0.\n",
            "  0.         0.00392157 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.31764706 0.99607843 0.88627451\n",
            "  0.89411765 0.9372549  0.92941176 0.9254902  0.91764706 0.90980392\n",
            "  0.91372549 0.92156863 0.92156863 0.9254902  0.9372549  0.92941176\n",
            "  0.91372549 0.88235294 0.96470588 0.28627451 0.         0.\n",
            "  0.         0.         0.         0.         0.01176471 0.\n",
            "  0.         1.         0.92156863 0.9372549  0.8745098  0.91764706\n",
            "  0.93333333 0.9254902  0.92941176 0.9254902  0.92156863 0.92156863\n",
            "  0.92156863 0.92156863 0.9254902  0.92156863 0.91764706 0.90196078\n",
            "  0.90588235 1.         0.09411765 0.         0.01568627 0.\n",
            "  0.         0.         0.         0.         0.69411765 0.9372549\n",
            "  0.8745098  0.99607843 0.8745098  0.90980392 0.91764706 0.91764706\n",
            "  0.9254902  0.9254902  0.92156863 0.92156863 0.92156863 0.92156863\n",
            "  0.92156863 0.91764706 0.90588235 0.91372549 0.87058824 0.96470588\n",
            "  0.34509804 0.         0.00392157 0.         0.         0.\n",
            "  0.         0.         0.91764706 0.9372549  0.89803922 1.\n",
            "  0.8627451  0.90980392 0.91372549 0.90980392 0.91764706 0.92156863\n",
            "  0.92156863 0.92156863 0.92156863 0.92156863 0.91764706 0.91372549\n",
            "  0.90980392 0.90196078 0.89411765 0.99607843 0.54901961 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.88235294 0.94117647 0.88627451 1.         0.86666667 0.89019608\n",
            "  0.90980392 0.89411765 0.90588235 0.90196078 0.89411765 0.89803922\n",
            "  0.90588235 0.90196078 0.89411765 0.89411765 0.90980392 0.8745098\n",
            "  0.89803922 0.95686275 0.90588235 0.         0.         0.\n",
            "  0.         0.         0.         0.18431373 0.96078431 0.90588235\n",
            "  0.91764706 0.97647059 0.89803922 0.86666667 0.89803922 0.88235294\n",
            "  0.89803922 0.89019608 0.88627451 0.89019608 0.89411765 0.89019608\n",
            "  0.89411765 0.89803922 0.89411765 0.87843137 0.96470588 0.94117647\n",
            "  0.89019608 0.         0.         0.         0.         0.\n",
            "  0.         0.2        0.97254902 0.90196078 0.96078431 0.96470588\n",
            "  0.90196078 0.88627451 0.90196078 0.89019608 0.90196078 0.89803922\n",
            "  0.89411765 0.89803922 0.90196078 0.89411765 0.89411765 0.90588235\n",
            "  0.88235294 0.89019608 0.94901961 0.92941176 1.         0.\n",
            "  0.         0.         0.         0.         0.         0.39607843\n",
            "  0.99215686 0.89803922 0.96862745 0.94509804 0.86666667 0.91372549\n",
            "  0.89411765 0.89019608 0.89803922 0.89411765 0.89019608 0.89411765\n",
            "  0.90196078 0.89019608 0.90196078 0.91764706 0.88235294 0.89803922\n",
            "  0.98431373 0.89803922 0.95294118 0.21568627 0.         0.\n",
            "  0.         0.         0.         0.4        1.         0.89019608\n",
            "  0.94901961 0.94509804 0.86666667 0.91764706 0.8745098  0.90196078\n",
            "  0.89411765 0.90588235 0.89803922 0.90588235 0.90588235 0.89019608\n",
            "  0.89803922 0.94509804 0.85882353 0.9254902  0.99607843 0.88235294\n",
            "  0.98039216 0.65490196 0.         0.         0.         0.\n",
            "  0.         0.35294118 1.         0.89803922 0.9254902  0.90588235\n",
            "  0.87058824 0.9254902  0.8745098  0.90588235 0.89803922 0.90588235\n",
            "  0.89803922 0.90588235 0.90588235 0.89411765 0.87843137 0.96078431\n",
            "  0.85490196 0.95294118 0.9372549  0.89019608 0.95686275 0.68627451\n",
            "  0.         0.         0.         0.         0.         0.83137255\n",
            "  0.98039216 0.88235294 0.9254902  0.97647059 0.89803922 0.92941176\n",
            "  0.8745098  0.90588235 0.89803922 0.90588235 0.89803922 0.90588235\n",
            "  0.90588235 0.90196078 0.86666667 0.95294118 0.88235294 0.97254902\n",
            "  0.90196078 0.9254902  0.91764706 1.         0.00392157 0.\n",
            "  0.         0.         0.         0.96078431 0.95294118 0.90980392\n",
            "  0.95294118 0.85490196 0.89411765 0.93333333 0.87058824 0.90588235\n",
            "  0.89803922 0.90588235 0.89803922 0.90588235 0.90588235 0.90196078\n",
            "  0.87058824 0.92941176 0.92941176 0.98823529 0.89803922 0.9372549\n",
            "  0.94117647 0.8745098  0.         0.         0.         0.\n",
            "  0.10588235 1.         0.92156863 0.94901961 0.92941176 0.84705882\n",
            "  0.90196078 0.9254902  0.87843137 0.89803922 0.89019608 0.91372549\n",
            "  0.91372549 0.91372549 0.90196078 0.89411765 0.87843137 0.90196078\n",
            "  0.96078431 0.96862745 0.86666667 0.95294118 0.9372549  0.98823529\n",
            "  0.         0.         0.         0.         0.34509804 1.\n",
            "  0.90980392 0.97254902 0.9254902  0.81568627 0.91764706 0.90588235\n",
            "  0.8745098  0.89019608 0.88627451 0.91372549 0.90980392 0.90980392\n",
            "  0.90196078 0.89411765 0.87843137 0.87843137 0.92156863 0.91372549\n",
            "  0.91764706 0.96862745 0.92156863 1.         0.         0.\n",
            "  0.         0.         0.3254902  1.         0.88235294 0.98039216\n",
            "  0.92941176 0.87843137 0.9254902  0.89803922 0.88235294 0.88235294\n",
            "  0.89019608 0.92156863 0.89803922 0.90588235 0.90196078 0.90196078\n",
            "  0.89019608 0.86666667 0.89019608 0.86666667 0.9372549  0.98039216\n",
            "  0.90588235 1.         0.         0.         0.         0.\n",
            "  0.07843137 1.         0.87843137 0.97254902 0.91764706 0.88627451\n",
            "  0.90980392 0.87058824 0.88235294 0.87843137 0.90588235 0.93333333\n",
            "  0.88627451 0.90196078 0.89411765 0.90196078 0.90196078 0.86666667\n",
            "  0.89803922 0.88235294 0.95686275 0.96470588 0.90196078 1.\n",
            "  0.         0.         0.         0.         0.37254902 1.\n",
            "  0.85490196 0.94901961 1.         0.90980392 0.88627451 0.87843137\n",
            "  0.89803922 0.89411765 0.89411765 0.90980392 0.89411765 0.89803922\n",
            "  0.90588235 0.91372549 0.90980392 0.88627451 0.86666667 0.87843137\n",
            "  0.96862745 0.95686275 0.89411765 1.         0.         0.\n",
            "  0.         0.         0.65490196 1.         0.83529412 0.92156863\n",
            "  1.         0.31764706 0.96078431 0.98431373 0.93333333 0.9254902\n",
            "  0.90196078 0.89803922 0.90196078 0.89803922 0.90196078 0.90588235\n",
            "  0.93333333 0.94117647 1.         0.75294118 1.         0.9372549\n",
            "  0.89411765 1.         0.09019608 0.         0.         0.\n",
            "  0.67843137 0.94901961 0.87843137 0.91372549 1.         0.\n",
            "  0.53333333 0.88627451 0.9372549  1.         0.89803922 0.9254902\n",
            "  0.9254902  0.91764706 0.91372549 0.89411765 0.98431373 0.97254902\n",
            "  0.78431373 0.31764706 1.         0.92941176 0.88235294 1.\n",
            "  0.39607843 0.         0.         0.         0.6745098  1.\n",
            "  0.88627451 0.91372549 1.         0.         0.         0.\n",
            "  0.         0.         0.03137255 0.08235294 0.08627451 0.08235294\n",
            "  0.07843137 0.05490196 0.         0.         0.         0.\n",
            "  1.         0.93333333 0.89803922 0.96470588 0.69803922 0.\n",
            "  0.         0.         0.0627451  1.         0.9254902  0.93333333\n",
            "  0.98823529 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.87058824 0.95686275\n",
            "  0.87058824 0.99607843 0.46666667 0.         0.         0.\n",
            "  0.         0.11764706 0.89411765 0.94901961 0.63921569 0.\n",
            "  0.         0.         0.         0.00784314 0.01568627 0.02352941\n",
            "  0.01960784 0.01960784 0.01568627 0.01568627 0.00784314 0.\n",
            "  0.00392157 0.         0.59215686 0.98431373 0.92156863 0.70588235\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.91764706 1.         0.74901961 0.         0.04313725 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.01568627 0.\n",
            "  0.40392157 0.96470588 0.96862745 0.28235294 0.         0.\n",
            "  0.         0.         0.         0.00392157 0.37254902 0.30196078\n",
            "  0.20392157 0.         0.01568627 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.01176471 0.         0.32156863 0.92941176\n",
            "  0.90588235 0.2745098  0.         0.        ]]\n",
            "current_H shape:[ 0 ]: (784, 1)\n",
            "current_grad_L_by_A[ 0  ]: [[ 0.          0.         -0.          0.          0.          0.\n",
            "   0.          0.         21.96511804 -0.         -0.          0.\n",
            "  -0.          0.         -0.          0.         -0.          0.\n",
            "   0.          0.         -0.          0.          0.          0.\n",
            "   0.          0.          0.          0.         -0.          0.\n",
            "   0.          0.        ]]\n",
            "current_grad_L_by_A[ 0  ] shape: (1, 32)\n",
            "self.array_grad_L_by_weight[ 0 ]: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 552\n",
            "self.array_grad_L_by_bias[ 0 ]: [[ 0.          0.         -0.          0.          0.          0.\n",
            "   0.          0.         21.96511804 -0.         -0.          0.\n",
            "  -0.          0.         -0.          0.         -0.          0.\n",
            "   0.          0.         -0.          0.          0.          0.\n",
            "   0.          0.          0.          0.         -0.          0.\n",
            "   0.          0.        ]]\n",
            "Predicted output: [1.00000000e+000 7.51913095e-226 2.03682261e-216 4.16471440e-273\n",
            " 1.39064178e-220 2.06113907e-206 3.25034132e-236 5.26496062e-242\n",
            " 5.47435120e-207 2.34817256e-315]\n",
            "Actual output: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: RuntimeWarning: underflow encountered in exp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Biases [ 0.09017158  0.42796968  0.65189415  0.17198773 -0.12439975  0.81738447\n",
            "  0.83994874 -0.65476249 -1.72565208 -0.90044656  0.41275672 -0.78775272\n",
            " -0.55095268 -0.8069004  -0.08835901  0.56508585 -0.91769544 -1.66633967\n",
            "  0.78152873 -0.7571061  -0.17292577 -0.24074307 -0.52064336 -0.49879155\n",
            " -1.55957682 -0.08191558  0.19969615 -0.57302873  0.83813795 -0.75171859\n",
            " -0.80937799  0.22424953]\n",
            "A's [-145.30203898  -24.02703111  -16.25276156 -131.9916029  -192.43797777\n",
            "  -37.66023652  -18.14362333 -257.60208426   22.57972106 -152.48308491\n",
            "  -11.98659663 -302.3472125   -72.66249035  -75.23803424 -120.65605828\n",
            "   -4.31971528 -286.62851389 -181.91718253  -33.44591376 -297.25238872\n",
            "  -94.51841757 -200.96854398 -104.6271835  -179.42964525 -500.48772502\n",
            "  -98.48703356  -50.71566206 -136.86927868  -26.91145144 -285.20738818\n",
            " -275.31812286  -14.62234833]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 2.10114969e+00  2.46523039e+00 -8.97014575e-01 -4.06045483e-03\n",
            "  -6.69532988e-01 -1.94642287e+00  1.76228313e-01 -3.03210110e-01\n",
            "   7.41851688e-01 -8.11748355e-01]\n",
            " [ 1.45202164e+00  1.05731147e+00 -2.65268128e-01  7.12982227e-01\n",
            "   1.16339981e-01  1.34039607e+00 -7.20264578e-01  5.36020997e-01\n",
            "  -1.14732803e-01 -8.52383342e-01]\n",
            " [ 1.27834700e+00 -9.31578510e-01  5.91444418e+00 -3.13729451e+00\n",
            "  -2.52405504e-01 -8.15235685e-01 -1.45862209e+00 -3.43475723e-01\n",
            "   1.01582961e+00 -5.97192853e+00]\n",
            " [ 1.70687113e+01  2.04409738e-01  1.59754677e+00 -2.83173010e+00\n",
            "   2.51397538e+00  9.34496056e-01  8.30885034e-01 -8.15487539e-01\n",
            "  -5.28086871e-01 -1.23024099e+01]\n",
            " [ 1.95334337e+01  5.94458093e-01 -1.69647492e+00 -8.28584189e+00\n",
            "   4.52038471e-01 -5.10581933e-01  1.47763031e-01 -1.78791563e+00\n",
            "   6.14013681e-01 -6.28650550e+00]\n",
            " [ 1.60933497e+00  6.64103061e-01  7.77575698e-01 -9.43842109e-03\n",
            "   1.61623803e-01  8.45016415e-01 -1.40692164e-01  1.04953810e+00\n",
            "   1.21544638e+00  5.06843077e-01]\n",
            " [ 1.73782607e+00  2.82179697e-01  2.70231433e-01 -1.27763898e+00\n",
            "  -2.59392017e-01  1.05206840e+00  6.70836257e-01 -4.40261755e-01\n",
            "   5.59054517e-01  8.48724554e-02]\n",
            " [ 3.58260501e+00  7.39260273e-01  5.44904091e-01 -2.80766743e+00\n",
            "  -1.83417412e+00 -1.39587437e+00  2.08574814e+00  1.17675228e+00\n",
            "   6.31537488e-01  1.75948925e+00]\n",
            " [ 2.17316366e+01 -1.24683987e+00  1.97740084e+00 -6.61357508e+00\n",
            "  -6.81568306e-01  7.66138607e-01 -2.28656730e+00 -3.02583465e+00\n",
            "   6.70124736e-01 -1.19618425e+01]\n",
            " [-5.16142570e+00  7.11586925e-02 -3.00143268e-01  5.97081485e+00\n",
            "  -2.05841479e+00  1.21425460e-01 -8.13036872e-02 -8.81031380e-01\n",
            "   1.13257190e+00 -1.70748495e+00]\n",
            " [-1.50230842e-01  1.03930763e+00  7.29168297e-01  1.02620290e+00\n",
            "  -1.09021236e+00  2.75264079e-01 -1.96737026e-01  1.68387065e+00\n",
            "  -1.12253310e+00  6.89092159e-03]\n",
            " [ 1.84260267e+00  3.99198686e-01 -1.52415861e+00 -5.53662461e-01\n",
            "  -6.95304516e-01  1.80543543e-01 -3.37668606e-01 -1.28131826e+00\n",
            "   5.89818080e-02 -2.82260285e+00]\n",
            " [-1.55816795e+00 -4.69021914e-01 -4.12058082e-01  8.03722175e-01\n",
            "   1.12316593e-01 -9.67943868e-01  6.07025278e-01 -1.37768867e+00\n",
            "  -6.60798098e-01  2.15182178e+00]\n",
            " [ 2.41757876e+00  8.42468575e-01  1.92183715e+00  2.29729630e+00\n",
            "   1.20509059e+00  1.14726221e-01 -3.26866712e-01  1.14392147e+00\n",
            "   7.28845462e-01 -4.61155146e+00]\n",
            " [-1.20219080e+00  6.76892638e-01 -9.42912310e-01 -1.92645260e+00\n",
            "  -2.75746506e-01 -3.44998721e-02  1.49006107e+00 -1.04884987e+00\n",
            "  -1.16748214e-02  4.05754908e+00]\n",
            " [-1.96057007e-01  1.67591488e-01 -4.46548969e-01  1.57364207e+00\n",
            "   7.12836079e-01  8.41031306e-01 -6.93758189e-01 -1.13758541e+00\n",
            "  -1.21432166e-01  4.32179953e-01]\n",
            " [ 3.40226462e-03  1.53968645e-01  7.15296631e-03  6.84252444e-01\n",
            "  -1.04532001e+00  8.49172338e-01 -4.20993426e-01 -4.48084427e-01\n",
            "  -1.58122829e-02 -1.20747563e+00]\n",
            " [ 4.96056528e+00  1.84482447e+00  3.49564185e-01  3.64753159e+00\n",
            "   1.67208203e-01 -2.03435087e+00  1.31231916e+00 -4.93635486e-01\n",
            "   1.90631102e+00 -7.29858784e+00]\n",
            " [ 1.39309490e+00  5.56403132e-01  1.60308951e-01  7.03829981e-01\n",
            "  -1.06670368e+00 -8.85351361e-01 -2.80529220e-01 -8.77616397e-01\n",
            "   8.26863347e-01 -1.67612503e+00]\n",
            " [ 6.30278720e+00 -1.09585299e+00 -1.08103152e-01 -5.82314994e+00\n",
            "  -1.16267201e+00 -6.53111631e-01 -8.57373891e-01 -2.14912733e+00\n",
            "   3.11407572e-02  3.54406904e-02]\n",
            " [-1.46743702e-01 -9.43673115e-01  1.65475333e+00 -1.81225515e+00\n",
            "   7.71264415e-01 -2.21848462e+00 -1.14691887e-01  5.49918394e-01\n",
            "  -1.18438568e-01  3.44435661e+00]\n",
            " [ 1.15483391e+00  4.34464327e-01  3.93290067e-01 -1.12292351e+01\n",
            "  -6.58334895e-01 -3.74907738e-01 -1.41611555e-01 -2.00175783e+00\n",
            "  -6.15540612e-01  1.25890684e+01]\n",
            " [ 6.84144849e-01 -1.43595713e+00 -1.04511258e+00 -5.80519916e-01\n",
            "  -1.23161507e+00 -1.35292300e+00  6.78433076e-01  1.84038658e-01\n",
            "  -1.31372530e+00 -1.28116069e+00]\n",
            " [ 1.25921840e+01 -7.82203372e-01  2.10349878e-01 -8.69121482e-01\n",
            "   1.24189986e+00 -3.04123536e-01  8.49146897e-01 -2.61207423e+00\n",
            "   5.50689660e-01 -1.00973032e+01]\n",
            " [ 2.01521251e+00  7.65434462e-01  1.58340823e+00 -6.62221908e+00\n",
            "   4.16327772e-01  8.65797709e-02 -7.77249968e-01 -1.29064603e+00\n",
            "   7.23859020e-01  9.71425751e+00]\n",
            " [ 4.61922872e+00 -2.28986326e+00  1.59171146e-01 -2.31256877e+00\n",
            "   1.41023583e+00 -7.81474646e-01  1.59279132e-02 -5.18267173e-01\n",
            "  -5.83126593e-01 -6.79365023e-01]\n",
            " [ 3.53626738e-01 -1.15211746e+00 -1.12159934e+00  2.71981678e-01\n",
            "   1.40136595e+00 -4.27549781e-01 -2.84710131e-01  3.25494097e-01\n",
            "  -1.23769283e+00  8.29975266e-01]\n",
            " [ 1.40117986e+00 -1.39539147e+00  1.13603720e+00 -2.11739563e+00\n",
            "   1.94996148e+00  7.80239841e-01  6.77848751e-01  1.10068299e+00\n",
            "  -1.19756701e-01  1.88593067e+00]\n",
            " [ 8.10819802e-02 -9.90712935e-02  4.47845897e-01  4.26572385e-01\n",
            "  -3.22653610e-01  8.55161491e-01 -1.45797387e+00  2.33972834e-01\n",
            "  -5.01437020e-01 -6.93621946e-01]\n",
            " [ 3.82218675e-01 -6.95748040e-02 -3.24467046e-01 -2.23033183e+00\n",
            "   2.07346250e+00 -4.25927450e-02 -2.27085566e-01  3.71196163e-01\n",
            "  -2.51196835e-01  3.53068319e+00]\n",
            " [ 1.45429389e+01 -2.26989131e-01 -3.27272311e-01 -2.71914334e+00\n",
            "   4.14779258e-01 -1.13569562e+00  1.31769772e+00 -5.59849052e-01\n",
            "   1.35488671e+00 -9.04303386e+00]\n",
            " [ 7.22607280e-01  6.88038100e-01  5.48534881e-01 -1.56715187e-01\n",
            "   3.00254157e-01 -7.02257301e-01  7.15930457e-01 -7.07571535e-01\n",
            "   1.12434820e+00 -7.63653157e-01]]\n",
            "Biases [ 1.24480674  0.70190615  0.78462187  0.46118624  0.066041    0.00692364\n",
            "  0.31411998 -0.06619161  0.84911997  0.70808256]\n",
            "A's [ 490.91539006  -27.4513904    -5.73159898 -136.26369263  -15.32356505\n",
            "   17.30611967  -51.31593188  -64.64912878   15.98034957 -233.54527685]\n",
            "**************************\n",
            "Loss: 716.5101481528778\n",
            "Data point number: 8\n",
            "Back prop starts ===========================\n",
            "current_H:[ 1 ]: [[0.         2.26221281 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  2.66991625 0.         0.         2.27828598 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         3.796255   0.\n",
            "  0.         1.09780583]]\n",
            "current_H shape:[ 1 ]: (32, 1)\n",
            "current_grad_L_by_A[ 1  ]: [[ 2.62935792e-04  1.27494308e-03  1.36647795e-04  9.85198759e-01\n",
            "   3.67225165e-04 -9.87977717e-01  2.28561495e-07  6.28682293e-07\n",
            "   1.13299885e-05  7.25018753e-04]]\n",
            "current_grad_L_by_A[ 1  ] shape: (1, 10)\n",
            "self.array_grad_L_by_weight[ 1 ]: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 5.94816717e-04  2.88419257e-03  3.09126392e-04  2.22872925e+00\n",
            "   8.30741471e-04 -2.23501585e+00  5.17054743e-07  1.42221314e-06\n",
            "   2.56308450e-05  1.64014671e-03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 7.02016544e-04  3.40399125e-03  3.64838168e-04  2.63039818e+00\n",
            "   9.80460434e-04 -2.63781776e+00  6.10240051e-07  1.67852907e-06\n",
            "   3.02501203e-05  1.93573935e-03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 5.99042928e-04  2.90468494e-03  3.11322754e-04  2.24456452e+00\n",
            "   8.36643943e-04 -2.25089578e+00  5.20728450e-07  1.43231805e-06\n",
            "   2.58129538e-05  1.65180006e-03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 9.98171315e-04  4.84000904e-03  5.18749874e-04  3.74006571e+00\n",
            "   1.39408037e-03 -3.75061535e+00  8.67677720e-07  2.38663830e-06\n",
            "   4.30115253e-05  2.75235607e-03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 2.88652445e-04  1.39963994e-03  1.50012745e-04  1.08155694e+00\n",
            "   4.03141926e-04 -1.08460769e+00  2.50916142e-07  6.90171085e-07\n",
            "   1.24381274e-05  7.95929812e-04]]\n",
            "number of non-zeros in weight gradient: 50\n",
            "self.array_grad_L_by_bias[ 1 ]: [[ 2.62935792e-04  1.27494308e-03  1.36647795e-04  9.85198759e-01\n",
            "   3.67225165e-04 -9.87977717e-01  2.28561495e-07  6.28682293e-07\n",
            "   1.13299885e-05  7.25018753e-04]]\n",
            "current_grad_H_by_A[ 1 ]: [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0. 0. 1.]]\n",
            "self.array_grad_L_by_A[ 0 ]: [[ 0.         -0.62073509 -0.         -0.         -0.         -0.\n",
            "  -0.         -0.         -0.          0.          0.         -0.\n",
            "   1.74866222  0.         -0.          0.72010398 -0.          0.\n",
            "   0.         -0.          0.         -0.          0.         -0.\n",
            "  -0.         -0.          0.         -0.         -0.42529295 -0.\n",
            "  -0.          0.54013018]]\n",
            "current_H:[ 0 ]: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.00392157 0.01176471 0.00392157 0.\n",
            "  0.         0.00392157 0.00392157 0.         0.         0.\n",
            "  0.         0.22745098 0.         0.15294118 0.00392157 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.01176471 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.25098039 0.42745098 0.57254902\n",
            "  0.75294118 0.75686275 0.02745098 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.         0.         0.         0.\n",
            "  0.         0.         0.36862745 0.14901961 0.38823529 0.81960784\n",
            "  0.71764706 0.89803922 0.75294118 0.55686275 0.18823529 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.         0.         0.         0.16078431 0.17647059\n",
            "  0.61960784 0.57254902 0.64313725 0.44705882 0.2        0.00392157\n",
            "  0.20784314 0.41176471 0.16470588 0.14117647 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.03921569 0.26666667 0.17254902 0.11764706 0.23137255 0.6745098\n",
            "  0.57254902 0.         0.08627451 0.         0.05098039 0.40392157\n",
            "  0.43529412 0.40392157 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.01176471 0.00392157 0.         0.08627451 0.23921569\n",
            "  0.34509804 0.59607843 1.         0.27843137 0.         0.\n",
            "  0.         0.         0.1372549  0.33333333 0.43921569 0.78823529\n",
            "  0.17254902 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.         0.05098039 0.24313725 0.60392157 0.24313725\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.21176471 0.38823529 0.23921569 0.41568627 0.2        0.0745098\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.03529412 0.00392157\n",
            "  0.         0.         0.00392157 0.         0.30980392 0.32156863\n",
            "  0.18431373 0.12941176 0.22745098 0.19607843 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.01176471\n",
            "  0.00392157 0.01176471 0.03529412 0.01176471 0.         0.\n",
            "  0.00392157 0.         0.39215686 0.34509804 0.18823529 0.1372549\n",
            "  0.2745098  0.21176471 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.01176471 0.         0.00392157 0.         0.\n",
            "  0.43529412 0.76470588 0.46666667 0.11372549 0.22745098 0.17647059\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.01176471 0.         0.         0.35686275 0.57254902\n",
            "  0.67058824 0.0627451  0.36470588 0.1372549  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.18823529 0.17647059 0.01176471 0.30980392 0.34117647\n",
            "  0.38823529 0.02352941 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.01176471 0.         0.         0.46666667 0.5372549\n",
            "  0.12941176 0.37647059 0.30196078 0.05098039 0.17647059 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.1254902  0.62745098 0.64313725 0.55686275 0.45490196 0.30980392\n",
            "  0.32156863 0.15294118 0.15294118 0.         0.         0.\n",
            "  0.         0.         0.01176471 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.01176471\n",
            "  0.01568627 0.03921569 0.         0.16078431 0.70588235 0.55686275\n",
            "  0.67058824 0.00392157 0.         0.         0.18823529 0.28627451\n",
            "  0.0627451  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.00392157 0.00392157 0.         0.\n",
            "  0.         0.         0.         0.         0.01176471 0.\n",
            "  0.10588235 0.60784314 0.44705882 0.6627451  0.         0.\n",
            "  0.         0.         0.18431373 0.29803922 0.02352941 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.         0.         0.60784314 0.50588235\n",
            "  0.62745098 0.         0.         0.         0.         0.\n",
            "  0.17647059 0.37647059 0.         0.         0.         0.\n",
            "  0.         0.         0.00392157 0.         0.0627451  0.15294118\n",
            "  0.25098039 0.         0.         0.         0.         0.\n",
            "  0.         0.50588235 0.59215686 0.68627451 0.         0.\n",
            "  0.         0.01568627 0.01568627 0.         0.18823529 0.45490196\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.22745098 0.34117647 0.28627451 0.03921569\n",
            "  0.         0.         0.         0.         0.10588235 0.73333333\n",
            "  0.76470588 0.         0.         0.         0.         0.01176471\n",
            "  0.00392157 0.         0.18431373 0.57254902 0.         0.\n",
            "  0.00392157 0.         0.         0.         0.00392157 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.70980392 0.88235294 0.17647059 0.\n",
            "  0.         0.         0.         0.         0.00392157 0.\n",
            "  0.17647059 0.72941176 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.00392157 0.71764706\n",
            "  0.82352941 0.35294118 0.         0.         0.         0.49411765\n",
            "  0.99215686 0.55686275 0.         0.         0.         0.\n",
            "  0.         0.         0.00392157 0.         0.18823529 0.79607843\n",
            "  0.         0.         0.25098039 0.22745098 0.17647059 0.10588235\n",
            "  0.0627451  0.03529412 0.00392157 0.68627451 0.96078431 0.8\n",
            "  0.08627451 0.         0.2745098  0.9254902  0.74509804 0.02352941\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.19607843 0.76862745 0.         0.\n",
            "  0.37647059 0.50196078 0.58431373 0.63921569 0.61960784 0.54901961\n",
            "  0.54117647 0.57254902 0.60392157 0.42352941 0.35294118 0.58039216\n",
            "  0.75686275 0.69411765 0.14117647 0.         0.02745098 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.16078431 0.49019608 0.         0.         0.         0.\n",
            "  0.         0.         0.0745098  0.18431373 0.25490196 0.36470588\n",
            "  0.36862745 0.49019608 0.65098039 0.70588235 0.46666667 0.11372549\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.1254902  0.93333333\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.51372549 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "current_H shape:[ 0 ]: (784, 1)\n",
            "current_grad_L_by_A[ 0  ]: [[ 0.         -0.62073509 -0.         -0.         -0.         -0.\n",
            "  -0.         -0.         -0.          0.          0.         -0.\n",
            "   1.74866222  0.         -0.          0.72010398 -0.          0.\n",
            "   0.         -0.          0.         -0.          0.         -0.\n",
            "  -0.         -0.          0.         -0.         -0.42529295 -0.\n",
            "  -0.          0.54013018]]\n",
            "current_grad_L_by_A[ 0  ] shape: (1, 32)\n",
            "self.array_grad_L_by_weight[ 0 ]: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 1265\n",
            "self.array_grad_L_by_bias[ 0 ]: [[ 0.         -0.62073509 -0.         -0.         -0.         -0.\n",
            "  -0.         -0.         -0.          0.          0.         -0.\n",
            "   1.74866222  0.         -0.          0.72010398 -0.          0.\n",
            "   0.         -0.          0.         -0.          0.         -0.\n",
            "  -0.         -0.          0.         -0.         -0.42529295 -0.\n",
            "  -0.          0.54013018]]\n",
            "Predicted output: [2.62935792e-04 1.27494308e-03 1.36647795e-04 9.85198759e-01\n",
            " 3.67225165e-04 1.20222834e-02 2.28561495e-07 6.28682293e-07\n",
            " 1.13299885e-05 7.25018753e-04]\n",
            "Actual output: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n",
            "Biases [ 0.03087893  0.49004319  0.62158498  0.1144591  -0.22994885  0.81738447\n",
            "  0.83994874 -1.01886055 -3.71672221 -1.13828378  0.41275672 -0.90701723\n",
            " -0.89284531 -0.93809922 -0.13541796  0.49307545 -1.03918461 -1.97094642\n",
            "  0.78152873 -0.89302571 -0.2115672  -0.32237899 -0.56398459 -0.57751211\n",
            " -1.77936978 -0.19009385  0.19969615 -0.8121965   0.88066725 -0.85180433\n",
            " -0.93873857  0.17023652]\n",
            "A's [ -20.56938903    2.26221281   -5.71177431  -27.61305707  -29.5245449\n",
            "  -20.7930688    -8.53297792  -44.21438002 -100.43746551  -18.16840079\n",
            "   -2.1909027   -48.50351417    2.66991625  -26.9766549   -28.95280086\n",
            "    2.27828598  -55.91231502  -27.58216732   -3.04833865  -39.75751781\n",
            "  -28.99393168  -42.70597006  -30.25654961  -24.64789517  -89.34028209\n",
            "  -18.48720869  -14.52565367  -27.33271883    3.796255    -58.85209798\n",
            "  -47.42505608    1.09780583]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 2.29150284e+00  2.46523039e+00 -8.97014575e-01 -4.06045483e-03\n",
            "  -6.69532988e-01 -1.94642287e+00  1.76228313e-01 -3.03210110e-01\n",
            "   7.41851688e-01 -1.00210150e+00]\n",
            " [ 1.45196216e+00  1.05702305e+00 -2.65299041e-01  4.90109302e-01\n",
            "   1.16256907e-01  1.56389765e+00 -7.20264629e-01  5.36020855e-01\n",
            "  -1.14735366e-01 -8.52547357e-01]\n",
            " [ 1.48419008e+00 -9.31578510e-01  7.85121064e+00 -3.44192828e+00\n",
            "  -2.52451199e-01 -8.15235685e-01 -1.45862209e+00 -3.72808236e-01\n",
            "   1.01582961e+00 -7.78052609e+00]\n",
            " [ 1.86309544e+01  2.04409738e-01  1.59754677e+00 -3.08872116e+00\n",
            "   2.51397538e+00  9.34496056e-01  8.30885034e-01 -8.91756953e-01\n",
            "  -5.28086871e-01 -1.35313924e+01]\n",
            " [ 2.12724713e+01  5.94458093e-01 -1.69647492e+00 -8.95832767e+00\n",
            "   4.52038471e-01 -5.10581933e-01  1.47763031e-01 -1.98749493e+00\n",
            "   6.14013681e-01 -7.15347795e+00]\n",
            " [ 1.60933497e+00  6.64103061e-01  7.77575698e-01 -9.43842109e-03\n",
            "   1.61623803e-01  8.45016415e-01 -1.40692164e-01  1.04953810e+00\n",
            "   1.21544638e+00  5.06843077e-01]\n",
            " [ 1.73782607e+00  2.82179697e-01  2.70231433e-01 -1.27763898e+00\n",
            "  -2.59392017e-01  1.05206840e+00  6.70836257e-01 -4.40261755e-01\n",
            "   5.59054517e-01  8.48724554e-02]\n",
            " [ 3.77914644e+00  7.39260273e-01  1.09045840e+00 -3.04914443e+00\n",
            "  -1.83417412e+00 -1.39587437e+00  2.08574814e+00  1.10508710e+00\n",
            "   6.31537488e-01  1.33053567e+00]\n",
            " [ 2.17740175e+01 -1.24683987e+00  4.00957574e+00 -7.11445367e+00\n",
            "  -6.81568306e-01  7.66138607e-01 -2.28656730e+00 -3.17448463e+00\n",
            "   6.70124736e-01 -1.33868697e+01]\n",
            " [-6.03553027e+00  7.11586925e-02 -3.00143268e-01  7.01445383e+00\n",
            "  -2.05849531e+00  1.21425460e-01 -8.13036872e-02 -8.81031380e-01\n",
            "   1.13257190e+00 -1.87693884e+00]\n",
            " [-1.50230842e-01  1.03930763e+00  7.29168297e-01  1.02620290e+00\n",
            "  -1.09021236e+00  2.75264079e-01 -1.96737026e-01  1.68387065e+00\n",
            "  -1.12253310e+00  6.89092159e-03]\n",
            " [ 2.17075852e+00  3.99198686e-01 -1.52415861e+00 -5.53662461e-01\n",
            "  -6.95304516e-01  1.80543543e-01 -3.37668606e-01 -1.28131826e+00\n",
            "   5.89818080e-02 -3.15075870e+00]\n",
            " [-1.98342171e+00 -4.69362313e-01 -4.12094565e-01  9.16478882e-01\n",
            "   1.12218547e-01 -7.04162092e-01  6.07025217e-01 -1.44097796e+00\n",
            "  -6.60801123e-01  2.26430437e+00]\n",
            " [ 2.45563765e+00  8.42468575e-01  1.92183715e+00  2.68631422e+00\n",
            "   1.20509059e+00  1.14726221e-01 -3.26866712e-01  1.14392147e+00\n",
            "   7.28845462e-01 -5.03862827e+00]\n",
            " [-1.20219080e+00  6.76892638e-01 -9.42912310e-01 -2.17283210e+00\n",
            "  -2.75746506e-01 -3.44998721e-02  1.49006107e+00 -1.12197000e+00\n",
            "  -1.16748214e-02  4.37704871e+00]\n",
            " [-1.96116911e-01  1.67301019e-01 -4.46580101e-01  1.34918561e+00\n",
            "   7.12752415e-01  1.06612088e+00 -6.93758241e-01 -1.13758555e+00\n",
            "  -1.21434748e-01  4.32014773e-01]\n",
            " [ 1.75344010e-01  1.53968645e-01  7.15296631e-03  6.84252444e-01\n",
            "  -1.04532001e+00  8.49172338e-01 -4.20993426e-01 -4.48084427e-01\n",
            "  -1.58122829e-02 -1.37941738e+00]\n",
            " [ 5.05616973e+00  1.84482447e+00  3.49564185e-01  4.35581129e+00\n",
            "   1.67208203e-01 -2.03435087e+00  1.31231916e+00 -5.28710521e-01\n",
            "   1.90631102e+00 -8.06739695e+00]\n",
            " [ 1.39309490e+00  5.56403132e-01  1.60308951e-01  7.03829981e-01\n",
            "  -1.06670368e+00 -8.85351361e-01 -2.80529220e-01 -8.77616397e-01\n",
            "   8.26863347e-01 -1.67612503e+00]\n",
            " [ 7.03071613e+00 -1.09585299e+00 -1.08103152e-01 -6.25150511e+00\n",
            "  -1.16267201e+00 -6.53111631e-01 -8.57373891e-01 -2.27625392e+00\n",
            "   3.11407572e-02 -1.37006479e-01]\n",
            " [-1.46743702e-01 -9.43673115e-01  1.65475333e+00 -2.01340703e+00\n",
            "   7.71264415e-01 -2.21848462e+00 -1.14691887e-01  4.90220849e-01\n",
            "  -1.18438568e-01  3.70520603e+00]\n",
            " [ 1.15483391e+00  4.34464327e-01  3.93290067e-01 -1.20697653e+01\n",
            "  -6.58334895e-01 -3.74907738e-01 -1.41611555e-01 -2.25120908e+00\n",
            "  -6.15540612e-01  1.36790498e+01]\n",
            " [ 6.84144849e-01 -1.43595713e+00 -1.04511258e+00 -5.87964216e-01\n",
            "  -1.23161507e+00 -1.35292300e+00  6.78433076e-01  1.81829350e-01\n",
            "  -1.31372530e+00 -1.27150708e+00]\n",
            " [ 1.38161703e+01 -7.82203372e-01  2.10349878e-01 -1.01822449e+00\n",
            "   1.24189986e+00 -3.04123536e-01  8.49146897e-01 -2.65632479e+00\n",
            "   5.50689660e-01 -1.11279359e+01]\n",
            " [ 2.29817284e+00  7.65434462e-01  1.58340823e+00 -7.24885895e+00\n",
            "   4.16327772e-01  8.65797709e-02 -7.77249968e-01 -1.47661925e+00\n",
            "   7.23859020e-01  1.02439103e+01]\n",
            " [ 5.43784494e+00 -2.28986326e+00  1.59171146e-01 -3.13100326e+00\n",
            "   1.41005410e+00 -7.81474646e-01  1.59279132e-02 -5.18267173e-01\n",
            "  -5.83126594e-01 -6.79365023e-01]\n",
            " [ 3.53626738e-01 -1.15211746e+00 -1.12159934e+00  2.71981678e-01\n",
            "   1.40136595e+00 -4.27549781e-01 -2.84710131e-01  3.25494097e-01\n",
            "  -1.23769283e+00  8.29975266e-01]\n",
            " [ 1.79685975e+00 -1.39539147e+00  1.42735044e+00 -2.59788325e+00\n",
            "   1.94987364e+00  7.80239841e-01  6.77848751e-01  1.07548782e+00\n",
            "  -1.19756701e-01  1.70470818e+00]\n",
            " [ 8.09821630e-02 -9.95552944e-02  4.47794022e-01  5.25658141e-02\n",
            "  -3.22793018e-01  1.23022303e+00 -1.45797396e+00  2.33972595e-01\n",
            "  -5.01441321e-01 -6.93897181e-01]\n",
            " [ 3.82218675e-01 -6.95748040e-02 -3.24467046e-01 -2.50187715e+00\n",
            "   2.07346250e+00 -4.25927450e-02 -2.27085566e-01  2.90607360e-01\n",
            "  -2.51196835e-01  3.88281731e+00]\n",
            " [ 1.59477465e+01 -2.26989131e-01 -3.27272311e-01 -3.00969890e+00\n",
            "   4.14779258e-01 -1.13569562e+00  1.31769772e+00 -6.46079686e-01\n",
            "   1.35488671e+00 -1.00710552e+01]\n",
            " [ 7.22578415e-01  6.87898136e-01  5.48519880e-01 -2.64870881e-01\n",
            "   3.00213843e-01 -5.93796532e-01  7.15930432e-01 -7.07571605e-01\n",
            "   1.12434696e+00 -7.63732750e-01]]\n",
            "Biases [ 1.20917113  0.70177865  0.9475082   0.32534384  0.06598972  0.10572141\n",
            "  0.31411996 -0.07532536  0.84911884  0.62719014]\n",
            "A's [ 1.0238272   2.60257415  0.3693241   9.25251602  1.35789252  4.84643448\n",
            " -6.02403265 -5.01221192 -2.12062961  2.03811485]\n",
            "**************************\n",
            "Loss: 6.378145260834441\n",
            "Data point number: 9\n",
            "Back prop starts ===========================\n",
            "current_H:[ 1 ]: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         1.95466711 0.\n",
            "  0.         0.        ]]\n",
            "current_H shape:[ 1 ]: (32, 1)\n",
            "current_grad_L_by_A[ 1  ]: [[ 0.13493184  0.05708187  0.21274662  0.05274125  0.01953763 -0.5768599\n",
            "   0.00272256  0.05036611  0.03015267  0.01657934]]\n",
            "current_grad_L_by_A[ 1  ] shape: (1, 10)\n",
            "self.array_grad_L_by_weight[ 1 ]: [[ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.26374682  0.11157606  0.41584882  0.10309159  0.03818956 -1.12756907\n",
            "   0.00532169  0.09844899  0.05893843  0.0324071 ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]]\n",
            "number of non-zeros in weight gradient: 10\n",
            "self.array_grad_L_by_bias[ 1 ]: [[ 0.13493184  0.05708187  0.21274662  0.05274125  0.01953763 -0.5768599\n",
            "   0.00272256  0.05036611  0.03015267  0.01657934]]\n",
            "current_grad_H_by_A[ 1 ]: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "self.array_grad_L_by_A[ 0 ]: [[ 0.        -0.         0.         0.         0.         0.\n",
            "  -0.         0.         0.        -0.         0.        -0.\n",
            "   0.         0.        -0.        -0.        -0.         0.\n",
            "   0.         0.         0.        -0.         0.         0.\n",
            "   0.         0.         0.        -0.        -0.6314989 -0.\n",
            "   0.         0.       ]]\n",
            "current_H:[ 0 ]: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.00392157 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.64313725 0.19607843 0.         0.02745098 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.00392157 0.         0.         0.00392157\n",
            "  0.         0.         0.00392157 0.00392157 0.         0.\n",
            "  0.01960784 0.         0.17647059 0.85098039 1.         0.69019608\n",
            "  0.         0.02352941 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.00392157 0.         0.01176471 0.01176471\n",
            "  0.01960784 0.03529412 0.         0.00784314 0.         0.24313725\n",
            "  0.9254902  0.90588235 0.84313725 0.10588235 0.         0.00392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.11372549 0.95686275 0.90588235 0.91764706\n",
            "  0.29019608 0.         0.00392157 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00784314 0.         0.\n",
            "  0.         0.09019608 0.16078431 0.23137255 0.43529412 0.5254902\n",
            "  0.54117647 0.88627451 0.79215686 0.85098039 0.08627451 0.\n",
            "  0.00392157 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.01960784 0.         0.1372549  0.70196078 0.76470588\n",
            "  0.71372549 0.88235294 0.77647059 0.94509804 0.69411765 0.78039216\n",
            "  0.80392157 0.82352941 0.10196078 0.         0.00392157 0.\n",
            "  0.         0.01176471 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.0745098  0.         0.         0.\n",
            "  0.         0.         0.92156863 0.95294118 0.77647059 0.46666667\n",
            "  0.         0.01176471 0.00392157 0.01176471 0.01568627 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00784314 0.01960784 0.         0.         0.\n",
            "  0.66666667 0.98823529 0.70980392 0.71372549 0.         0.\n",
            "  0.         0.         0.         0.0745098  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.00392157 0.00392157\n",
            "  0.         0.         0.01568627 0.         0.29803922 1.\n",
            "  0.71764706 0.85882353 0.03529412 0.         0.         0.16470588\n",
            "  0.74901961 0.64313725 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00784314 0.         0.         0.92941176 0.77647059 0.8\n",
            "  0.29411765 0.18431373 0.86666667 0.86666667 0.93333333 0.09803922\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.         0.00392157 0.00784314 0.00392157 0.\n",
            "  0.         0.81960784 0.83137255 0.89803922 1.         0.99607843\n",
            "  0.90980392 0.89019608 0.68235294 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.         0.         0.         0.\n",
            "  0.82352941 1.         0.34117647 0.39607843 0.90196078 0.93333333\n",
            "  0.41176471 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.         0.01568627\n",
            "  0.00392157 0.         0.00392157 0.98039216 0.9254902  0.\n",
            "  0.         0.         0.87843137 0.91372549 0.07843137 0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.01176471 0.01568627 0.01568627 0.00784314 0.         0.\n",
            "  0.         0.00392157 0.         0.00784314 0.         0.\n",
            "  0.8        0.7254902  0.         0.         0.         0.02352941\n",
            "  0.89019608 0.79215686 0.         0.         0.         0.00392157\n",
            "  0.         0.00392157 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.         0.         0.67843137 0.62352941 0.\n",
            "  0.         0.00784314 0.         0.03921569 0.92941176 0.6\n",
            "  0.         0.         0.         0.         0.00392157 0.\n",
            "  0.         0.         0.         0.15686275 0.54117647 0.08235294\n",
            "  0.         0.         0.00784314 0.         0.03137255 0.\n",
            "  0.51764706 0.76470588 0.         0.         0.         0.\n",
            "  0.         0.03137255 0.94117647 0.4627451  0.         0.00392157\n",
            "  0.01960784 0.02352941 0.01568627 0.         0.51764706 0.90980392\n",
            "  0.81568627 0.81568627 0.94509804 0.85098039 0.         0.\n",
            "  0.         0.00392157 0.         0.11372549 0.85098039 0.1372549\n",
            "  0.         0.03529412 0.         0.00784314 0.         0.09803922\n",
            "  0.93333333 0.22745098 0.         0.00784314 0.         0.\n",
            "  0.         0.         0.70980392 1.         0.90588235 0.91372549\n",
            "  0.85882353 0.93333333 0.30196078 0.         0.         0.\n",
            "  0.         0.76862745 0.56862745 0.         0.         0.\n",
            "  0.         0.00784314 0.         0.19215686 0.89411765 0.\n",
            "  0.         0.00784314 0.24313725 0.36078431 0.03137255 0.\n",
            "  0.81176471 1.         0.84705882 0.77647059 0.74117647 0.81568627\n",
            "  0.86666667 0.         0.         0.         0.69411765 0.9372549\n",
            "  0.0745098  0.         0.         0.         0.         0.00784314\n",
            "  0.         0.25098039 0.85490196 0.         0.         0.01176471\n",
            "  0.37647059 0.97647059 0.8745098  0.82745098 0.92941176 0.95294118\n",
            "  0.82745098 0.89411765 1.         0.98823529 1.         0.54117647\n",
            "  0.14901961 0.68627451 0.94901961 0.67843137 0.         0.\n",
            "  0.         0.         0.         0.00784314 0.         0.34901961\n",
            "  0.8        0.         0.         0.00784314 0.         0.77254902\n",
            "  0.94117647 0.94117647 0.92941176 0.85882353 0.87058824 0.95686275\n",
            "  0.92156863 0.95294118 0.95686275 1.         1.         0.91764706\n",
            "  0.91372549 0.17647059 0.         0.00784314 0.         0.\n",
            "  0.         0.00784314 0.         0.41176471 0.7372549  0.\n",
            "  0.         0.         0.         0.64705882 0.99215686 0.87843137\n",
            "  0.89803922 0.94901961 0.95686275 0.90980392 0.9372549  0.94901961\n",
            "  0.95294118 0.92941176 0.90196078 0.90196078 0.81176471 0.\n",
            "  0.         0.00392157 0.         0.         0.         0.03529412\n",
            "  0.         0.47058824 0.64705882 0.         0.03137255 0.\n",
            "  0.         0.17647059 1.         0.98823529 0.99215686 0.94509804\n",
            "  0.89803922 0.8745098  0.90196078 0.92156863 0.94117647 0.9372549\n",
            "  0.91372549 0.96078431 0.25490196 0.         0.00784314 0.\n",
            "  0.         0.         0.         0.03921569 0.         0.50196078\n",
            "  0.56078431 0.         0.03921569 0.         0.         0.\n",
            "  0.         0.28235294 0.79215686 1.         1.         1.\n",
            "  1.         1.         1.         1.         1.         0.76078431\n",
            "  0.         0.         0.00784314 0.         0.         0.\n",
            "  0.         0.03137255 0.         0.72941176 0.62745098 0.\n",
            "  0.03529412 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.14901961 0.34901961 0.52941176 0.63529412\n",
            "  0.70588235 0.70196078 0.59607843 0.         0.         0.00392157\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.26666667 0.11372549 0.         0.01176471 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "current_H shape:[ 0 ]: (784, 1)\n",
            "current_grad_L_by_A[ 0  ]: [[ 0.        -0.         0.         0.         0.         0.\n",
            "  -0.         0.         0.        -0.         0.        -0.\n",
            "   0.         0.        -0.        -0.        -0.         0.\n",
            "   0.         0.         0.        -0.         0.         0.\n",
            "   0.         0.         0.        -0.        -0.6314989 -0.\n",
            "   0.         0.       ]]\n",
            "current_grad_L_by_A[ 0  ] shape: (1, 32)\n",
            "self.array_grad_L_by_weight[ 0 ]: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "number of non-zeros in weight gradient: 314\n",
            "self.array_grad_L_by_bias[ 0 ]: [[ 0.        -0.         0.         0.         0.         0.\n",
            "  -0.         0.         0.        -0.         0.        -0.\n",
            "   0.         0.        -0.        -0.        -0.         0.\n",
            "   0.         0.         0.        -0.         0.         0.\n",
            "   0.         0.         0.        -0.        -0.6314989 -0.\n",
            "   0.         0.       ]]\n",
            "Predicted output: [0.13493184 0.05708187 0.21274662 0.05274125 0.01953763 0.4231401\n",
            " 0.00272256 0.05036611 0.03015267 0.01657934]\n",
            "Actual output: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "Layer 0\n",
            "============================\n",
            "Activation: relu\n",
            "Number of units: 32\n",
            "Weights [[-0.23677285  0.30000313 -1.87856866 ... -0.02001042 -0.93338787\n",
            "  -0.26010536]\n",
            " [-0.95442528 -0.8275317  -0.07339604 ... -0.40197079 -1.21842002\n",
            "  -0.28173168]\n",
            " [-0.28469295 -0.46727926 -0.44409613 ...  0.21426595 -2.64534561\n",
            "   1.02562958]\n",
            " ...\n",
            " [ 0.34682924 -1.06643032  1.60432576 ...  0.72077716  1.44919765\n",
            "   1.50368916]\n",
            " [-0.07150146 -0.77779625 -0.25400997 ... -0.82705873  1.3926286\n",
            "  -0.52585658]\n",
            " [ 0.65165466 -0.04335635 -0.91594082 ...  0.24410686  1.62845918\n",
            "  -0.05187252]]\n",
            "Biases [-0.02248445  0.54590934  0.59430673  0.06268332 -0.32494303  0.81738447\n",
            "  0.83994874 -1.34654881 -5.50868532 -1.35233728  0.41275672 -1.01435529\n",
            " -1.20054867 -1.05617815 -0.17777102  0.42826609 -1.14852486 -2.24509249\n",
            "  0.78152873 -1.01535336 -0.24634449 -0.39585131 -0.60299169 -0.64836062\n",
            " -1.97718343 -0.28745428  0.19969615 -1.02744749  0.9820935  -0.94188149\n",
            " -1.05516309  0.1216248 ]\n",
            "A's [ -46.0430946    -8.97511392  -20.00031048  -55.27159639  -57.54634293\n",
            "  -17.35615538   -8.53135553 -121.99609648 -404.89292209  -57.54606699\n",
            "   -3.21566723  -95.32904781  -28.34249921  -44.1699049   -68.37806563\n",
            "   -0.86988643 -108.77060009  -51.5710622   -24.04213896 -102.13991763\n",
            "  -59.74749421 -116.0750301   -66.69733824  -54.52215277 -162.21134896\n",
            "  -33.5484624   -22.01557296  -52.58301338    1.95466711 -142.93703049\n",
            "  -94.01474455   -4.07261591]\n",
            "**************************\n",
            "Layer 1\n",
            "============================\n",
            "Activation: softmax\n",
            "Number of units: 10\n",
            "Weights [[ 2.46282067e+00  2.46523039e+00 -8.97014575e-01 -4.06045483e-03\n",
            "  -6.69532988e-01 -1.94642287e+00  1.76228313e-01 -3.03210110e-01\n",
            "   7.41851688e-01 -1.17341934e+00]\n",
            " [ 1.45190863e+00  1.05676347e+00 -2.65326862e-01  2.89523669e-01\n",
            "   1.16182140e-01  1.76504908e+00 -7.20264676e-01  5.36020727e-01\n",
            "  -1.14737673e-01 -8.52694970e-01]\n",
            " [ 1.66944885e+00 -9.31578510e-01  9.59430046e+00 -3.71609868e+00\n",
            "  -2.52492325e-01 -8.15235685e-01 -1.45862209e+00 -3.99207498e-01\n",
            "   1.01582961e+00 -9.40826389e+00]\n",
            " [ 2.00369732e+01  2.04409738e-01  1.59754677e+00 -3.32001312e+00\n",
            "   2.51397538e+00  9.34496056e-01  8.30885034e-01 -9.60399426e-01\n",
            "  -5.28086871e-01 -1.46374768e+01]\n",
            " [ 2.28376050e+01  5.94458093e-01 -1.69647492e+00 -9.56356487e+00\n",
            "   4.52038471e-01 -5.10581933e-01  1.47763031e-01 -2.16711630e+00\n",
            "   6.14013681e-01 -7.93375316e+00]\n",
            " [ 1.60933497e+00  6.64103061e-01  7.77575698e-01 -9.43842109e-03\n",
            "   1.61623803e-01  8.45016415e-01 -1.40692164e-01  1.04953810e+00\n",
            "   1.21544638e+00  5.06843077e-01]\n",
            " [ 1.73782607e+00  2.82179697e-01  2.70231433e-01 -1.27763898e+00\n",
            "  -2.59392017e-01  1.05206840e+00  6.70836257e-01 -4.40261755e-01\n",
            "   5.59054517e-01  8.48724554e-02]\n",
            " [ 3.95603373e+00  7.39260273e-01  1.58145729e+00 -3.26647373e+00\n",
            "  -1.83417412e+00 -1.39587437e+00  2.08574814e+00  1.04058845e+00\n",
            "   6.31537488e-01  9.44477458e-01]\n",
            " [ 2.18121603e+01 -1.24683987e+00  5.83853314e+00 -7.56524440e+00\n",
            "  -6.81568306e-01  7.66138607e-01 -2.28656730e+00 -3.30826962e+00\n",
            "   6.70124736e-01 -1.46693942e+01]\n",
            " [-6.82222437e+00  7.11586925e-02 -3.00143268e-01  7.95372890e+00\n",
            "  -2.05856778e+00  1.21425460e-01 -8.13036872e-02 -8.81031380e-01\n",
            "   1.13257190e+00 -2.02944734e+00]\n",
            " [-1.50230842e-01  1.03930763e+00  7.29168297e-01  1.02620290e+00\n",
            "  -1.09021236e+00  2.75264079e-01 -1.96737026e-01  1.68387065e+00\n",
            "  -1.12253310e+00  6.89092159e-03]\n",
            " [ 2.46609878e+00  3.99198686e-01 -1.52415861e+00 -5.53662461e-01\n",
            "  -6.95304516e-01  1.80543543e-01 -3.37668606e-01 -1.28131826e+00\n",
            "   5.89818080e-02 -3.44609896e+00]\n",
            " [-2.36615010e+00 -4.69668673e-01 -4.12127401e-01  1.01795992e+00\n",
            "   1.12130305e-01 -4.66758494e-01  6.07025162e-01 -1.49793831e+00\n",
            "  -6.60803845e-01  2.36553869e+00]\n",
            " [ 2.48989066e+00  8.42468575e-01  1.92183715e+00  3.03643035e+00\n",
            "   1.20509059e+00  1.14726221e-01 -3.26866712e-01  1.14392147e+00\n",
            "   7.28845462e-01 -5.42299740e+00]\n",
            " [-1.20219080e+00  6.76892638e-01 -9.42912310e-01 -2.39457365e+00\n",
            "  -2.75746506e-01 -3.44998721e-02  1.49006107e+00 -1.18777811e+00\n",
            "  -1.16748214e-02  4.66459838e+00]\n",
            " [-1.96170825e-01  1.67039597e-01 -4.46608120e-01  1.14717481e+00\n",
            "   7.12677117e-01  1.26870150e+00 -6.93758288e-01 -1.13758568e+00\n",
            "  -1.21437071e-01  4.31866111e-01]\n",
            " [ 3.30091581e-01  1.53968645e-01  7.15296631e-03  6.84252444e-01\n",
            "  -1.04532001e+00  8.49172338e-01 -4.20993426e-01 -4.48084427e-01\n",
            "  -1.58122829e-02 -1.53416495e+00]\n",
            " [ 5.14221374e+00  1.84482447e+00  3.49564185e-01  4.99326302e+00\n",
            "   1.67208203e-01 -2.03435087e+00  1.31231916e+00 -5.60278052e-01\n",
            "   1.90631102e+00 -8.75932516e+00]\n",
            " [ 1.39309490e+00  5.56403132e-01  1.60308951e-01  7.03829981e-01\n",
            "  -1.06670368e+00 -8.85351361e-01 -2.80529220e-01 -8.77616397e-01\n",
            "   8.26863347e-01 -1.67612503e+00]\n",
            " [ 7.68585216e+00 -1.09585299e+00 -1.08103152e-01 -6.63702477e+00\n",
            "  -1.16267201e+00 -6.53111631e-01 -8.57373891e-01 -2.39066785e+00\n",
            "   3.11407572e-02 -2.92208932e-01]\n",
            " [-1.46743702e-01 -9.43673115e-01  1.65475333e+00 -2.19444371e+00\n",
            "   7.71264415e-01 -2.21848462e+00 -1.14691887e-01  4.36493059e-01\n",
            "  -1.18438568e-01  3.93997050e+00]\n",
            " [ 1.15483391e+00  4.34464327e-01  3.93290067e-01 -1.28262424e+01\n",
            "  -6.58334895e-01 -3.74907738e-01 -1.41611555e-01 -2.47571521e+00\n",
            "  -6.15540612e-01  1.46600330e+01]\n",
            " [ 6.84144849e-01 -1.43595713e+00 -1.04511258e+00 -5.94664086e-01\n",
            "  -1.23161507e+00 -1.35292300e+00  6.78433076e-01  1.79840973e-01\n",
            "  -1.31372530e+00 -1.26281883e+00]\n",
            " [ 1.49177580e+01 -7.82203372e-01  2.10349878e-01 -1.15241720e+00\n",
            "   1.24189986e+00 -3.04123536e-01  8.49146897e-01 -2.69615030e+00\n",
            "   5.50689660e-01 -1.20555054e+01]\n",
            " [ 2.55283714e+00  7.65434462e-01  1.58340823e+00 -7.81283484e+00\n",
            "   4.16327772e-01  8.65797709e-02 -7.77249968e-01 -1.64399515e+00\n",
            "   7.23859020e-01  1.07205978e+01]\n",
            " [ 6.17459954e+00 -2.28986326e+00  1.59171146e-01 -3.86759431e+00\n",
            "   1.40989055e+00 -7.81474646e-01  1.59279132e-02 -5.18267173e-01\n",
            "  -5.83126594e-01 -6.79365023e-01]\n",
            " [ 3.53626738e-01 -1.15211746e+00 -1.12159934e+00  2.71981678e-01\n",
            "   1.40136595e+00 -4.27549781e-01 -2.84710131e-01  3.25494097e-01\n",
            "  -1.23769283e+00  8.29975266e-01]\n",
            " [ 2.15297165e+00 -1.39539147e+00  1.68953236e+00 -3.03032212e+00\n",
            "   1.94979459e+00  7.80239841e-01  6.77848751e-01  1.05281215e+00\n",
            "  -1.19756701e-01  1.54160794e+00]\n",
            " [ 5.45176452e-02 -1.11148501e-01  4.06162452e-01 -2.94349259e-01\n",
            "  -3.26737441e-01  1.68053531e+00 -1.45850621e+00  2.24127482e-01\n",
            "  -5.07339035e-01 -6.97385603e-01]\n",
            " [ 3.82218675e-01 -6.95748040e-02 -3.24467046e-01 -2.74626793e+00\n",
            "   2.07346250e+00 -4.25927450e-02 -2.27085566e-01  2.18077437e-01\n",
            "  -2.51196835e-01  4.19973802e+00]\n",
            " [ 1.72120733e+01 -2.26989131e-01 -3.27272311e-01 -3.27119891e+00\n",
            "   4.14779258e-01 -1.13569562e+00  1.31769772e+00 -7.23687257e-01\n",
            "   1.35488671e+00 -1.09962744e+01]\n",
            " [ 7.22552436e-01  6.87772169e-01  5.48506379e-01 -3.62211005e-01\n",
            "   3.00177560e-01 -4.96181839e-01  7.15930410e-01 -7.07571667e-01\n",
            "   1.12434584e+00 -7.63804384e-01]]\n",
            "Biases [ 1.16360591  0.69595572  1.07283124  0.19781155  0.06398979  0.25232539\n",
            "  0.31384768 -0.08858234  0.84610255  0.55272903]\n",
            "A's [ 1.3674643   0.50718119  1.82279645  0.4280925  -0.56496318  2.5103979\n",
            " -2.53573379  0.38201318 -0.13103202 -0.72914786]\n",
            "**************************\n",
            "Loss: 1.2407926773370457\n",
            "Average  categorical_crossentropy  loss:  0.04846053090738231\n",
            "Correctly classified: 6734.0\n",
            "total_samples: 60000\n",
            "Train accuracy  0.11223333333333334\n",
            "Correctly classified: 1130.0\n",
            "total_samples: 10000\n",
            "Test accuracy  0.113\n",
            "Correctly classified: 1130.0\n",
            "total_samples: 10000\n",
            "Test accuracy at end: 0.113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_xtrain=np.array([[1,2],[2,3],[3,4]])\n",
        "sample_xtrain=sample_xtrain.astype('uint8')\n",
        "print(sample_xtrain.shape)\n",
        "print(sample_xtrain[0])"
      ],
      "metadata": {
        "id": "uy-kRM--tU5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ytrain=np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0]])\n",
        "sample_ytrain=sample_ytrain.astype('float32')\n",
        "print(sample_ytrain)\n",
        "print(sample_ytrain.shape)"
      ],
      "metadata": {
        "id": "KySDZSYIUjIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.finfo(np.float64).max"
      ],
      "metadata": {
        "id": "O9Kca8TSH9A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o = 1.98138316e-84\n",
        "print(o)\n",
        "temp = 1.0+o\n",
        "print(temp)\n",
        "y=1/temp\n",
        "print(y)"
      ],
      "metadata": {
        "id": "HcnV0woio2bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ff = np.array([1,2,3,4])\n",
        "ff = ff[np.newaxis].T\n",
        "print(ff)\n",
        "print(ff.shape)\n",
        "print(\"FFF\",ff.T)\n",
        "print(ff.shape)"
      ],
      "metadata": {
        "id": "9j3PoYRbPCi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.array([0,0.1])\n",
        "print(\"A\",type(a))\n",
        "np.maximum(a,1e-3)"
      ],
      "metadata": {
        "id": "5srzTMrHt9n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh(x):\n",
        "    t=(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "    dt=1-t**2\n",
        "    return t,dt"
      ],
      "metadata": {
        "id": "Wkw7TSU6dcAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Activation().tanh(np.array([9]))"
      ],
      "metadata": {
        "id": "QAqQdKc2TYdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UaO4qIs3rYIu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}